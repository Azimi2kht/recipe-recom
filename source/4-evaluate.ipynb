{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NHX_YR9EWc6"
      },
      "source": [
        "# Installations and setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B5EtCnmSENqp"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "!pip install transformers==4.55.4\n",
        "!pip install --no-deps trl==0.22.2\n",
        "!pip install --no-deps evaluate rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320,
          "referenced_widgets": [
            "72c20854909a45eaaaf61012b4c15aed",
            "7ecef4efceec475ab2937fe3bab448af",
            "0b13f584ddd64125944b50c2962647d7",
            "3af44163e808405bbcb583417067afc0",
            "7dd05ed4c9c84631b5db552eb3e5799e",
            "957788d4fae84166bfc9fbb0b572343a",
            "6db949a98385435a81e2220619022ff7",
            "bcedb31a48244877a5c29a403ee77ef9",
            "9e2c5bc56d2447d1a4307d4396383383",
            "16cbe4c8ab6f42f494c617e14ff826ed",
            "d06441c0490b4463b7d3ed9b7b4fc00a",
            "9d482698162742b699b06ba177155d49",
            "bc1cc1d0d8a341cf8c7cd2898c285cc5",
            "e6171dce2972419088864207ae5990cd",
            "90f46d8a0330400f9d4235b7cef7df57",
            "e6da1088ce214b9ca2a8680270ad0d2e",
            "a52c989381fd4e85bda4c231f05b8210",
            "eea3a2ceae2e44cdb7637f9d6122b32a",
            "5321b58f90f542f884db313ed7e09886",
            "a6d10faa97bc4b868b0c614df1d41c5e",
            "52086dcfb63646ed871652855c620f49",
            "f0704ddf65b94bcaa91ed3af301523bf",
            "684595bd0fdb4b0296b605ce0ad9d87b",
            "7bda469ff6674e16adea510262a8fc68",
            "e6c3cc681529436c853d73dc1d655902",
            "ce869b663b7d422d9e2cfbc807b352ad",
            "3696af4a31b944ca8baacacb89b4404f",
            "ee8309b714b445fbb7576b2c44f4be09",
            "8b917628c48b4a7e94b0c16373b824f9",
            "4f4d3998ff5c4043a929ae6f6c3be395",
            "97ef5fa25e30466bbfdb7d753e4c3883",
            "3c093a9ecaa54d59bf99ab36586be587",
            "e0f9738353da487a84d1bb3ee52f825e",
            "6cefa094069b49acb1d65a97bb019b1a",
            "091f2b020c094abf91f9d3172213c053",
            "597925f7e8f14bd0b2d34e61715d8c52",
            "6c7e8897aa6b4c748a039824a934b368",
            "357a336b06aa4eed937c6b0a1ace6062",
            "fd423d0ade294b648d62739fd884e793",
            "12b2f78684dc46ff8dba2e692af3aef8",
            "82a2211a50654b5a9c0fee2ce6631a11",
            "db33dfc1c08f4e1d85df5699ee096e74",
            "87430bbc5852435285c6fff793e78a80",
            "3dd3b995a047404eb0360d895569ebcb",
            "a7df437b088e46fa9346729d94960189",
            "aef4337da0884c82a3285787ca311b90",
            "54e4b48a274a4bcdb95e041ed1fd6769",
            "7a3ad35f3f194b8ca8ef94aa72ce5202",
            "5527f5f291ea409b89c36adcadedc36f",
            "1aa64635846d40799bb46e2a33ef9d63",
            "53670c3fc0264499b40a8d64977ec0a3",
            "e2d6520b78a940cebf166b3678600c33",
            "1b27de43b3314c3991b74bb2d58540f9",
            "db9394a5c7f841188fd6ad81a3e1cc7b",
            "5cafc6a6ca4a4af4b2bdf563749c9ce6"
          ]
        },
        "id": "o9LmFHhzERVk",
        "outputId": "9ada78b9-5f4b-49a4-b567-83f8f63769d9"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torch._dynamo' has no attribute 'decorators' (most likely due to a circular import)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mevaluate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load \u001b[38;5;66;03m# Import from evaluate instead of datasets\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/evaluate/__init__.py:29\u001b[0m\n\u001b[1;32m     25\u001b[0m SCRIPTS_VERSION \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(__version__)\u001b[38;5;241m.\u001b[39mis_devrelease \u001b[38;5;28;01melse\u001b[39;00m __version__\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m version\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation_suite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EvaluationSuite\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     31\u001b[0m     AudioClassificationEvaluator,\n\u001b[1;32m     32\u001b[0m     AutomaticSpeechRecognitionEvaluator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     evaluator,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m push_to_hub\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/evaluate/evaluation_suite/__init__.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DownloadConfig, DownloadMode, load_dataset\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evaluator\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloading\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evaluation_module_factory\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_logger\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/evaluate/evaluator/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipelines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SUPPORTED_TASKS \u001b[38;5;28;01mas\u001b[39;00m SUPPORTED_PIPELINE_TASKS\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipelines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TASK_ALIASES\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipelines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_task \u001b[38;5;28;01mas\u001b[39;00m check_pipeline_task\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/transformers/pipelines/__init__.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoConfig\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FEATURE_EXTRACTOR_MAPPING, AutoFeatureExtractor\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_processing_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IMAGE_PROCESSOR_MAPPING, AutoImageProcessor\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForDepthEstimation, AutoModelForImageToImage\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessing_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PROCESSOR_MAPPING, AutoProcessor\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_class_from_dynamic_module, resolve_trust_remote_code\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_processing_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageProcessingMixin\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_processing_utils_fast\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseImageProcessorFast\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     CONFIG_NAME,\n\u001b[1;32m     31\u001b[0m     IMAGE_PROCESSOR_NAME,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     logging,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m requires\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/transformers/image_processing_utils_fast.py:43\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     convert_to_rgb,\n\u001b[1;32m     25\u001b[0m     get_resize_output_image_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     reorder_images,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     31\u001b[0m     ChannelDimension,\n\u001b[1;32m     32\u001b[0m     ImageInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     validate_preprocess_arguments,\n\u001b[1;32m     42\u001b[0m )\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessing_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Unpack\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     45\u001b[0m     TensorType,\n\u001b[1;32m     46\u001b[0m     auto_docstring,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     logging,\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_rocm_platform\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/transformers/processing_utils.py:75\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecate_kwarg\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedAudioTokenizerBase\n\u001b[1;32m     78\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# type hinting: specifying the type of processor class that inherits from ProcessorMixin\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/transformers/modeling_utils.py:57\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflash_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flash_attention_forward\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflash_paged\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m paged_attention_forward\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflex_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flex_attention_forward\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub_kernels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_kernel, load_and_register_kernel\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdpa_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sdpa_attention_forward\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/transformers/integrations/flex_attention.py:46\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflex_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BlockMask, create_block_mask, flex_attention\n\u001b[1;32m     43\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mWrappedFlexAttention\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    We are doing a singleton class so that flex attention is compiled once when it's first called.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     _instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/transformers/integrations/flex_attention.py:61\u001b[0m, in \u001b[0;36mWrappedFlexAttention\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instance\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, training):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    Initialize or update the singleton instance.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_flex_compiled \u001b[38;5;129;01mor\u001b[39;00m training \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/compiler/__init__.py:247\u001b[0m, in \u001b[0;36mdisable\u001b[0;34m(fn, recursive, reason)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdisable\u001b[39m(fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, reason\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    This function provides a decorator to disable compilation on a function.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m    It also provides the option of recursively disabling called functions.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m        reason (optional): A string value indicating the reason for disabling the function.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive, reason\u001b[38;5;241m=\u001b[39mreason)\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/_dynamo/__init__.py:92\u001b[0m\n\u001b[1;32m     59\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_in_graph\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massume_constant_result\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     89\u001b[0m ]\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# allowlist this for weights_only load of NJTs\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m torch\u001b[38;5;241m.\u001b[39mserialization\u001b[38;5;241m.\u001b[39madd_safe_globals([\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecorators\u001b[49m\u001b[38;5;241m.\u001b[39m_DimRange])\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmanual_seed \u001b[38;5;129;01mis\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mmanual_seed:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_builtins\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torch._dynamo' has no attribute 'decorators' (most likely due to a circular import)"
          ]
        }
      ],
      "source": [
        "from evaluate import load # Import from evaluate instead of datasets\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "random_state = 3407\n",
        "\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
        "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
        "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Meta-Llama-3.1-8B\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ4c7HMGFv7G",
        "outputId": "d9b9d225-5ba9-4a90-f4cf-f31bb0e17065"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.10.12 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 8, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = random_state,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5RVPoUOFIu7"
      },
      "source": [
        "## Dataset Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "8f46241d6a244eb4a073860b8c7c5ed1",
            "22bff263c6fc4f7ca0076a3c441040b6",
            "d3b438d3950549beb8612a0994156ec0",
            "d7f735c7119447c888823e408e0592ed",
            "82678300934f430782b089e4165a0407",
            "72b64491bfb943948a2eb7e5c8b99c28",
            "274980930ec04ab093c4e079829dce5d",
            "43da9e2f26954c4e8bf3fdb867028d8f",
            "c70df4d2f6244eb0ba8e74d28e01a5a4",
            "a79390a06d394ff895c250cfdf49845e",
            "2076f8c76b1b40f195bee2077f48988e",
            "478adf2cb9234674bb55205c37b7fb20",
            "d270c228256e4eb6beec82721b300ddf",
            "cfdc0ccf31d14718ba4323d53af1617c",
            "6735fe277015436bb03804426da1b7c3",
            "4ba8adf9783e4aa6af62b0098c4fdb3c",
            "177346c121c1484a961a3e79be3ab8d4",
            "662e7520c4cf4c769ed79148764732a5",
            "01c577ae017440bf8574713a6431a6cf",
            "7634e83aa8f546548c4b4f4325936f60",
            "9ebb5e67e4f947429d78e6d01ceb7c8f",
            "f658eb52077c4c83b1427446b2a36fea",
            "7a5295d41e4f42f493387166853219a9",
            "fe95c79aab1e4cbfac7649e5e182e4bf",
            "f50b934ba3394f3a9c328ed7c0929f17",
            "4d7c4ad2e2114d85999601f0c37e170c",
            "9f42be5e0bc64ad88409b1cfa25e16c0",
            "02c42f9e9bb14a8fb4ce0996816f4e99",
            "5a3c40d3b5bf453baf55783db1d411e8",
            "b2a1a489992643bb8a01a5e48ab8c908",
            "7f710b5bebbc419da51335777f905c97",
            "762e0363a9d8407c876dccb7de38d718",
            "3fdc0edb544243d2bfd9b8a254977188"
          ]
        },
        "id": "Qmk2h_7qFFol",
        "outputId": "e9336299-ff5d-4f21-ca25-1b7ec5f7258d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f46241d6a244eb4a073860b8c7c5ed1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "recipe_recom.parquet:   0%|          | 0.00/214k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "478adf2cb9234674bb55205c37b7fb20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/5149 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a5295d41e4f42f493387166853219a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5149 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "### Human:\n",
        "{}\n",
        "\n",
        "### Assistant\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, output in zip(instructions, outputs):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = prompt.format(instruction, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"azimidokht/recipe-recom\", split = \"train\")\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
        "\n",
        "split_dataset = dataset.train_test_split(test_size=0.2, shuffle=True, seed=random_state)\n",
        "\n",
        "train_dataset = split_dataset[\"train\"]\n",
        "temp_dataset  = split_dataset[\"test\"]\n",
        "\n",
        "val_test_split = temp_dataset.train_test_split(test_size=0.5, shuffle=True, seed=random_state)\n",
        "\n",
        "val_dataset  = val_test_split[\"train\"]\n",
        "test_dataset = val_test_split[\"test\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeBSnU1EFcKb"
      },
      "source": [
        "# Utilities and functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "0b0809a6555d4ffeba21c8ef739205df",
            "7df5c1bd952048e4adfb74909785650f",
            "0ac8fb5abd104cc88e676f7b8d9a7499",
            "919dbcad1670489f8d770d35c4018852",
            "d9466ea68d2443dfbab04c304fa72319",
            "0843de010fd340eaa43cce014053248b",
            "841aca65851e46649f908f1a1f27c69b",
            "723ab26b8e0c463cbe0276173c0e56e4",
            "d8b3965cd6794a0bb76c6314943ba6ef",
            "e85894e4f11b466eaedb1575d0986230",
            "72425f0744004baba17d6e5d23ffe8e9",
            "4226eb7a134548ca9567e8133b7fc5df",
            "b9392bcac2f045f396b27eafe351d540",
            "ee85bb2c200c403fa95d01e8b60fbc04",
            "791d8e210c6b4eff8195796b919a90d2",
            "cf1a1ed6df9d43afadf3a78ca13cb89a",
            "a752cc23a9d04a498e914909ba465b5c",
            "77ea68cd55a74d02837ef9c62ea1f2bd",
            "1c87e89f399b4e7fb406ac316b081611",
            "09cea5e418924e74a7bf7925d91c4746",
            "e84036aaca174fca9430c9cb45412580",
            "444899c1096b48dfac540255ef4ec07c"
          ]
        },
        "id": "pwuZ2g2OFfC3",
        "outputId": "3338a709-d137-4245-8ddc-aae853838a78"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'load' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m### Human:\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;132;01m{}\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m### Assistant\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m rouge \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m bleu \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbleu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m inferenced_data \u001b[38;5;241m=\u001b[39m {}\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load' is not defined"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "### Human:\n",
        "{}\n",
        "\n",
        "### Assistant\n",
        "{}\"\"\"\n",
        "rouge = load(\"rouge\")\n",
        "bleu = load(\"bleu\")\n",
        "\n",
        "inferenced_data = {}\n",
        "\n",
        "def generate_predictions(dataset, model, tokenizer, max_new_tokens=128):\n",
        "    \"\"\"Generate model outputs for a HF datasets split of dicts with keys: instruction, output.\"\"\"\n",
        "    predictions, references, instructions = [], [], []\n",
        "    FastLanguageModel.for_inference(model)\n",
        "    for example in tqdm(dataset):\n",
        "        instruction = example[\"instruction\"]\n",
        "        reference   = example[\"output\"]\n",
        "\n",
        "        inputs = tokenizer(\n",
        "            [prompt.format(instruction, \"\")],\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "        outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, use_cache=True)\n",
        "        generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "\n",
        "        # It Extracts just the assistant section\n",
        "        # Falls back to full text if the delimiter isn't present\n",
        "        #If the model output doesnâ€™t include the separator (### Assistant), use the full text as the prediction instead of trying to split it.\n",
        "        if \"### Assistant\" in generated_text:\n",
        "            assistant_response = generated_text.split(\"### Assistant\", 1)[-1].strip()\n",
        "        else:\n",
        "            assistant_response = generated_text.strip()\n",
        "\n",
        "        predictions.append(assistant_response)\n",
        "        references.append(reference)\n",
        "        instructions.append(instruction)\n",
        "    return predictions, references, instructions\n",
        "    \n",
        "\n",
        "def evaluate(predictions, references, metrics: list[str]):\n",
        "    \"\"\"\n",
        "    Evaluate the predictions against the references using the specified metrics.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    if \"rouge\" in metrics:\n",
        "      results[\"rouge\"] = rouge.compute(predictions=predictions, references=references)\n",
        "    if \"bleu\" in metrics:\n",
        "      results[\"bleu\"] = bleu.compute(predictions=predictions, references=[[ref] for ref in references]) # BLEU expects a list of references\n",
        "    else:\n",
        "      raise ValueError(\"Invalid metric\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def store(data, path):\n",
        "  with open(path, \"w\") as f:\n",
        "    json.dump(data, f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TO8dblDDzSr"
      },
      "source": [
        "# Base model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429,
          "referenced_widgets": [
            "ef2ea3286cd84745a6635cfb433a8810",
            "c72e233a48ef440fa74fcf6a11e4c466",
            "d5602a74e41346d48a40da5055b9bedc",
            "3fa42322604a40699b09aa47bb7ce475",
            "66945d36cfa4425ca6cfed923e86dfc6",
            "9f4f233d9237470c97680200575df1a2",
            "edc64d52caf3449b85488f497064990e",
            "102263c3891545b0912cfd82a1cd5d1f",
            "02400ecf2c4d4223a0bae55b932e9f4a",
            "1936b74c380e4390a29dab658aaedde0",
            "0fcc3f735e9a42b7afe82fca6edf351a",
            "d9432700110842d6a281e8ce53acdb4b",
            "eb3464710df4429ab17f03bf32b36cfc",
            "50ee208cda4a42c0b449f7e7ee8c099d",
            "b6da0dd4cb7946a49122554acae6d64c",
            "983edc8581cc45888379188d7029c250",
            "f4a8eafdb5584eafa03b4406c7f1dd39",
            "67305af8395b4009bf4d0daabc633406",
            "0c91387fe86d408c90f4f05c4725190e",
            "753e9770dbd44e4ca11e675cb22e6b07",
            "ed6377a8eded4a7daba3dd4577dbe038",
            "b439dea07dba4c0a87d1bebb4241e6c3"
          ]
        },
        "id": "7oh2_6N4Dukf",
        "outputId": "44ebbc13-85a5-48b4-c01a-8cf3e4d79fd3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef2ea3286cd84745a6635cfb433a8810",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9432700110842d6a281e8ce53acdb4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1456109987.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mrouge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rouge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bleu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0minferenced_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/loading.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \"\"\"\n\u001b[1;32m    747\u001b[0m     \u001b[0mdownload_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDownloadMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_mode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mDownloadMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREUSE_DATASET_IF_EXISTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m     evaluation_module = evaluation_module_factory(\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/loading.py\u001b[0m in \u001b[0;36mevaluation_module_factory\u001b[0;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                 \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                                 \u001b[0mdynamic_modules_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic_modules_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m                             ).get_module()\n\u001b[0m\u001b[1;32m    640\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m                             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/loading.py\u001b[0m in \u001b[0;36mget_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mimports\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_imports\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m         local_imports = _download_additional_modules(\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhf_hub_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/loading.py\u001b[0m in \u001b[0;36m_download_additional_modules\u001b[0;34m(name, base_path, imports, download_config)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong import_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         local_import_path = cached_path(\n\u001b[0m\u001b[1;32m    249\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/utils/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_remote_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         output_path = get_from_cache(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/utils/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, token, download_desc)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mconnected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mftp_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             response = http_head(\n\u001b[0m\u001b[1;32m    452\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/utils/file_utils.py\u001b[0m in \u001b[0;36mhttp_head\u001b[0;34m(url, proxies, headers, cookies, allow_redirects, timeout, max_retries)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user-agent\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datasets_user_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"user-agent\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     response = _request_with_retry(\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/utils/file_utils.py\u001b[0m in \u001b[0;36m_request_with_retry\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, **params)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mtries\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m             \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0;31m# Redirect resolving generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mresolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                 resp = self.send(\n\u001b[0m\u001b[1;32m    266\u001b[0m                     \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"\\nGenerating predictions for the validation dataset...\")\n",
        "val_predictions_base, val_references_base, val_inst_base = generate_predictions(val_dataset, model, tokenizer)\n",
        "print(\"Generating predictions for the test dataset...\")\n",
        "test_predictions_base, test_references_base, test_inst_base = generate_predictions(test_dataset, model, tokenizer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inferenced_data[\"test\"] = [val_predictions_base, val_references_base, val_inst_base]\n",
        "inferenced_data[\"val\"] = [test_predictions_base, test_references_base, test_inst_base]\n",
        "\n",
        "store(inferenced_data, \"./base-inference.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'evaluate' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load if available\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m val_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m(val_predictions_base, val_references_base, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouge\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbleu\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Rouge results:\u001b[39m\u001b[38;5;124m\"\u001b[39m, val_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouge\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation BLEU results:\u001b[39m\u001b[38;5;124m\"\u001b[39m, val_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbleu\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'evaluate' is not defined"
          ]
        }
      ],
      "source": [
        "# load if available\n",
        "\n",
        "\n",
        "val_results = evaluate(val_predictions_base, val_references_base, metrics=[\"rouge\", \"bleu\"])\n",
        "print(\"Validation Rouge results:\", val_results[\"rouge\"])\n",
        "print(\"Validation BLEU results:\", val_results[\"bleu\"])\n",
        "\n",
        "test_results = evaluate(test_predictions_base, test_references_base, metrics=[\"rouge\", \"bleu\"])\n",
        "print(\"Test Rouge results:\", test_results[\"rouge\"])\n",
        "print(\"Test BLEU results:\", test_results[\"bleu\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hallucination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading JSON: ../results/base-inference-r8.json\n",
            "Loading hummus CSV: ../data/pp_recipes.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/1g/st98989x26136dtmmybf9mdc0000gn/T/ipykernel_22720/1015138889.py:38: DtypeWarning: Columns (35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(csv_path, index_col=0, low_memory=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating split: test\n",
            "\n",
            "=== Metrics ===\n",
            "total_examples: 515\n",
            "TP: 14\n",
            "FP: 0\n",
            "FN: 501\n",
            "precision: 1.0\n",
            "recall: 0.027184466019417475\n",
            "f1: 0.05293005671077505\n",
            "hallucination_count: 488\n",
            "hallucination_rate: 0.9475728155339805\n",
            "summary_csv: constraint_evaluation_summary_base.csv\n",
            "\n",
            "Detailed summary saved to constraint_evaluation_summary_base.csv\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# CONFIG - change file names / keys if needed\n",
        "JSON_PATH = \"../results/base-inference-r8.json\"   # <- path to your jsondump\n",
        "CSV_PATH = \"../data/pp_recipes.csv\"          # <- hummus recipes CSV\n",
        "OUTPUT_SUMMARY_CSV = \"constraint_evaluation_summary_base.csv\"\n",
        "\n",
        "# Columns mapping from your description (adjust if different)\n",
        "COLS = {\n",
        "    \"title\": \"title\",\n",
        "    \"calories\": \"calories [cal]\",\n",
        "    \"protein\": \"protein [g]\",\n",
        "    \"sodium\": \"sodium [mg]\",\n",
        "    \"duration\": \"duration\",           # may be string/object - ensure numeric if possible\n",
        "    \"serves\": \"serves\",\n",
        "    \"total_fat\": \"totalFat [g]\",\n",
        "    \"carbs\": \"totalCarbohydrate [g]\",\n",
        "    \"fiber\": \"dietaryFiber [g]\",\n",
        "    \"ingredients\": \"ingredients\"\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# Helper functions\n",
        "# -------------------------\n",
        "def load_inputs(json_path: str) -> Dict[str, Any]:\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "\n",
        "def load_df(csv_path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_path, index_col=0, low_memory=True)\n",
        "    # Normalise title for matching\n",
        "    df[COLS[\"title\"]] = df[COLS[\"title\"]].astype(str).str.strip()\n",
        "    # Try converting numeric columns\n",
        "    for c in [\"calories\", \"protein\", \"sodium\", \"duration\", \"total_fat\", \"carbs\", \"fiber\"]:\n",
        "        colname = COLS.get(c)\n",
        "        if colname in df.columns:\n",
        "            # remove non-numeric and coerce\n",
        "            df[colname] = pd.to_numeric(df[colname].astype(str).str.replace(r\"[^\\d\\.\\-]\", \"\", regex=True), errors=\"coerce\")\n",
        "    # Normalize ingredients column to lowercase string for containment checks\n",
        "    if COLS[\"ingredients\"] in df.columns:\n",
        "        df[COLS[\"ingredients\"]] = df[COLS[\"ingredients\"]].astype(str).str.lower()\n",
        "    return df\n",
        "\n",
        "\n",
        "def extract_title_and_claims(model_output: str) -> Tuple[Optional[str], Dict[str, float], List[str]]:\n",
        "    \"\"\"\n",
        "    Extract a claimed title and numeric claims from model output.\n",
        "    Returns (title, numeric_claims, list_of_mentioned_ingredients)\n",
        "    Numeric claims keys: calories, protein, sodium, duration, serves, fiber, total_fat, carbs\n",
        "    This function uses heuristic regex matching on outputs like:\n",
        "      \"Hummus Delight - 350 calories, 15g protein, ready in 20 minutes.\"\n",
        "      \"Title - Takes 12 minutes, 300.0 calories\"\n",
        "    \"\"\"\n",
        "    claims = {}\n",
        "    ing_list = []\n",
        "\n",
        "    if not isinstance(model_output, str):\n",
        "        return None, claims, ing_list\n",
        "\n",
        "    # Attempt to parse \"Title - ...\" or \"Title: ...\" or \"Title â€” ...\"\n",
        "    m = re.match(r'^\\s*([^\\-\\â€“\\â€”\\:]+?)\\s*(?:[-\\â€“\\â€”\\:])\\s*(.*)$', model_output.strip())\n",
        "    if m:\n",
        "        title = m.group(1).strip()\n",
        "        rest = m.group(2)\n",
        "    else:\n",
        "        # fallback: first token phrase before comma\n",
        "        parts = model_output.split(\",\")\n",
        "        title = parts[0].strip()\n",
        "        rest = \", \".join(parts[1:]) if len(parts) > 1 else \"\"\n",
        "\n",
        "    # numeric captures\n",
        "    # calories: \"350 calories\" or \"350.0 calories\"\n",
        "    mcal = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*(?:calories|cal|kcal)\\b', model_output, flags=re.I)\n",
        "    if mcal:\n",
        "        claims[\"calories\"] = float(mcal.group(1))\n",
        "    # protein: \"15g protein\"\n",
        "    mprot = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*g\\s*(?:protein)\\b', model_output, flags=re.I)\n",
        "    if mprot:\n",
        "        claims[\"protein\"] = float(mprot.group(1))\n",
        "    # sodium: \"180mg sodium\"\n",
        "    msod = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*mg\\s*(?:sodium)\\b', model_output, flags=re.I)\n",
        "    if msod:\n",
        "        claims[\"sodium\"] = float(msod.group(1))\n",
        "    # duration: \"ready in 20 minutes\", \"Takes 12 minutes\"\n",
        "    mtime = re.search(r'(\\d+)\\s*(?:minutes|min|mins)\\b', model_output, flags=re.I)\n",
        "    if mtime:\n",
        "        claims[\"duration\"] = float(mtime.group(1))\n",
        "    # serves: \"serves 4\"\n",
        "    mserves = re.search(r'serves\\s*(\\d+)', model_output, flags=re.I)\n",
        "    if mserves:\n",
        "        claims[\"serves\"] = int(mserves.group(1))\n",
        "    # fiber: \"5g fiber\"\n",
        "    mfib = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*g\\s*(?:dietary fiber|fiber)\\b', model_output, flags=re.I)\n",
        "    if mfib:\n",
        "        claims[\"fiber\"] = float(mfib.group(1))\n",
        "    # total_fat: \"9g fat\"\n",
        "    mfat = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*g\\s*(?:fat)\\b', model_output, flags=re.I)\n",
        "    if mfat:\n",
        "        claims[\"total_fat\"] = float(mfat.group(1))\n",
        "    # carbs: \"30g carbs\"\n",
        "    mcarb = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*g\\s*(?:carb|carbs|carbohydrate|carbohydrates)\\b', model_output, flags=re.I)\n",
        "    if mcarb:\n",
        "        claims[\"carbs\"] = float(mcarb.group(1))\n",
        "\n",
        "    # Extract simple ingredients mentioned like \"Features chickpeas and tahini\"\n",
        "    # Look for \"Features X and Y\" or \"using X and Y\" patterns\n",
        "    ming = re.search(r'(?:features|using|uses|with)\\s+([a-zA-Z0-9\\s\\-\\']+?)\\s*(?:,|\\band\\b|\\.)', model_output, flags=re.I)\n",
        "    if ming:\n",
        "        # split on 'and' or commas\n",
        "        text = ming.group(1)\n",
        "        candidates = re.split(r'\\band\\b|,', text, flags=re.I)\n",
        "        ing_list = [c.strip().lower() for c in candidates if c.strip()]\n",
        "\n",
        "    # fallback: look for \"using X and Y.\" explicit pattern\n",
        "    m2 = re.search(r'using\\s+([^\\.,]+?)\\.', model_output, flags=re.I)\n",
        "    if m2:\n",
        "        parts = re.split(r'\\band\\b|,', m2.group(1))\n",
        "        ing_list = [p.strip().lower() for p in parts if p.strip()]\n",
        "\n",
        "    return title if title else None, claims, ing_list\n",
        "\n",
        "\n",
        "def parse_instruction_to_constraints(instruction: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Given an instruction string (as generated in variants), return a constraints dict.\n",
        "    Supports the variant instruction formats you provided.\n",
        "    \"\"\"\n",
        "    instr = instruction.lower()\n",
        "    constraints = {}\n",
        "\n",
        "    # calories: \"under 400 calories\" or \"around 400 calories\" or \"under 400\"\n",
        "    m = re.search(r'under\\s+(\\d+)', instr)\n",
        "    if m:\n",
        "        constraints[\"calories_max\"] = float(m.group(1))\n",
        "    m2 = re.search(r'around\\s+(\\d+)', instr)\n",
        "    if m2:\n",
        "        val = float(m2.group(1))\n",
        "        # allow +/- 50 calories tolerance for \"around\"\n",
        "        constraints[\"calories_min\"] = max(0.0, val - 50)\n",
        "        constraints[\"calories_max\"] = val + 50\n",
        "\n",
        "    # time-based: \"less than X minutes\"\n",
        "    mtime = re.search(r'less than\\s+(\\d+)\\s*minutes', instr)\n",
        "    if mtime:\n",
        "        constraints[\"duration_max\"] = float(mtime.group(1))\n",
        "\n",
        "    # protein: \"at least Xg protein\" or \"high-protein at least X\"\n",
        "    mprot = re.search(r'at least\\s+(\\d+)\\s*g\\s*protein', instr)\n",
        "    if mprot:\n",
        "        constraints[\"protein_min\"] = float(mprot.group(1))\n",
        "    else:\n",
        "        # \"high-protein recipe with at least 12g protein.\" or \"high-protein with at least 10\"\n",
        "        mprot2 = re.search(r'(\\d+)\\s*g\\s*protein', instr)\n",
        "        if mprot2 and 'high-protein' in instr:\n",
        "            constraints[\"protein_min\"] = float(mprot2.group(1))\n",
        "\n",
        "    # sodium: \"under Xmg sodium\"\n",
        "    msod = re.search(r'under\\s+(\\d+)\\s*mg\\s*sodium', instr)\n",
        "    if msod:\n",
        "        constraints[\"sodium_max\"] = float(msod.group(1))\n",
        "\n",
        "    # ingredient-based: \"using X and Y\"\n",
        "    ming = re.search(r'suggest a recipe using\\s+([a-z0-9\\s\\-\\']+?)\\s+and\\s+([a-z0-9\\s\\-\\']+)', instr)\n",
        "    if ming:\n",
        "        constraints[\"ingredients_include\"] = [ming.group(1).strip(), ming.group(2).strip()]\n",
        "\n",
        "    # fiber: \"at least Xg fiber\" or \"high-fiber at least\"\n",
        "    mf = re.search(r'at least\\s+(\\d+)\\s*g\\s*fiber', instr)\n",
        "    if mf:\n",
        "        constraints[\"fiber_min\"] = float(mf.group(1))\n",
        "    mff = re.search(r'high-fiber.*?(\\d+)', instr)\n",
        "    if mff and \"fiber\" in instr:\n",
        "        constraints[\"fiber_min\"] = float(mff.group(1))\n",
        "\n",
        "    # balanced meal: this is generic -> require calories, protein, total_fat present and between some moderate bounds\n",
        "    if \"balanced meal\" in instr:\n",
        "        constraints[\"balanced\"] = True\n",
        "\n",
        "    # time variant in your code: instruction uses \"less than {duration + 10} minutes\"\n",
        "    mquick = re.search(r'less than\\s+(\\d+)\\s*minutes', instr)\n",
        "    if mquick:\n",
        "        constraints[\"duration_max\"] = float(mquick.group(1))\n",
        "\n",
        "    return constraints\n",
        "\n",
        "\n",
        "def recipe_satisfies_constraints(recipe_row: pd.Series, constraints: Dict[str, Any]) -> bool:\n",
        "    \"\"\"\n",
        "    Returns True if the pandas series (one recipe) satisfies all constraints.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # calories\n",
        "        if \"calories_max\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"calories\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"calories\"]] > constraints[\"calories_max\"]:\n",
        "                return False\n",
        "        if \"calories_min\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"calories\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"calories\"]] < constraints[\"calories_min\"]:\n",
        "                return False\n",
        "        # duration\n",
        "        if \"duration_max\" in constraints:\n",
        "            if COLS[\"duration\"] not in recipe_row or pd.isna(recipe_row[COLS[\"duration\"]]):\n",
        "                return False\n",
        "            if float(recipe_row[COLS[\"duration\"]]) > constraints[\"duration_max\"]:\n",
        "                return False\n",
        "        # protein\n",
        "        if \"protein_min\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"protein\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"protein\"]] < constraints[\"protein_min\"]:\n",
        "                return False\n",
        "        # sodium\n",
        "        if \"sodium_max\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"sodium\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"sodium\"]] > constraints[\"sodium_max\"]:\n",
        "                return False\n",
        "        # ingredients include\n",
        "        if \"ingredients_include\" in constraints:\n",
        "            ing_field = recipe_row.get(COLS[\"ingredients\"], \"\")\n",
        "            if not isinstance(ing_field, str):\n",
        "                return False\n",
        "            ing_field_low = ing_field.lower()\n",
        "            for ing in constraints[\"ingredients_include\"]:\n",
        "                if ing.lower() not in ing_field_low:\n",
        "                    return False\n",
        "        # fiber\n",
        "        if \"fiber_min\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"fiber\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"fiber\"]] < constraints[\"fiber_min\"]:\n",
        "                return False\n",
        "        # balanced: require numeric calories/protein/total_fat exists; simple heuristics\n",
        "        if constraints.get(\"balanced\"):\n",
        "            if any(pd.isna(recipe_row.get(COLS.get(k), None)) for k in [\"calories\", \"protein\", \"total_fat\"]):\n",
        "                return False\n",
        "            # require moderate calories <= 700 and protein >= 10\n",
        "            if recipe_row[COLS[\"calories\"]] > 700:\n",
        "                return False\n",
        "            if recipe_row[COLS[\"protein\"]] < 8:\n",
        "                return False\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        # if any unexpected error, return False\n",
        "        return False\n",
        "\n",
        "\n",
        "def find_any_matching_recipe(df: pd.DataFrame, constraints: Dict[str, Any]) -> Optional[pd.Series]:\n",
        "    \"\"\"\n",
        "    Returns first matching recipe row (as Series) that satisfies constraints, or None.\n",
        "    \"\"\"\n",
        "    # quick vectorized filter approach\n",
        "    mask = pd.Series(True, index=df.index)\n",
        "\n",
        "    if \"calories_max\" in constraints and COLS[\"calories\"] in df.columns:\n",
        "        mask &= df[COLS[\"calories\"]].fillna(np.inf) <= constraints[\"calories_max\"]\n",
        "    if \"calories_min\" in constraints and COLS[\"calories\"] in df.columns:\n",
        "        mask &= df[COLS[\"calories\"]].fillna(-np.inf) >= constraints[\"calories_min\"]\n",
        "    if \"duration_max\" in constraints and COLS[\"duration\"] in df.columns:\n",
        "        mask &= df[COLS[\"duration\"]].fillna(np.inf) <= constraints[\"duration_max\"]\n",
        "    if \"protein_min\" in constraints and COLS[\"protein\"] in df.columns:\n",
        "        mask &= df[COLS[\"protein\"]].fillna(-np.inf) >= constraints[\"protein_min\"]\n",
        "    if \"sodium_max\" in constraints and COLS[\"sodium\"] in df.columns:\n",
        "        mask &= df[COLS[\"sodium\"]].fillna(np.inf) <= constraints[\"sodium_max\"]\n",
        "    if \"fiber_min\" in constraints and COLS[\"fiber\"] in df.columns:\n",
        "        mask &= df[COLS[\"fiber\"]].fillna(-np.inf) >= constraints[\"fiber_min\"]\n",
        "    if \"ingredients_include\" in constraints and COLS[\"ingredients\"] in df.columns:\n",
        "        for ing in constraints[\"ingredients_include\"]:\n",
        "            mask &= df[COLS[\"ingredients\"]].str.contains(ing.lower(), na=False)\n",
        "\n",
        "    # balanced: apply heuristic\n",
        "    if constraints.get(\"balanced\"):\n",
        "        mask &= df[COLS[\"calories\"]].fillna(np.inf) <= 700\n",
        "        mask &= df[COLS[\"protein\"]].fillna(-np.inf) >= 8\n",
        "        mask &= df[COLS[\"total_fat\"]].fillna(-np.inf) > 0\n",
        "\n",
        "    filtered = df[mask]\n",
        "    if len(filtered) == 0:\n",
        "        return None\n",
        "    return filtered.iloc[0]\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Main evaluation\n",
        "# -------------------------\n",
        "def evaluate(inferenced_data: Dict[str, Any], df: pd.DataFrame, split_key: str = \"test\"):\n",
        "    \"\"\"\n",
        "    Expects inferenced_data[split_key] to be [predictions_list, references_list, instructions_list]\n",
        "    Each element in predictions_list corresponds to a model output. In your variant setup, you might\n",
        "    have predictions as lists of variants per recipe; we attempt to handle either flat lists or nested.\n",
        "    \"\"\"\n",
        "    preds, refs, insts = inferenced_data[split_key]\n",
        "\n",
        "    # Normalize lists: if preds is a dict or nested list-of-lists, flatten into per-variant instruction objects.\n",
        "    # We'll assume 'insts' is parallel: each entry may contain 'variants' list (per your earlier generation),\n",
        "    # or insts may already be the list of generated 'instruction' strings.\n",
        "    # We'll construct a list of dicts: { \"instruction\": ..., \"output\": ... }\n",
        "    records = []\n",
        "\n",
        "    # Case A: you saved a structure of variants per example (list of dicts with \"instruction\" and \"output\")\n",
        "    # We'll detect types and normalize.\n",
        "    if isinstance(preds, list) and len(preds) > 0 and isinstance(preds[0], dict) and 'output' in preds[0]:\n",
        "        # already normalized predictions as dicts\n",
        "        normalized = preds\n",
        "    else:\n",
        "        # Attempt to pair insts and preds element-wise\n",
        "        normalized = []\n",
        "        # If preds entries are lists of outputs per example and insts are lists of variants (list-of-dicts)\n",
        "        if isinstance(preds, list) and len(preds) == len(insts):\n",
        "            for p, i in zip(preds, insts):\n",
        "                # If i is list of variant dicts\n",
        "                if isinstance(i, list):\n",
        "                    # each variant has instruction + output but model output might be in p list in same order\n",
        "                    # Best effort: if p is list with same length, pair them; otherwise assume p is single str\n",
        "                    if isinstance(p, list) and len(p) == len(i):\n",
        "                        for out, var in zip(p, i):\n",
        "                            normalized.append({\"instruction\": var.get(\"instruction\") if isinstance(var, dict) else str(var),\n",
        "                                               \"output\": out})\n",
        "                    else:\n",
        "                        # pair each variant instruction with same p (string)\n",
        "                        for var in i:\n",
        "                            normalized.append({\"instruction\": var.get(\"instruction\") if isinstance(var, dict) else str(var),\n",
        "                                               \"output\": p if isinstance(p, str) else str(p)})\n",
        "                else:\n",
        "                    # i is a single instruction string\n",
        "                    normalized.append({\"instruction\": i, \"output\": p})\n",
        "        else:\n",
        "            # fallback: if insts is list of variant dicts\n",
        "            if isinstance(insts, list):\n",
        "                for entry in insts:\n",
        "                    if isinstance(entry, dict) and 'instruction' in entry and 'output' in entry:\n",
        "                        normalized.append({\"instruction\": entry['instruction'], \"output\": entry['output']})\n",
        "                    elif isinstance(entry, dict) and 'instruction' in entry:\n",
        "                        normalized.append({\"instruction\": entry['instruction'], \"output\": \"\"})\n",
        "                    else:\n",
        "                        # can't interpret; make best-effort\n",
        "                        normalized.append({\"instruction\": str(entry), \"output\": \"\"})\n",
        "            else:\n",
        "                raise ValueError(\"Unable to normalize predictions/instructions structure. Inspect your inferenced_data format.\")\n",
        "\n",
        "    # Now evaluate each normalized pair\n",
        "    for item in normalized:\n",
        "        instruction = item.get(\"instruction\", \"\")\n",
        "        output = item.get(\"output\", \"\")\n",
        "        title, claims, mentioned_ings = extract_title_and_claims(output)\n",
        "        constraints = parse_instruction_to_constraints(instruction)\n",
        "\n",
        "        title_present = False\n",
        "        recipe_row = None\n",
        "        if title:\n",
        "            # try exact or case-insensitive match in df titles\n",
        "            matches = df[df[COLS[\"title\"]].str.lower() == title.lower()]\n",
        "            if len(matches) == 0:\n",
        "                # try substring match\n",
        "                matches = df[df[COLS[\"title\"]].str.lower().str.contains(re.escape(title.lower()), na=False)]\n",
        "            if len(matches) > 0:\n",
        "                title_present = True\n",
        "                recipe_row = matches.iloc[0]\n",
        "\n",
        "        # Check if the title's referenced recipe (if present) satisfies constraints\n",
        "        satisfied_by_returned = False\n",
        "        if title_present and recipe_row is not None and constraints:\n",
        "            satisfied_by_returned = recipe_satisfies_constraints(recipe_row, constraints)\n",
        "        elif title_present and (not constraints):\n",
        "            # if no constraints parsed, consider it satisfied_by_returned = True (no constraint)\n",
        "            satisfied_by_returned = True\n",
        "\n",
        "        # Check whether any recipe in dataset satisfies constraints (for recall/TP/FN)\n",
        "        any_matching = True if not constraints else (find_any_matching_recipe(df, constraints) is not None)\n",
        "\n",
        "        # Hallucination: title not found in dataset\n",
        "        hallucinated = not title_present\n",
        "\n",
        "        records.append({\n",
        "            \"instruction\": instruction,\n",
        "            \"model_output\": output,\n",
        "            \"parsed_title\": title,\n",
        "            \"title_in_dataset\": title_present,\n",
        "            \"satisfied_by_returned\": satisfied_by_returned,\n",
        "            \"dataset_has_any_matching\": any_matching,\n",
        "            \"hallucinated\": hallucinated,\n",
        "            \"constraints\": constraints,\n",
        "            \"claims\": claims,\n",
        "            \"mentioned_ingredients\": mentioned_ings\n",
        "        })\n",
        "\n",
        "    # Compute metrics:\n",
        "    TP = 0  # dataset has a matching recipe AND model returned an example that satisfied constraints\n",
        "    FP = 0  # model returned a recipe that DOES NOT satisfy constraints OR hallucination where dataset had none\n",
        "    FN = 0  # dataset has a matching recipe but model either returned non-matching recipe or hallucinated/no answer\n",
        "\n",
        "    for r in records:\n",
        "        if r[\"dataset_has_any_matching\"]:\n",
        "            # ground truth: there exists an example satisfying constraints\n",
        "            if r[\"title_in_dataset\"] and r[\"satisfied_by_returned\"]:\n",
        "                TP += 1\n",
        "            else:\n",
        "                FN += 1\n",
        "        else:\n",
        "            # dataset has no matching recipe\n",
        "            if r[\"title_in_dataset\"]:\n",
        "                # model returned a recipe (but dataset actually doesn't have matching recipe!) -> FP\n",
        "                FP += 1\n",
        "            else:\n",
        "                # model did not return any recipe (and none exists): true negative (not used in precision/recall)\n",
        "                pass\n",
        "\n",
        "    # Another kind of FP: returned a recipe but it didn't satisfy constraints (even though dataset has matching recipe).\n",
        "    # The above counts that as FN (because dataset_has_any_matching true and model didn't return matching) â€” acceptable.\n",
        "    # Also count hallucinated returns (title not present) as FP when dataset_has_any_matching is False or True\n",
        "    # For clarity compute hallucination rate:\n",
        "    total_outputs = len(records)\n",
        "    halluc_count = sum(1 for r in records if r[\"hallucinated\"])\n",
        "    halluc_rate = halluc_count / total_outputs if total_outputs > 0 else 0.0\n",
        "\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    summary_df = pd.DataFrame(records)\n",
        "    summary_df.to_csv(OUTPUT_SUMMARY_CSV, index=False)\n",
        "\n",
        "    metrics = {\n",
        "        \"total_examples\": total_outputs,\n",
        "        \"TP\": TP,\n",
        "        \"FP\": FP,\n",
        "        \"FN\": FN,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"hallucination_count\": halluc_count,\n",
        "        \"hallucination_rate\": halluc_rate,\n",
        "        \"summary_csv\": OUTPUT_SUMMARY_CSV\n",
        "    }\n",
        "\n",
        "    return summary_df, metrics\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Entry point\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Load files\n",
        "    print(\"Loading JSON:\", JSON_PATH)\n",
        "    inferenced = load_inputs(JSON_PATH)\n",
        "    print(\"Loading hummus CSV:\", CSV_PATH)\n",
        "    df = load_df(CSV_PATH)\n",
        "\n",
        "    # Choose split to evaluate - 'test' or 'val' - modify if needed\n",
        "    split_to_eval = \"test\"\n",
        "    if split_to_eval not in inferenced:\n",
        "        # fallback to 'val' or first key\n",
        "        if \"val\" in inferenced:\n",
        "            split_to_eval = \"val\"\n",
        "        else:\n",
        "            split_to_eval = list(inferenced.keys())[0]\n",
        "\n",
        "    print(f\"Evaluating split: {split_to_eval}\")\n",
        "    summary_df, metrics = evaluate(inferenced, df, split_key=split_to_eval)\n",
        "\n",
        "    print(\"\\n=== Metrics ===\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "    print(f\"\\nDetailed summary saved to {metrics['summary_csv']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhuARhQyD16Z"
      },
      "source": [
        "# Fine-tined model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "74fdbb26d293465d9215fe333d55fffd",
            "6975eb7347354a25a572d384466f2c88",
            "360723bbb6ec4817908f269e3b1c7915",
            "72549f8f32a149d18731c0d87ead602e",
            "6d64d877880b4c92a690458256bce02f",
            "a282541f31c740f7b88f51ade8f24447",
            "311a459f497049a1a342ce1b3c66ff81",
            "7ea22621877845d59125b30262598bf9",
            "e20e3316865e4a53bf6b97bb8744c50b",
            "eaa0e847a5f04b21941ba7aa28354133",
            "9068008ac7ec4bc9b98d4ef626ce99c8"
          ]
        },
        "id": "rkL0AtHAGAnM",
        "outputId": "cfe3338e-2bb6-47e0-bd1e-6b95c5d6c171"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.10.12: Fast Llama patching. Transformers: 4.55.4.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74fdbb26d293465d9215fe333d55fffd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/83.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the model and tokenizer from the Hugging Face Hub\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"azimidokht/recipe-recom-fine-tuned\",  # your HF repo\n",
        "    max_seq_length = 2048,  # or the same you used during training\n",
        "    dtype = None,           # or \"float16\"/\"bfloat16\" depending on your GPU\n",
        "    load_in_4bit = True,    # set to True if you trained/quantized with 4-bit\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1NMYUSsD4s8",
        "outputId": "e3f662ff-33c1-405c-c597-8dbbc409f70d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating predictions for the validation dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 515/515 [18:59<00:00,  2.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating predictions for the test dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 515/515 [18:49<00:00,  2.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Rouge results: {'rouge1': np.float64(0.40453685922545124), 'rouge2': np.float64(0.14331750751282368), 'rougeL': np.float64(0.3867874845240147), 'rougeLsum': np.float64(0.38656809820506405)}\n",
            "Validation BLEU results: {'bleu': 0.18616916303170597, 'precisions': [0.578895096213532, 0.33156498673740054, 0.12156583629893239, 0.060829493087557605], 'brevity_penalty': 0.9591448031459188, 'length_ratio': 0.9599570968895245, 'translation_length': 8055, 'reference_length': 8391}\n",
            "Test Rouge results: {'rouge1': np.float64(0.3961609293564492), 'rouge2': np.float64(0.1340261275115724), 'rougeL': np.float64(0.3781028237338431), 'rougeLsum': np.float64(0.37816379311891846)}\n",
            "Test BLEU results: {'bleu': 0.1753465742384433, 'precisions': [0.5765054294175715, 0.32468045855843986, 0.11082838563754595, 0.05320933069065406], 'brevity_penalty': 0.9619947380591407, 'length_ratio': 0.9626989783796627, 'translation_length': 8104, 'reference_length': 8418}\n"
          ]
        }
      ],
      "source": [
        "inferenced_data_tuned = {}\n",
        "\n",
        "print(\"\\nGenerating predictions for the validation dataset...\")\n",
        "val_predictions_tuned, val_references_tuned, val_inst_tuned = generate_predictions(val_dataset, model, tokenizer)\n",
        "print(\"Generating predictions for the test dataset...\")\n",
        "test_predictions_tuned, test_references_tuned, test_inst_tuned = generate_predictions(test_dataset, model, tokenizer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JReTGUO-NhvP"
      },
      "outputs": [],
      "source": [
        "inferenced_data_tuned[\"test\"] = [val_predictions_tuned, val_references_tuned, val_inst_tuned]\n",
        "inferenced_data_tuned[\"val\"] = [test_predictions_tuned, test_references_tuned, test_inst_tuned]\n",
        "\n",
        "store(inferenced_data_tuned, \"./fine-tuned-inference-r8.json\")\n",
        "\n",
        "val_results_tuned = evaluate(val_predictions_tuned, val_references_tuned, metrics=[\"rouge\", \"bleu\"])\n",
        "print(\"Validation Rouge results:\", val_results_tuned[\"rouge\"])\n",
        "print(\"Validation BLEU results:\", val_results_tuned[\"bleu\"])\n",
        "\n",
        "test_results_tuned = evaluate(test_predictions_tuned, test_references_tuned, metrics=[\"rouge\", \"bleu\"])\n",
        "print(\"Test Rouge results:\", test_results_tuned[\"rouge\"])\n",
        "print(\"Test BLEU results:\", test_results_tuned[\"bleu\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading JSON: ../results/fine-tuned-inference-r8.json\n",
            "Loading hummus CSV: ../data/pp_recipes.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/1g/st98989x26136dtmmybf9mdc0000gn/T/ipykernel_13743/1361165452.py:38: DtypeWarning: Columns (35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(csv_path, index_col=0, low_memory=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating split: test\n",
            "\n",
            "=== Metrics ===\n",
            "total_examples: 515\n",
            "TP: 172\n",
            "FP: 0\n",
            "FN: 343\n",
            "precision: 1.0\n",
            "recall: 0.3339805825242718\n",
            "f1: 0.5007278020378456\n",
            "hallucination_count: 121\n",
            "hallucination_rate: 0.23495145631067962\n",
            "summary_csv: constraint_evaluation_summary.csv\n",
            "\n",
            "Detailed summary saved to constraint_evaluation_summary.csv\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# CONFIG - change file names / keys if needed\n",
        "JSON_PATH = \"../results/fine-tuned-inference-r8.json\"   # <- path to your jsondump\n",
        "CSV_PATH = \"../data/pp_recipes.csv\"          # <- hummus recipes CSV\n",
        "OUTPUT_SUMMARY_CSV = \"constraint_evaluation_summary.csv\"\n",
        "\n",
        "# Columns mapping from your description (adjust if different)\n",
        "COLS = {\n",
        "    \"title\": \"title\",\n",
        "    \"calories\": \"calories [cal]\",\n",
        "    \"protein\": \"protein [g]\",\n",
        "    \"sodium\": \"sodium [mg]\",\n",
        "    \"duration\": \"duration\",           # may be string/object - ensure numeric if possible\n",
        "    \"serves\": \"serves\",\n",
        "    \"total_fat\": \"totalFat [g]\",\n",
        "    \"carbs\": \"totalCarbohydrate [g]\",\n",
        "    \"fiber\": \"dietaryFiber [g]\",\n",
        "    \"ingredients\": \"ingredients\"\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# Helper functions\n",
        "# -------------------------\n",
        "def load_inputs(json_path: str) -> Dict[str, Any]:\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "\n",
        "def load_df(csv_path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_path, index_col=0, low_memory=True)\n",
        "    # Normalise title for matching\n",
        "    df[COLS[\"title\"]] = df[COLS[\"title\"]].astype(str).str.strip()\n",
        "    # Try converting numeric columns\n",
        "    for c in [\"calories\", \"protein\", \"sodium\", \"duration\", \"total_fat\", \"carbs\", \"fiber\"]:\n",
        "        colname = COLS.get(c)\n",
        "        if colname in df.columns:\n",
        "            # remove non-numeric and coerce\n",
        "            df[colname] = pd.to_numeric(df[colname].astype(str).str.replace(r\"[^\\d\\.\\-]\", \"\", regex=True), errors=\"coerce\")\n",
        "    # Normalize ingredients column to lowercase string for containment checks\n",
        "    if COLS[\"ingredients\"] in df.columns:\n",
        "        df[COLS[\"ingredients\"]] = df[COLS[\"ingredients\"]].astype(str).str.lower()\n",
        "    return df\n",
        "\n",
        "\n",
        "def extract_title_and_claims(model_output: str) -> Tuple[Optional[str], Dict[str, float], List[str]]:\n",
        "    \"\"\"\n",
        "    Extract a claimed title and numeric claims from model output.\n",
        "    Returns (title, numeric_claims, list_of_mentioned_ingredients)\n",
        "    Numeric claims keys: calories, protein, sodium, duration, serves, fiber, total_fat, carbs\n",
        "    This function uses heuristic regex matching on outputs like:\n",
        "      \"Hummus Delight - 350 calories, 15g protein, ready in 20 minutes.\"\n",
        "      \"Title - Takes 12 minutes, 300.0 calories\"\n",
        "    \"\"\"\n",
        "    claims = {}\n",
        "    ing_list = []\n",
        "\n",
        "    if not isinstance(model_output, str):\n",
        "        return None, claims, ing_list\n",
        "\n",
        "    # Attempt to parse \"Title - ...\" or \"Title: ...\" or \"Title â€” ...\"\n",
        "    m = re.match(r'^\\s*([^\\-\\â€“\\â€”\\:]+?)\\s*(?:[-\\â€“\\â€”\\:])\\s*(.*)$', model_output.strip())\n",
        "    if m:\n",
        "        title = m.group(1).strip()\n",
        "        rest = m.group(2)\n",
        "    else:\n",
        "        # fallback: first token phrase before comma\n",
        "        parts = model_output.split(\",\")\n",
        "        title = parts[0].strip()\n",
        "        rest = \", \".join(parts[1:]) if len(parts) > 1 else \"\"\n",
        "\n",
        "    # numeric captures\n",
        "    # calories: \"350 calories\" or \"350.0 calories\"\n",
        "    mcal = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*(?:calories|cal|kcal)\\b', model_output, flags=re.I)\n",
        "    if mcal:\n",
        "        claims[\"calories\"] = float(mcal.group(1))\n",
        "    # protein: \"15g protein\"\n",
        "    mprot = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*g\\s*(?:protein)\\b', model_output, flags=re.I)\n",
        "    if mprot:\n",
        "        claims[\"protein\"] = float(mprot.group(1))\n",
        "    # sodium: \"180mg sodium\"\n",
        "    msod = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*mg\\s*(?:sodium)\\b', model_output, flags=re.I)\n",
        "    if msod:\n",
        "        claims[\"sodium\"] = float(msod.group(1))\n",
        "    # duration: \"ready in 20 minutes\", \"Takes 12 minutes\"\n",
        "    mtime = re.search(r'(\\d+)\\s*(?:minutes|min|mins)\\b', model_output, flags=re.I)\n",
        "    if mtime:\n",
        "        claims[\"duration\"] = float(mtime.group(1))\n",
        "    # serves: \"serves 4\"\n",
        "    mserves = re.search(r'serves\\s*(\\d+)', model_output, flags=re.I)\n",
        "    if mserves:\n",
        "        claims[\"serves\"] = int(mserves.group(1))\n",
        "    # fiber: \"5g fiber\"\n",
        "    mfib = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*g\\s*(?:dietary fiber|fiber)\\b', model_output, flags=re.I)\n",
        "    if mfib:\n",
        "        claims[\"fiber\"] = float(mfib.group(1))\n",
        "    # total_fat: \"9g fat\"\n",
        "    mfat = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*g\\s*(?:fat)\\b', model_output, flags=re.I)\n",
        "    if mfat:\n",
        "        claims[\"total_fat\"] = float(mfat.group(1))\n",
        "    # carbs: \"30g carbs\"\n",
        "    mcarb = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*g\\s*(?:carb|carbs|carbohydrate|carbohydrates)\\b', model_output, flags=re.I)\n",
        "    if mcarb:\n",
        "        claims[\"carbs\"] = float(mcarb.group(1))\n",
        "\n",
        "    # Extract simple ingredients mentioned like \"Features chickpeas and tahini\"\n",
        "    # Look for \"Features X and Y\" or \"using X and Y\" patterns\n",
        "    ming = re.search(r'(?:features|using|uses|with)\\s+([a-zA-Z0-9\\s\\-\\']+?)\\s*(?:,|\\band\\b|\\.)', model_output, flags=re.I)\n",
        "    if ming:\n",
        "        # split on 'and' or commas\n",
        "        text = ming.group(1)\n",
        "        candidates = re.split(r'\\band\\b|,', text, flags=re.I)\n",
        "        ing_list = [c.strip().lower() for c in candidates if c.strip()]\n",
        "\n",
        "    # fallback: look for \"using X and Y.\" explicit pattern\n",
        "    m2 = re.search(r'using\\s+([^\\.,]+?)\\.', model_output, flags=re.I)\n",
        "    if m2:\n",
        "        parts = re.split(r'\\band\\b|,', m2.group(1))\n",
        "        ing_list = [p.strip().lower() for p in parts if p.strip()]\n",
        "\n",
        "    return title if title else None, claims, ing_list\n",
        "\n",
        "\n",
        "def parse_instruction_to_constraints(instruction: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Given an instruction string (as generated in variants), return a constraints dict.\n",
        "    Supports the variant instruction formats you provided.\n",
        "    \"\"\"\n",
        "    instr = instruction.lower()\n",
        "    constraints = {}\n",
        "\n",
        "    # calories: \"under 400 calories\" or \"around 400 calories\" or \"under 400\"\n",
        "    m = re.search(r'under\\s+(\\d+)', instr)\n",
        "    if m:\n",
        "        constraints[\"calories_max\"] = float(m.group(1))\n",
        "    m2 = re.search(r'around\\s+(\\d+)', instr)\n",
        "    if m2:\n",
        "        val = float(m2.group(1))\n",
        "        # allow +/- 50 calories tolerance for \"around\"\n",
        "        constraints[\"calories_min\"] = max(0.0, val - 50)\n",
        "        constraints[\"calories_max\"] = val + 50\n",
        "\n",
        "    # time-based: \"less than X minutes\"\n",
        "    mtime = re.search(r'less than\\s+(\\d+)\\s*minutes', instr)\n",
        "    if mtime:\n",
        "        constraints[\"duration_max\"] = float(mtime.group(1))\n",
        "\n",
        "    # protein: \"at least Xg protein\" or \"high-protein at least X\"\n",
        "    mprot = re.search(r'at least\\s+(\\d+)\\s*g\\s*protein', instr)\n",
        "    if mprot:\n",
        "        constraints[\"protein_min\"] = float(mprot.group(1))\n",
        "    else:\n",
        "        # \"high-protein recipe with at least 12g protein.\" or \"high-protein with at least 10\"\n",
        "        mprot2 = re.search(r'(\\d+)\\s*g\\s*protein', instr)\n",
        "        if mprot2 and 'high-protein' in instr:\n",
        "            constraints[\"protein_min\"] = float(mprot2.group(1))\n",
        "\n",
        "    # sodium: \"under Xmg sodium\"\n",
        "    msod = re.search(r'under\\s+(\\d+)\\s*mg\\s*sodium', instr)\n",
        "    if msod:\n",
        "        constraints[\"sodium_max\"] = float(msod.group(1))\n",
        "\n",
        "    # ingredient-based: \"using X and Y\"\n",
        "    ming = re.search(r'suggest a recipe using\\s+([a-z0-9\\s\\-\\']+?)\\s+and\\s+([a-z0-9\\s\\-\\']+)', instr)\n",
        "    if ming:\n",
        "        constraints[\"ingredients_include\"] = [ming.group(1).strip(), ming.group(2).strip()]\n",
        "\n",
        "    # fiber: \"at least Xg fiber\" or \"high-fiber at least\"\n",
        "    mf = re.search(r'at least\\s+(\\d+)\\s*g\\s*fiber', instr)\n",
        "    if mf:\n",
        "        constraints[\"fiber_min\"] = float(mf.group(1))\n",
        "    mff = re.search(r'high-fiber.*?(\\d+)', instr)\n",
        "    if mff and \"fiber\" in instr:\n",
        "        constraints[\"fiber_min\"] = float(mff.group(1))\n",
        "\n",
        "    # balanced meal: this is generic -> require calories, protein, total_fat present and between some moderate bounds\n",
        "    if \"balanced meal\" in instr:\n",
        "        constraints[\"balanced\"] = True\n",
        "\n",
        "    # time variant in your code: instruction uses \"less than {duration + 10} minutes\"\n",
        "    mquick = re.search(r'less than\\s+(\\d+)\\s*minutes', instr)\n",
        "    if mquick:\n",
        "        constraints[\"duration_max\"] = float(mquick.group(1))\n",
        "\n",
        "    return constraints\n",
        "\n",
        "\n",
        "def recipe_satisfies_constraints(recipe_row: pd.Series, constraints: Dict[str, Any]) -> bool:\n",
        "    \"\"\"\n",
        "    Returns True if the pandas series (one recipe) satisfies all constraints.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # calories\n",
        "        if \"calories_max\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"calories\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"calories\"]] > constraints[\"calories_max\"]:\n",
        "                return False\n",
        "        if \"calories_min\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"calories\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"calories\"]] < constraints[\"calories_min\"]:\n",
        "                return False\n",
        "        # duration\n",
        "        if \"duration_max\" in constraints:\n",
        "            if COLS[\"duration\"] not in recipe_row or pd.isna(recipe_row[COLS[\"duration\"]]):\n",
        "                return False\n",
        "            if float(recipe_row[COLS[\"duration\"]]) > constraints[\"duration_max\"]:\n",
        "                return False\n",
        "        # protein\n",
        "        if \"protein_min\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"protein\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"protein\"]] < constraints[\"protein_min\"]:\n",
        "                return False\n",
        "        # sodium\n",
        "        if \"sodium_max\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"sodium\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"sodium\"]] > constraints[\"sodium_max\"]:\n",
        "                return False\n",
        "        # ingredients include\n",
        "        if \"ingredients_include\" in constraints:\n",
        "            ing_field = recipe_row.get(COLS[\"ingredients\"], \"\")\n",
        "            if not isinstance(ing_field, str):\n",
        "                return False\n",
        "            ing_field_low = ing_field.lower()\n",
        "            for ing in constraints[\"ingredients_include\"]:\n",
        "                if ing.lower() not in ing_field_low:\n",
        "                    return False\n",
        "        # fiber\n",
        "        if \"fiber_min\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"fiber\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"fiber\"]] < constraints[\"fiber_min\"]:\n",
        "                return False\n",
        "        # balanced: require numeric calories/protein/total_fat exists; simple heuristics\n",
        "        if constraints.get(\"balanced\"):\n",
        "            if any(pd.isna(recipe_row.get(COLS.get(k), None)) for k in [\"calories\", \"protein\", \"total_fat\"]):\n",
        "                return False\n",
        "            # require moderate calories <= 700 and protein >= 10\n",
        "            if recipe_row[COLS[\"calories\"]] > 700:\n",
        "                return False\n",
        "            if recipe_row[COLS[\"protein\"]] < 8:\n",
        "                return False\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        # if any unexpected error, return False\n",
        "        return False\n",
        "\n",
        "\n",
        "def find_any_matching_recipe(df: pd.DataFrame, constraints: Dict[str, Any]) -> Optional[pd.Series]:\n",
        "    \"\"\"\n",
        "    Returns first matching recipe row (as Series) that satisfies constraints, or None.\n",
        "    \"\"\"\n",
        "    # quick vectorized filter approach\n",
        "    mask = pd.Series(True, index=df.index)\n",
        "\n",
        "    if \"calories_max\" in constraints and COLS[\"calories\"] in df.columns:\n",
        "        mask &= df[COLS[\"calories\"]].fillna(np.inf) <= constraints[\"calories_max\"]\n",
        "    if \"calories_min\" in constraints and COLS[\"calories\"] in df.columns:\n",
        "        mask &= df[COLS[\"calories\"]].fillna(-np.inf) >= constraints[\"calories_min\"]\n",
        "    if \"duration_max\" in constraints and COLS[\"duration\"] in df.columns:\n",
        "        mask &= df[COLS[\"duration\"]].fillna(np.inf) <= constraints[\"duration_max\"]\n",
        "    if \"protein_min\" in constraints and COLS[\"protein\"] in df.columns:\n",
        "        mask &= df[COLS[\"protein\"]].fillna(-np.inf) >= constraints[\"protein_min\"]\n",
        "    if \"sodium_max\" in constraints and COLS[\"sodium\"] in df.columns:\n",
        "        mask &= df[COLS[\"sodium\"]].fillna(np.inf) <= constraints[\"sodium_max\"]\n",
        "    if \"fiber_min\" in constraints and COLS[\"fiber\"] in df.columns:\n",
        "        mask &= df[COLS[\"fiber\"]].fillna(-np.inf) >= constraints[\"fiber_min\"]\n",
        "    if \"ingredients_include\" in constraints and COLS[\"ingredients\"] in df.columns:\n",
        "        for ing in constraints[\"ingredients_include\"]:\n",
        "            mask &= df[COLS[\"ingredients\"]].str.contains(ing.lower(), na=False)\n",
        "\n",
        "    # balanced: apply heuristic\n",
        "    if constraints.get(\"balanced\"):\n",
        "        mask &= df[COLS[\"calories\"]].fillna(np.inf) <= 700\n",
        "        mask &= df[COLS[\"protein\"]].fillna(-np.inf) >= 8\n",
        "        mask &= df[COLS[\"total_fat\"]].fillna(-np.inf) > 0\n",
        "\n",
        "    filtered = df[mask]\n",
        "    if len(filtered) == 0:\n",
        "        return None\n",
        "    return filtered.iloc[0]\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Main evaluation\n",
        "# -------------------------\n",
        "def evaluate(inferenced_data: Dict[str, Any], df: pd.DataFrame, split_key: str = \"test\"):\n",
        "    \"\"\"\n",
        "    Expects inferenced_data[split_key] to be [predictions_list, references_list, instructions_list]\n",
        "    Each element in predictions_list corresponds to a model output. In your variant setup, you might\n",
        "    have predictions as lists of variants per recipe; we attempt to handle either flat lists or nested.\n",
        "    \"\"\"\n",
        "    preds, refs, insts = inferenced_data[split_key]\n",
        "\n",
        "    # Normalize lists: if preds is a dict or nested list-of-lists, flatten into per-variant instruction objects.\n",
        "    # We'll assume 'insts' is parallel: each entry may contain 'variants' list (per your earlier generation),\n",
        "    # or insts may already be the list of generated 'instruction' strings.\n",
        "    # We'll construct a list of dicts: { \"instruction\": ..., \"output\": ... }\n",
        "    records = []\n",
        "\n",
        "    # Case A: you saved a structure of variants per example (list of dicts with \"instruction\" and \"output\")\n",
        "    # We'll detect types and normalize.\n",
        "    if isinstance(preds, list) and len(preds) > 0 and isinstance(preds[0], dict) and 'output' in preds[0]:\n",
        "        # already normalized predictions as dicts\n",
        "        normalized = preds\n",
        "    else:\n",
        "        # Attempt to pair insts and preds element-wise\n",
        "        normalized = []\n",
        "        # If preds entries are lists of outputs per example and insts are lists of variants (list-of-dicts)\n",
        "        if isinstance(preds, list) and len(preds) == len(insts):\n",
        "            for p, i in zip(preds, insts):\n",
        "                # If i is list of variant dicts\n",
        "                if isinstance(i, list):\n",
        "                    # each variant has instruction + output but model output might be in p list in same order\n",
        "                    # Best effort: if p is list with same length, pair them; otherwise assume p is single str\n",
        "                    if isinstance(p, list) and len(p) == len(i):\n",
        "                        for out, var in zip(p, i):\n",
        "                            normalized.append({\"instruction\": var.get(\"instruction\") if isinstance(var, dict) else str(var),\n",
        "                                               \"output\": out})\n",
        "                    else:\n",
        "                        # pair each variant instruction with same p (string)\n",
        "                        for var in i:\n",
        "                            normalized.append({\"instruction\": var.get(\"instruction\") if isinstance(var, dict) else str(var),\n",
        "                                               \"output\": p if isinstance(p, str) else str(p)})\n",
        "                else:\n",
        "                    # i is a single instruction string\n",
        "                    normalized.append({\"instruction\": i, \"output\": p})\n",
        "        else:\n",
        "            # fallback: if insts is list of variant dicts\n",
        "            if isinstance(insts, list):\n",
        "                for entry in insts:\n",
        "                    if isinstance(entry, dict) and 'instruction' in entry and 'output' in entry:\n",
        "                        normalized.append({\"instruction\": entry['instruction'], \"output\": entry['output']})\n",
        "                    elif isinstance(entry, dict) and 'instruction' in entry:\n",
        "                        normalized.append({\"instruction\": entry['instruction'], \"output\": \"\"})\n",
        "                    else:\n",
        "                        # can't interpret; make best-effort\n",
        "                        normalized.append({\"instruction\": str(entry), \"output\": \"\"})\n",
        "            else:\n",
        "                raise ValueError(\"Unable to normalize predictions/instructions structure. Inspect your inferenced_data format.\")\n",
        "\n",
        "    # Now evaluate each normalized pair\n",
        "    for item in normalized:\n",
        "        instruction = item.get(\"instruction\", \"\")\n",
        "        output = item.get(\"output\", \"\")\n",
        "        title, claims, mentioned_ings = extract_title_and_claims(output)\n",
        "        constraints = parse_instruction_to_constraints(instruction)\n",
        "\n",
        "        title_present = False\n",
        "        recipe_row = None\n",
        "        if title:\n",
        "            # try exact or case-insensitive match in df titles\n",
        "            matches = df[df[COLS[\"title\"]].str.lower() == title.lower()]\n",
        "            if len(matches) == 0:\n",
        "                # try substring match\n",
        "                matches = df[df[COLS[\"title\"]].str.lower().str.contains(re.escape(title.lower()), na=False)]\n",
        "            if len(matches) > 0:\n",
        "                title_present = True\n",
        "                recipe_row = matches.iloc[0]\n",
        "\n",
        "        # Check if the title's referenced recipe (if present) satisfies constraints\n",
        "        satisfied_by_returned = False\n",
        "        if title_present and recipe_row is not None and constraints:\n",
        "            satisfied_by_returned = recipe_satisfies_constraints(recipe_row, constraints)\n",
        "        elif title_present and (not constraints):\n",
        "            # if no constraints parsed, consider it satisfied_by_returned = True (no constraint)\n",
        "            satisfied_by_returned = True\n",
        "\n",
        "        # Check whether any recipe in dataset satisfies constraints (for recall/TP/FN)\n",
        "        any_matching = True if not constraints else (find_any_matching_recipe(df, constraints) is not None)\n",
        "\n",
        "        # Hallucination: title not found in dataset\n",
        "        hallucinated = not title_present\n",
        "\n",
        "        records.append({\n",
        "            \"instruction\": instruction,\n",
        "            \"model_output\": output,\n",
        "            \"parsed_title\": title,\n",
        "            \"title_in_dataset\": title_present,\n",
        "            \"satisfied_by_returned\": satisfied_by_returned,\n",
        "            \"dataset_has_any_matching\": any_matching,\n",
        "            \"hallucinated\": hallucinated,\n",
        "            \"constraints\": constraints,\n",
        "            \"claims\": claims,\n",
        "            \"mentioned_ingredients\": mentioned_ings\n",
        "        })\n",
        "\n",
        "    # Compute metrics:\n",
        "    TP = 0  # dataset has a matching recipe AND model returned an example that satisfied constraints\n",
        "    FP = 0  # model returned a recipe that DOES NOT satisfy constraints OR hallucination where dataset had none\n",
        "    FN = 0  # dataset has a matching recipe but model either returned non-matching recipe or hallucinated/no answer\n",
        "\n",
        "    for r in records:\n",
        "        if r[\"dataset_has_any_matching\"]:\n",
        "            # ground truth: there exists an example satisfying constraints\n",
        "            if r[\"title_in_dataset\"] and r[\"satisfied_by_returned\"]:\n",
        "                TP += 1\n",
        "            else:\n",
        "                FN += 1\n",
        "        else:\n",
        "            # dataset has no matching recipe\n",
        "            if r[\"title_in_dataset\"]:\n",
        "                # model returned a recipe (but dataset actually doesn't have matching recipe!) -> FP\n",
        "                FP += 1\n",
        "            else:\n",
        "                # model did not return any recipe (and none exists): true negative (not used in precision/recall)\n",
        "                pass\n",
        "\n",
        "    # Another kind of FP: returned a recipe but it didn't satisfy constraints (even though dataset has matching recipe).\n",
        "    # The above counts that as FN (because dataset_has_any_matching true and model didn't return matching) â€” acceptable.\n",
        "    # Also count hallucinated returns (title not present) as FP when dataset_has_any_matching is False or True\n",
        "    # For clarity compute hallucination rate:\n",
        "    total_outputs = len(records)\n",
        "    halluc_count = sum(1 for r in records if r[\"hallucinated\"])\n",
        "    halluc_rate = halluc_count / total_outputs if total_outputs > 0 else 0.0\n",
        "\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    summary_df = pd.DataFrame(records)\n",
        "    summary_df.to_csv(OUTPUT_SUMMARY_CSV, index=False)\n",
        "\n",
        "    metrics = {\n",
        "        \"total_examples\": total_outputs,\n",
        "        \"TP\": TP,\n",
        "        \"FP\": FP,\n",
        "        \"FN\": FN,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"hallucination_count\": halluc_count,\n",
        "        \"hallucination_rate\": halluc_rate,\n",
        "        \"summary_csv\": OUTPUT_SUMMARY_CSV\n",
        "    }\n",
        "\n",
        "    return summary_df, metrics\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Entry point\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Load files\n",
        "    print(\"Loading JSON:\", JSON_PATH)\n",
        "    inferenced = load_inputs(JSON_PATH)\n",
        "    print(\"Loading hummus CSV:\", CSV_PATH)\n",
        "    df = load_df(CSV_PATH)\n",
        "\n",
        "    # Choose split to evaluate - 'test' or 'val' - modify if needed\n",
        "    split_to_eval = \"test\"\n",
        "    if split_to_eval not in inferenced:\n",
        "        # fallback to 'val' or first key\n",
        "        if \"val\" in inferenced:\n",
        "            split_to_eval = \"val\"\n",
        "        else:\n",
        "            split_to_eval = list(inferenced.keys())[0]\n",
        "\n",
        "    print(f\"Evaluating split: {split_to_eval}\")\n",
        "    summary_df, metrics = evaluate(inferenced, df, split_key=split_to_eval)\n",
        "\n",
        "    print(\"\\n=== Metrics ===\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "    print(f\"\\nDetailed summary saved to {metrics['summary_csv']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Post processing the tuned model outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Post-processing helpers\n",
        "# -------------------------\n",
        "def claims_close_enough(claims: Dict[str, float], recipe_row: pd.Series, tolerances: Dict[str, float]) -> bool:\n",
        "    \"\"\"\n",
        "    Return True if all numeric claims present are within tolerances of recipe_row values.\n",
        "    tolerances: relative (fraction) or absolute values depending on key.\n",
        "      e.g. {\"calories\": 0.10, \"protein\": 0.20, \"sodium\": 0.25, \"duration\": 2}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        for k, v in claims.items():\n",
        "            col = COLS.get(k)\n",
        "            if col is None or col not in recipe_row or pd.isna(recipe_row[col]):\n",
        "                # cannot compare, treat as not close\n",
        "                return False\n",
        "            truth = float(recipe_row[col])\n",
        "            # choose relative tolerance for calories/protein/sodium/carbs/fat/fiber; absolute for duration/serves\n",
        "            if k in {\"calories\", \"protein\", \"sodium\", \"carbs\", \"total_fat\", \"fiber\"}:\n",
        "                rel_tol = tolerances.get(k, 0.2)  # default 20%\n",
        "                if truth == 0:\n",
        "                    if abs(v - truth) > 1e-6:\n",
        "                        return False\n",
        "                else:\n",
        "                    if abs(v - truth) / (truth if truth != 0 else 1.0) > rel_tol:\n",
        "                        return False\n",
        "            elif k in {\"duration\", \"serves\"}:\n",
        "                abs_tol = tolerances.get(k, 5)  # default 5 minutes / servings tolerance\n",
        "                if abs(float(v) - truth) > abs_tol:\n",
        "                    return False\n",
        "            else:\n",
        "                # unknown key: conservatively require equality-ish\n",
        "                if abs(float(v) - truth) > 1e-6:\n",
        "                    return False\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def format_recipe_facts(recipe_row: pd.Series) -> Dict[str, Any]:\n",
        "    \"\"\"Return a dict of printable facts from recipe_row for insertion into corrected output.\"\"\"\n",
        "    out = {}\n",
        "    for key in [\"calories\", \"protein\", \"sodium\", \"duration\", \"serves\", \"fiber\", \"total_fat\", \"carbs\"]:\n",
        "        col = COLS.get(key)\n",
        "        if col and col in recipe_row and not pd.isna(recipe_row[col]):\n",
        "            out[key] = recipe_row[col]\n",
        "    # ingredients: string\n",
        "    if COLS[\"ingredients\"] in recipe_row and isinstance(recipe_row[COLS[\"ingredients\"]], str):\n",
        "        out[\"ingredients\"] = recipe_row[COLS[\"ingredients\"]]\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_corrected_output(original_output: str, corrected_title: str, facts: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    Build a readable corrected output string. Keep it simple and consistent.\n",
        "    Example: \"Hummus Classic - 350 calories, 12g protein, 180mg sodium, ready in 20 minutes. Ingredients: chickpeas, tahini, lemon...\"\n",
        "    \"\"\"\n",
        "    parts = []\n",
        "    if corrected_title:\n",
        "        parts.append(corrected_title)\n",
        "    factuals = []\n",
        "    if \"calories\" in facts:\n",
        "        factuals.append(f\"{int(round(facts['calories']))} calories\")\n",
        "    if \"protein\" in facts:\n",
        "        factuals.append(f\"{round(float(facts['protein']), 1)}g protein\")\n",
        "    if \"sodium\" in facts:\n",
        "        factuals.append(f\"{int(round(facts['sodium']))}mg sodium\")\n",
        "    if \"duration\" in facts:\n",
        "        factuals.append(f\"ready in {int(round(facts['duration']))} minutes\")\n",
        "    if \"serves\" in facts:\n",
        "        factuals.append(f\"serves {int(round(facts['serves']))}\")\n",
        "    if factuals:\n",
        "        parts.append(\" - \".join([parts.pop(0), \", \".join(factuals)]))  # join title with facts\n",
        "    if \"ingredients\" in facts:\n",
        "        parts.append(f\"Ingredients: {facts['ingredients']}\")\n",
        "    # If nothing to show, return original\n",
        "    return \". \".join(parts) if parts else original_output\n",
        "\n",
        "\n",
        "def find_and_return_dataset_recipe_for_constraints(df: pd.DataFrame, constraints: Dict[str, Any]) -> Optional[pd.Series]:\n",
        "    \"\"\"\n",
        "    Uses your existing find_any_matching_recipe to pick a recipe. Returns full recipe row or None.\n",
        "    \"\"\"\n",
        "    return find_any_matching_recipe(df, constraints)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "OUTPUT_SUMMARY_CSV = \"constraint_evaluation_summary_postprocess.csv\"\n",
        "import numbers\n",
        "\n",
        "def to_number(x):\n",
        "    \"\"\"\n",
        "    Try to coerce x to a number (int or float).\n",
        "    Accepts numeric types, strings with commas, units, etc.\n",
        "    Returns a float if possible, otherwise returns None.\n",
        "    \"\"\"\n",
        "    if x is None:\n",
        "        return None\n",
        "    # If it's already a numeric type (numpy/pandas numbers included)\n",
        "    if isinstance(x, numbers.Number):\n",
        "        try:\n",
        "            return float(x)\n",
        "        except Exception:\n",
        "            return None\n",
        "    # If it's a string, strip common noise and parse\n",
        "    s = str(x).strip()\n",
        "    if s == \"\":\n",
        "        return None\n",
        "    # Remove common words/units like 'servings', 'mins', 'minutes', 'g', 'mg', 'calories', etc.\n",
        "    s = re.sub(r'(?i)\\b(serves?|servings?|minutes|min|mins|g|mg|kcal|calories?|grams?)\\b', '', s)\n",
        "    # Remove parentheses and percent signs\n",
        "    s = re.sub(r'[\\(\\)\\%\\s]', '', s)\n",
        "    # Replace comma thousand separators like \"1,200\" -> \"1200\"\n",
        "    s = s.replace(',', '')\n",
        "    # Final safe numeric match: allow leading +/-, digits, optional decimal\n",
        "    m = re.match(r'^[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?$', s)\n",
        "    if not m:\n",
        "        return None\n",
        "    try:\n",
        "        return float(s)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def format_recipe_facts(recipe_row: pd.Series, debug: bool = False) -> Dict[str, Any]:\n",
        "    \"\"\"Return a dict of printable facts from recipe_row for insertion into corrected output.\n",
        "       Convert string fields to numeric where appropriate using to_number().\n",
        "    \"\"\"\n",
        "    out: Dict[str, Any] = {}\n",
        "    for key in [\"calories\", \"protein\", \"sodium\", \"duration\", \"serves\", \"fiber\", \"total_fat\", \"carbs\"]:\n",
        "        col = COLS.get(key)\n",
        "        if col and col in recipe_row:\n",
        "            val = recipe_row[col]\n",
        "            num = to_number(val)\n",
        "            if num is not None:\n",
        "                # keep as float for generality; callers will format as int/rounded as needed\n",
        "                out[key] = num\n",
        "            else:\n",
        "                # if we couldn't parse as number, optionally keep raw string for ingredients etc.\n",
        "                if isinstance(val, str) and val.strip() != \"\":\n",
        "                    out[key] = val.strip()\n",
        "                else:\n",
        "                    # skip missing/unparseable\n",
        "                    if debug:\n",
        "                        print(f\"[debug] could not parse field {col!r} value: {val!r}\")\n",
        "    # ingredients: keep textual form (lowercase already or preserve original)\n",
        "    if COLS[\"ingredients\"] in recipe_row and isinstance(recipe_row[COLS[\"ingredients\"]], str):\n",
        "        out[\"ingredients\"] = recipe_row[COLS[\"ingredients\"]].strip()\n",
        "    # Title might be useful too\n",
        "    if COLS[\"title\"] in recipe_row and isinstance(recipe_row[COLS[\"title\"]], str):\n",
        "        out[\"title\"] = recipe_row[COLS[\"title\"]].strip()\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_corrected_output(original_output: str, corrected_title: str, facts: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    Build a readable corrected output string safely.\n",
        "    - Accepts facts where numeric fields may be numeric or (rarely) strings.\n",
        "    - Will not crash if a value is missing or unparseable.\n",
        "    \"\"\"\n",
        "    # Use title argument primarily; fallback to facts['title'] if provided\n",
        "    title = corrected_title or facts.get(\"title\", None)\n",
        "    parts = []\n",
        "    if title:\n",
        "        parts.append(str(title))\n",
        "\n",
        "    factuals = []\n",
        "    # calories (display as integer)\n",
        "    if \"calories\" in facts:\n",
        "        try:\n",
        "            cal = facts[\"calories\"]\n",
        "            cal_num = float(cal)\n",
        "            factuals.append(f\"{int(round(cal_num))} calories\")\n",
        "        except Exception:\n",
        "            factuals.append(f\"calories: {facts['calories']}\")\n",
        "    # protein (1 decimal)\n",
        "    if \"protein\" in facts:\n",
        "        try:\n",
        "            prot = float(facts[\"protein\"])\n",
        "            factuals.append(f\"{round(prot, 1)}g protein\")\n",
        "        except Exception:\n",
        "            factuals.append(f\"protein: {facts['protein']}\")\n",
        "    # sodium (integer mg)\n",
        "    if \"sodium\" in facts:\n",
        "        try:\n",
        "            sod = float(facts[\"sodium\"])\n",
        "            factuals.append(f\"{int(round(sod))}mg sodium\")\n",
        "        except Exception:\n",
        "            factuals.append(f\"sodium: {facts['sodium']}\")\n",
        "    # duration\n",
        "    if \"duration\" in facts:\n",
        "        try:\n",
        "            dur = float(facts[\"duration\"])\n",
        "            factuals.append(f\"ready in {int(round(dur))} minutes\")\n",
        "        except Exception:\n",
        "            factuals.append(f\"duration: {facts['duration']}\")\n",
        "    # serves\n",
        "    if \"serves\" in facts:\n",
        "        try:\n",
        "            s = float(facts[\"serves\"])\n",
        "            factuals.append(f\"serves {int(round(s))}\")\n",
        "        except Exception:\n",
        "            factuals.append(f\"serves: {facts['serves']}\")\n",
        "    # fiber\n",
        "    if \"fiber\" in facts:\n",
        "        try:\n",
        "            f = float(facts[\"fiber\"])\n",
        "            factuals.append(f\"{round(f, 1)}g fiber\")\n",
        "        except Exception:\n",
        "            factuals.append(f\"fiber: {facts['fiber']}\")\n",
        "    # total_fat\n",
        "    if \"total_fat\" in facts:\n",
        "        try:\n",
        "            tf = float(facts[\"total_fat\"])\n",
        "            factuals.append(f\"{round(tf, 1)}g fat\")\n",
        "        except Exception:\n",
        "            factuals.append(f\"fat: {facts['total_fat']}\")\n",
        "    # carbs\n",
        "    if \"carbs\" in facts:\n",
        "        try:\n",
        "            cb = float(facts[\"carbs\"])\n",
        "            factuals.append(f\"{round(cb, 1)}g carbs\")\n",
        "        except Exception:\n",
        "            factuals.append(f\"carbs: {facts['carbs']}\")\n",
        "\n",
        "    # Join title + facts nicely:\n",
        "    if factuals:\n",
        "        if parts:\n",
        "            # combine title and facts\n",
        "            # result: \"Title - <comma separated factuals>\"\n",
        "            joined = \", \".join(factuals)\n",
        "            parts = [f\"{parts[0]} - {joined}\"]\n",
        "        else:\n",
        "            parts = [\", \".join(factuals)]\n",
        "\n",
        "    # Ingredients last\n",
        "    if \"ingredients\" in facts and facts[\"ingredients\"]:\n",
        "        parts.append(f\"Ingredients: {facts['ingredients']}\")\n",
        "\n",
        "    # If nothing was generated, return original output to be safe\n",
        "    return \". \".join(parts) if parts else original_output\n",
        "\n",
        "\n",
        "\n",
        "def find_and_return_dataset_recipe_for_constraints(\n",
        "    df: pd.DataFrame, constraints: Dict[str, Any]\n",
        ") -> Optional[pd.Series]:\n",
        "    \"\"\"\n",
        "    Uses your existing find_any_matching_recipe to pick a recipe. Returns full recipe row or None.\n",
        "    \"\"\"\n",
        "    return find_any_matching_recipe(df, constraints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def evaluate(inferenced_data: Dict[str, Any], df: pd.DataFrame, split_key: str = \"test\"):\n",
        "    \"\"\"\n",
        "    Expects inferenced_data[split_key] to be [predictions_list, references_list, instructions_list]\n",
        "    Each element in predictions_list corresponds to a model output. In your variant setup, you might\n",
        "    have predictions as lists of variants per recipe; we attempt to handle either flat lists or nested.\n",
        "    \"\"\"\n",
        "    preds, refs, insts = inferenced_data[split_key]\n",
        "\n",
        "    # Normalize lists: if preds is a dict or nested list-of-lists, flatten into per-variant instruction objects.\n",
        "    # We'll assume 'insts' is parallel: each entry may contain 'variants' list (per your earlier generation),\n",
        "    # or insts may already be the list of generated 'instruction' strings.\n",
        "    # We'll construct a list of dicts: { \"instruction\": ..., \"output\": ... }\n",
        "    records = []\n",
        "\n",
        "    # Case A: you saved a structure of variants per example (list of dicts with \"instruction\" and \"output\")\n",
        "    # We'll detect types and normalize.\n",
        "    if isinstance(preds, list) and len(preds) > 0 and isinstance(preds[0], dict) and 'output' in preds[0]:\n",
        "        # already normalized predictions as dicts\n",
        "        normalized = preds\n",
        "    else:\n",
        "        # Attempt to pair insts and preds element-wise\n",
        "        normalized = []\n",
        "        # If preds entries are lists of outputs per example and insts are lists of variants (list-of-dicts)\n",
        "        if isinstance(preds, list) and len(preds) == len(insts):\n",
        "            for p, i in zip(preds, insts):\n",
        "                # If i is list of variant dicts\n",
        "                if isinstance(i, list):\n",
        "                    # each variant has instruction + output but model output might be in p list in same order\n",
        "                    # Best effort: if p is list with same length, pair them; otherwise assume p is single str\n",
        "                    if isinstance(p, list) and len(p) == len(i):\n",
        "                        for out, var in zip(p, i):\n",
        "                            normalized.append({\"instruction\": var.get(\"instruction\") if isinstance(var, dict) else str(var),\n",
        "                                               \"output\": out})\n",
        "                    else:\n",
        "                        # pair each variant instruction with same p (string)\n",
        "                        for var in i:\n",
        "                            normalized.append({\"instruction\": var.get(\"instruction\") if isinstance(var, dict) else str(var),\n",
        "                                               \"output\": p if isinstance(p, str) else str(p)})\n",
        "                else:\n",
        "                    # i is a single instruction string\n",
        "                    normalized.append({\"instruction\": i, \"output\": p})\n",
        "        else:\n",
        "            # fallback: if insts is list of variant dicts\n",
        "            if isinstance(insts, list):\n",
        "                for entry in insts:\n",
        "                    if isinstance(entry, dict) and 'instruction' in entry and 'output' in entry:\n",
        "                        normalized.append({\"instruction\": entry['instruction'], \"output\": entry['output']})\n",
        "                    elif isinstance(entry, dict) and 'instruction' in entry:\n",
        "                        normalized.append({\"instruction\": entry['instruction'], \"output\": \"\"})\n",
        "                    else:\n",
        "                        # can't interpret; make best-effort\n",
        "                        normalized.append({\"instruction\": str(entry), \"output\": \"\"})\n",
        "            else:\n",
        "                raise ValueError(\"Unable to normalize predictions/instructions structure. Inspect your inferenced_data format.\")\n",
        "\n",
        "    # Now evaluate each normalized pair\n",
        "    for item in normalized:\n",
        "        instruction = item.get(\"instruction\", \"\")\n",
        "        output = item.get(\"output\", \"\")\n",
        "        # --- existing parsing ---\n",
        "        title, claims, mentioned_ings = extract_title_and_claims(output)\n",
        "        constraints = parse_instruction_to_constraints(instruction)\n",
        "\n",
        "        title_present = False\n",
        "        recipe_row = None\n",
        "        if title:\n",
        "            matches = df[df[COLS[\"title\"]].str.lower() == title.lower()]\n",
        "            if len(matches) == 0:\n",
        "                matches = df[df[COLS[\"title\"]].str.lower().str.contains(re.escape(title.lower()), na=False)]\n",
        "            if len(matches) > 0:\n",
        "                title_present = True\n",
        "                recipe_row = matches.iloc[0]\n",
        "\n",
        "        # Check if the title's referenced recipe (if present) satisfies constraints\n",
        "        satisfied_by_returned = False\n",
        "        if title_present and recipe_row is not None and constraints:\n",
        "            satisfied_by_returned = recipe_satisfies_constraints(recipe_row, constraints)\n",
        "        elif title_present and (not constraints):\n",
        "            satisfied_by_returned = True\n",
        "\n",
        "        any_matching = True if not constraints else (find_any_matching_recipe(df, constraints) is not None)\n",
        "        hallucinated = not title_present\n",
        "\n",
        "        # -------------------------\n",
        "        # POST-PROCESSING DECISION\n",
        "        # -------------------------\n",
        "        corrected_output = output\n",
        "        correction_type = None     # e.g., \"fix_claims\", \"replace_with_dataset\", None\n",
        "        correction_reason = None\n",
        "\n",
        "        # tolerances (you can tune these)\n",
        "        tolerances = {\n",
        "            \"calories\": 0.10,   # 10% relative\n",
        "            \"protein\": 0.20,    # 20%\n",
        "            \"sodium\": 0.25,     # 25%\n",
        "            \"duration\": 3,      # +/- 3 minutes absolute\n",
        "            \"serves\": 1\n",
        "        }\n",
        "\n",
        "        if title_present and recipe_row is not None:\n",
        "            # If model referenced an existing title: check if numeric claims align with dataset\n",
        "            if claims:\n",
        "                if not claims_close_enough(claims, recipe_row, tolerances):\n",
        "                    # Replace numeric facts with dataset facts\n",
        "                    facts = format_recipe_facts(recipe_row)\n",
        "                    corrected_output = build_corrected_output(output, recipe_row[COLS[\"title\"]], facts)\n",
        "                    correction_type = \"fix_claims\"\n",
        "                    correction_reason = \"model numeric claims diverged from dataset values\"\n",
        "            # If model returned title and there were no numeric claims, optionally we could augment with dataset facts.\n",
        "            else:\n",
        "                # Optionally add dataset facts to enrich the output (uncomment if desired)\n",
        "                # facts = format_recipe_facts(recipe_row)\n",
        "                # corrected_output = build_corrected_output(output, recipe_row[COLS[\"title\"]], facts)\n",
        "                pass\n",
        "\n",
        "        elif hallucinated and constraints:\n",
        "            # Model hallucinated title. If dataset contains a recipe that satisfies parsed constraints,\n",
        "            # replace output with that recipe's true facts.\n",
        "            candidate = find_any_matching_recipe(df, constraints)\n",
        "            if candidate is not None:\n",
        "                facts = format_recipe_facts(candidate)\n",
        "                corrected_output = build_corrected_output(output, candidate[COLS[\"title\"]], facts)\n",
        "                correction_type = \"replace_with_dataset\"\n",
        "                correction_reason = \"model hallucinated title but dataset had recipe matching constraints\"\n",
        "            else:\n",
        "                # Nothing to correct: dataset doesn't have matching recipe\n",
        "                pass\n",
        "\n",
        "        # add entry to records including corrected_output and correction flags\n",
        "        records.append({\n",
        "            \"instruction\": instruction,\n",
        "            \"model_output\": output,\n",
        "            \"parsed_title\": title,\n",
        "            \"title_in_dataset\": title_present,\n",
        "            \"satisfied_by_returned\": satisfied_by_returned,\n",
        "            \"dataset_has_any_matching\": any_matching,\n",
        "            \"hallucinated\": hallucinated,\n",
        "            \"constraints\": constraints,\n",
        "            \"claims\": claims,\n",
        "            \"mentioned_ingredients\": mentioned_ings,\n",
        "            \"corrected_output\": corrected_output,\n",
        "            \"correction_type\": correction_type,\n",
        "            \"correction_reason\": correction_reason\n",
        "        })\n",
        "    # --- Compute summary metrics ---\n",
        "    metrics = {}\n",
        "    if not summary_df.empty:\n",
        "        metrics[\"num_samples\"] = len(summary_df)\n",
        "        metrics[\"num_hallucinated\"] = int(summary_df[\"hallucinated\"].sum())\n",
        "        metrics[\"hallucination_rate\"] = metrics[\"num_hallucinated\"] / len(summary_df)\n",
        "\n",
        "        if \"correction_type\" in summary_df:\n",
        "            metrics[\"num_corrected\"] = int(summary_df[\"correction_type\"].notna().sum())\n",
        "            metrics[\"correction_rate\"] = metrics[\"num_corrected\"] / len(summary_df)\n",
        "\n",
        "        if \"satisfied_by_returned\" in summary_df:\n",
        "            metrics[\"constraint_satisfaction_rate\"] = (\n",
        "                summary_df[\"satisfied_by_returned\"].mean()\n",
        "            )\n",
        "\n",
        "        metrics[\"dataset_match_rate\"] = summary_df[\"title_in_dataset\"].mean()\n",
        "    else:\n",
        "        metrics = {\n",
        "            \"num_samples\": 0,\n",
        "            \"num_hallucinated\": 0,\n",
        "            \"hallucination_rate\": 0.0,\n",
        "            \"correction_rate\": 0.0,\n",
        "            \"constraint_satisfaction_rate\": 0.0,\n",
        "            \"dataset_match_rate\": 0.0,\n",
        "        }\n",
        "    # save results to CSV\n",
        "    summary_csv_path = f\"evaluation_summary_{split_key}.csv\"\n",
        "    summary_df.to_csv(summary_csv_path, index=False)\n",
        "\n",
        "    # add file path to metrics\n",
        "    metrics[\"summary_csv\"] = summary_csv_path\n",
        "    # âœ… Return both\n",
        "    return summary_df, metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading JSON: ../results/base-inference-r8.json\n",
            "Loading hummus CSV: ../data/pp_recipes.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/1g/st98989x26136dtmmybf9mdc0000gn/T/ipykernel_22720/1015138889.py:38: DtypeWarning: Columns (35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(csv_path, index_col=0, low_memory=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating split: test\n",
            "\n",
            "=== Metrics ===\n",
            "num_samples: 515\n",
            "num_hallucinated: 488\n",
            "hallucination_rate: 0.9475728155339805\n",
            "constraint_satisfaction_rate: 0.027184466019417475\n",
            "dataset_match_rate: 0.05242718446601942\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'summary_csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDetailed summary saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msummary_csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'summary_csv'"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Load files\n",
        "    print(\"Loading JSON:\", JSON_PATH)\n",
        "    inferenced = load_inputs(JSON_PATH)\n",
        "    print(\"Loading hummus CSV:\", CSV_PATH)\n",
        "    df = load_df(CSV_PATH)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating split: test\n",
            "\n",
            "=== Metrics ===\n",
            "num_samples: 515\n",
            "num_hallucinated: 488\n",
            "hallucination_rate: 0.9475728155339805\n",
            "constraint_satisfaction_rate: 0.027184466019417475\n",
            "dataset_match_rate: 0.05242718446601942\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'summary_csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDetailed summary saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msummary_csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'summary_csv'"
          ]
        }
      ],
      "source": [
        "# Choose split to evaluate - 'test' or 'val' - modify if needed\n",
        "split_to_eval = \"test\"\n",
        "if split_to_eval not in inferenced:\n",
        "    # fallback to 'val' or first key\n",
        "    if \"val\" in inferenced:\n",
        "        split_to_eval = \"val\"\n",
        "    else:\n",
        "        split_to_eval = list(inferenced.keys())[0]\n",
        "\n",
        "print(f\"Evaluating split: {split_to_eval}\")\n",
        "summary_df, metrics = evaluate(inferenced, df, split_key=split_to_eval)\n",
        "\n",
        "print(\"\\n=== Metrics ===\")\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "print(f\"\\nDetailed summary saved to {metrics['summary_csv']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading JSON: ../results/fine-tuned-inference-r8.json\n",
            "Loading CSV: ../data/pp_recipes.csv\n",
            "Evaluating split: test\n",
            "\n",
            "=== Metrics ===\n",
            "total_examples: 515\n",
            "hallucination_count: 0\n",
            "hallucination_rate: 0.0\n",
            "corrected_count: 514\n",
            "satisfied_by_returned_count: 208\n",
            "title_in_dataset_count: 511\n",
            "summary_csv: constraint_evaluation_summary.csv\n",
            "corrected_csv: constraint_evaluation_summary_corrected.csv\n",
            "\n",
            "Detailed summary saved to constraint_evaluation_summary.csv\n",
            "Corrected summary saved to constraint_evaluation_summary_corrected.csv\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List, Tuple, Optional\n",
        "import numbers\n",
        "import difflib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------\n",
        "# CONFIG - change paths / thresholds here\n",
        "# -------------------------\n",
        "JSON_PATH = \"../results/fine-tuned-inference-r8.json\"\n",
        "CSV_PATH = \"../data/pp_recipes.csv\"\n",
        "OUTPUT_SUMMARY_CSV = \"constraint_evaluation_summary.csv\"\n",
        "OUTPUT_CORRECTED_CSV = \"constraint_evaluation_summary_corrected.csv\"\n",
        "\n",
        "# fuzzy title match threshold (0..1) - lower => more permissive\n",
        "FUZZY_TITLE_THRESH = 0.78\n",
        "\n",
        "# tolerances used to decide if numeric claims are 'close enough' to dataset truth\n",
        "DEFAULT_TOLERANCES = {\n",
        "    \"calories\": 0.12,   # 12% relative\n",
        "    \"protein\": 0.25,    # 25%\n",
        "    \"sodium\": 0.30,     # 30%\n",
        "    \"carbs\": 0.20,\n",
        "    \"total_fat\": 0.30,\n",
        "    \"fiber\": 0.30,\n",
        "    \"duration\": 4,      # absolute minutes\n",
        "    \"serves\": 1         # absolute servings\n",
        "}\n",
        "\n",
        "# Column mapping from your dataset\n",
        "COLS = {\n",
        "    \"title\": \"title\",\n",
        "    \"calories\": \"calories [cal]\",\n",
        "    \"protein\": \"protein [g]\",\n",
        "    \"sodium\": \"sodium [mg]\",\n",
        "    \"duration\": \"duration\",\n",
        "    \"serves\": \"serves\",\n",
        "    \"total_fat\": \"totalFat [g]\",\n",
        "    \"carbs\": \"totalCarbohydrate [g]\",\n",
        "    \"fiber\": \"dietaryFiber [g]\",\n",
        "    \"ingredients\": \"ingredients\"\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# I/O & preprocessing\n",
        "# -------------------------\n",
        "def load_inputs(json_path: str) -> Dict[str, Any]:\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "\n",
        "def _clean_numeric_string(s: str) -> str:\n",
        "    # Remove wrapped units but keep numeric signs and decimal and comma that we will remove later\n",
        "    if not isinstance(s, str):\n",
        "        return s\n",
        "    s2 = re.sub(r'(?i)\\b(calories?|kcal|g|mg|grams?|minutes|min|mins|serves?|servings?)\\b', '', s)\n",
        "    return s2\n",
        "\n",
        "\n",
        "def to_number(x):\n",
        "    \"\"\"\n",
        "    Try to coerce x to a float. Accepts numeric types, strings with commas, units, etc.\n",
        "    Returns float or None.\n",
        "    \"\"\"\n",
        "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
        "        return None\n",
        "    if isinstance(x, numbers.Number):\n",
        "        try:\n",
        "            return float(x)\n",
        "        except Exception:\n",
        "            return None\n",
        "    s = str(x).strip()\n",
        "    if s == \"\":\n",
        "        return None\n",
        "    # Remove common words/units and parentheses\n",
        "    s = _clean_numeric_string(s)\n",
        "    s = re.sub(r'[\\(\\)\\%]', '', s)\n",
        "    # strip letters left, keep digits, decimal and exponent\n",
        "    s = s.replace(',', '')\n",
        "    m = re.search(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?', s)\n",
        "    if not m:\n",
        "        return None\n",
        "    num_s = m.group(0)\n",
        "    try:\n",
        "        return float(num_s)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_df(csv_path: str) -> pd.DataFrame:\n",
        "    # read and try to coerce numeric columns; keep raw ingredients as string\n",
        "    df = pd.read_csv(csv_path, index_col=None, low_memory=False)\n",
        "    # normalize title\n",
        "    if COLS[\"title\"] in df.columns:\n",
        "        df[COLS[\"title\"]] = df[COLS[\"title\"]].astype(str).str.strip()\n",
        "\n",
        "    # coerce known numeric columns using to_number so we handle odd strings\n",
        "    for key in [\"calories\", \"protein\", \"sodium\", \"duration\", \"serves\", \"total_fat\", \"carbs\", \"fiber\"]:\n",
        "        col = COLS.get(key)\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].apply(lambda v: to_number(v))\n",
        "\n",
        "    # normalize ingredients to lowercase string\n",
        "    if COLS[\"ingredients\"] in df.columns:\n",
        "        df[COLS[\"ingredients\"]] = df[COLS[\"ingredients\"]].astype(str).str.lower()\n",
        "    return df\n",
        "\n",
        "# -------------------------\n",
        "# Parsing model outputs\n",
        "# -------------------------\n",
        "def extract_title_and_claims(model_output: str) -> Tuple[Optional[str], Dict[str, float], List[str]]:\n",
        "    \"\"\"\n",
        "    Heuristic extraction:\n",
        "      - Title: common separators '-', ':' or 'â€”' or linebreak; or first clause before a dash/colon/comma\n",
        "      - Numeric claims: calories, protein, sodium, duration, serves, fiber, total_fat, carbs\n",
        "      - Mentioned simple ingredients from 'with', 'using', 'featuring', 'contains'\n",
        "    \"\"\"\n",
        "    claims = {}\n",
        "    ing_list = []\n",
        "    if not isinstance(model_output, str) or model_output.strip() == \"\":\n",
        "        return None, claims, ing_list\n",
        "\n",
        "    # pick title heuristically: try \"Title - ...\" then fallback to first clause\n",
        "    s = model_output.strip()\n",
        "    # if there's an explicit quoted title \"Hummus Classic\"\n",
        "    q = re.search(r'[\"â€œâ€](.+?)[\"â€œâ€]', s)\n",
        "    if q:\n",
        "        title = q.group(1).strip()\n",
        "    else:\n",
        "        m = re.match(r'^\\s*([^\\-\\â€“\\â€”\\:]+?)\\s*(?:[-\\â€“\\â€”\\:])\\s*(.*)$', s)\n",
        "        if m:\n",
        "            title = m.group(1).strip()\n",
        "        else:\n",
        "            # fallback to first clause before comma or newline\n",
        "            parts = re.split(r'[\\n,]', s)\n",
        "            title = parts[0].strip()\n",
        "\n",
        "    # robust numeric searches (allow thousand separators, decimals)\n",
        "    def _num_search(pattern, key, postproc=lambda x: float(x)):\n",
        "        m = re.search(pattern, s, flags=re.I)\n",
        "        if m:\n",
        "            raw = m.group(1).replace(',', '').strip()\n",
        "            try:\n",
        "                claims[key] = float(raw)\n",
        "            except Exception:\n",
        "                # fallback parse via to_number\n",
        "                n = to_number(m.group(1))\n",
        "                if n is not None:\n",
        "                    claims[key] = n\n",
        "\n",
        "    # calories\n",
        "    _num_search(r'([-\\d\\.,]+)\\s*(?:calories|cal|kcal)\\b', \"calories\")\n",
        "    # protein grams\n",
        "    _num_search(r'([-\\d\\.,]+)\\s*(?:g)?\\s*(?:protein)\\b', \"protein\")\n",
        "    # sodium mg\n",
        "    _num_search(r'([-\\d\\.,]+)\\s*(?:mg)\\s*(?:sodium)\\b', \"sodium\")\n",
        "    # carbs\n",
        "    _num_search(r'([-\\d\\.,]+)\\s*(?:g)?\\s*(?:carb|carbs|carbohydrate|carbohydrates)\\b', \"carbs\")\n",
        "    # total fat\n",
        "    _num_search(r'([-\\d\\.,]+)\\s*(?:g)?\\s*(?:fat|total fat|total_fat)\\b', \"total_fat\")\n",
        "    # fiber\n",
        "    _num_search(r'([-\\d\\.,]+)\\s*(?:g)?\\s*(?:dietary fiber|fiber)\\b', \"fiber\")\n",
        "    # duration in minutes\n",
        "    _num_search(r'([-\\d\\.,]+)\\s*(?:minutes|min|mins)\\b', \"duration\")\n",
        "    # serves\n",
        "    mserv = re.search(r'serves?\\s*[:\\-]?\\s*([-\\d\\.,]+)\\b', s, flags=re.I)\n",
        "    if mserv:\n",
        "        n = to_number(mserv.group(1))\n",
        "        if n is not None:\n",
        "            claims[\"serves\"] = n\n",
        "\n",
        "    # ingredients heuristics\n",
        "    ming = re.search(r'(?:features|featuring|using|with|contains|made with)\\s+([a-zA-Z0-9\\s\\-\\',&]+?)(?:[.,;]|$)', s, flags=re.I)\n",
        "    if ming:\n",
        "        text = ming.group(1)\n",
        "        candidates = re.split(r'[,;&]| and | & ', text, flags=re.I)\n",
        "        ing_list = [c.strip().lower() for c in candidates if c.strip()]\n",
        "\n",
        "    return title if title else None, claims, ing_list\n",
        "\n",
        "# -------------------------\n",
        "# Constraint parsing\n",
        "# -------------------------\n",
        "def parse_instruction_to_constraints(instruction: str) -> Dict[str, Any]:\n",
        "    instr = (instruction or \"\").lower()\n",
        "    constraints = {}\n",
        "    # calories\n",
        "    m = re.search(r'under\\s+([0-9,]+)\\s*(?:calories|kcal)?', instr)\n",
        "    if m:\n",
        "        n = to_number(m.group(1))\n",
        "        if n is not None:\n",
        "            constraints[\"calories_max\"] = float(n)\n",
        "    m2 = re.search(r'around\\s+([0-9,]+)\\s*(?:calories|kcal)?', instr)\n",
        "    if m2:\n",
        "        n = to_number(m2.group(1))\n",
        "        if n is not None:\n",
        "            constraints[\"calories_min\"] = max(0.0, n - 50)\n",
        "            constraints[\"calories_max\"] = n + 50\n",
        "    # duration\n",
        "    mtime = re.search(r'less than\\s+([0-9,]+)\\s*minutes', instr)\n",
        "    if mtime:\n",
        "        n = to_number(mtime.group(1))\n",
        "        if n is not None:\n",
        "            constraints[\"duration_max\"] = float(n)\n",
        "    # protein\n",
        "    mprot = re.search(r'at least\\s+([0-9,]+)\\s*g\\s*protein', instr)\n",
        "    if mprot:\n",
        "        n = to_number(mprot.group(1))\n",
        "        if n is not None:\n",
        "            constraints[\"protein_min\"] = float(n)\n",
        "    # sodium\n",
        "    msod = re.search(r'under\\s+([0-9,]+)\\s*mg\\s*sodium', instr)\n",
        "    if msod:\n",
        "        n = to_number(msod.group(1))\n",
        "        if n is not None:\n",
        "            constraints[\"sodium_max\"] = float(n)\n",
        "    # ingredients include pattern\n",
        "    ming = re.search(r'suggest a recipe using\\s+([a-z0-9\\s\\-\\']+?)\\s+and\\s+([a-z0-9\\s\\-\\']+)', instr)\n",
        "    if ming:\n",
        "        constraints[\"ingredients_include\"] = [ming.group(1).strip(), ming.group(2).strip()]\n",
        "    # fiber\n",
        "    mf = re.search(r'at least\\s+([0-9,]+)\\s*g\\s*fiber', instr)\n",
        "    if mf:\n",
        "        n = to_number(mf.group(1))\n",
        "        if n is not None:\n",
        "            constraints[\"fiber_min\"] = float(n)\n",
        "    # balanced meal\n",
        "    if \"balanced meal\" in instr:\n",
        "        constraints[\"balanced\"] = True\n",
        "    return constraints\n",
        "\n",
        "# -------------------------\n",
        "# Dataset matching & constraints checking\n",
        "# -------------------------\n",
        "def recipe_satisfies_constraints(recipe_row: pd.Series, constraints: Dict[str, Any]) -> bool:\n",
        "    try:\n",
        "        # calories\n",
        "        if \"calories_max\" in constraints:\n",
        "            if pd.isna(recipe_row.get(COLS[\"calories\"], np.nan)):\n",
        "                return False\n",
        "            if float(recipe_row[COLS[\"calories\"]]) > constraints[\"calories_max\"]:\n",
        "                return False\n",
        "        if \"calories_min\" in constraints:\n",
        "            if pd.isna(recipe_row.get(COLS[\"calories\"], np.nan)):\n",
        "                return False\n",
        "            if float(recipe_row[COLS[\"calories\"]]) < constraints[\"calories_min\"]:\n",
        "                return False\n",
        "        # duration\n",
        "        if \"duration_max\" in constraints:\n",
        "            if pd.isna(recipe_row.get(COLS[\"duration\"], np.nan)):\n",
        "                return False\n",
        "            if float(recipe_row[COLS[\"duration\"]]) > constraints[\"duration_max\"]:\n",
        "                return False\n",
        "        # protein\n",
        "        if \"protein_min\" in constraints:\n",
        "            if pd.isna(recipe_row.get(COLS[\"protein\"], np.nan)):\n",
        "                return False\n",
        "            if float(recipe_row[COLS[\"protein\"]]) < constraints[\"protein_min\"]:\n",
        "                return False\n",
        "        # sodium\n",
        "        if \"sodium_max\" in constraints:\n",
        "            if pd.isna(recipe_row.get(COLS[\"sodium\"], np.nan)):\n",
        "                return False\n",
        "            if float(recipe_row[COLS[\"sodium\"]]) > constraints[\"sodium_max\"]:\n",
        "                return False\n",
        "        # ingredients include\n",
        "        if \"ingredients_include\" in constraints:\n",
        "            ing_field = recipe_row.get(COLS[\"ingredients\"], \"\")\n",
        "            if not isinstance(ing_field, str) or ing_field.strip() == \"\":\n",
        "                return False\n",
        "            ing_field_low = ing_field.lower()\n",
        "            for ing in constraints[\"ingredients_include\"]:\n",
        "                if ing.lower() not in ing_field_low:\n",
        "                    return False\n",
        "        # fiber\n",
        "        if \"fiber_min\" in constraints:\n",
        "            if pd.isna(recipe_row.get(COLS[\"fiber\"], np.nan)):\n",
        "                return False\n",
        "            if float(recipe_row[COLS[\"fiber\"]]) < constraints[\"fiber_min\"]:\n",
        "                return False\n",
        "        # balanced: heuristics\n",
        "        if constraints.get(\"balanced\"):\n",
        "            if any(pd.isna(recipe_row.get(COLS.get(k), np.nan)) for k in [\"calories\", \"protein\", \"total_fat\"]):\n",
        "                return False\n",
        "            if float(recipe_row[COLS[\"calories\"]]) > 700:\n",
        "                return False\n",
        "            if float(recipe_row[COLS[\"protein\"]]) < 8:\n",
        "                return False\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def find_any_matching_recipe(df: pd.DataFrame, constraints: Dict[str, Any]) -> Optional[pd.Series]:\n",
        "    mask = pd.Series(True, index=df.index)\n",
        "    if \"calories_max\" in constraints and COLS[\"calories\"] in df.columns:\n",
        "        mask &= df[COLS[\"calories\"]].fillna(np.inf) <= constraints[\"calories_max\"]\n",
        "    if \"calories_min\" in constraints and COLS[\"calories\"] in df.columns:\n",
        "        mask &= df[COLS[\"calories\"]].fillna(-np.inf) >= constraints[\"calories_min\"]\n",
        "    if \"duration_max\" in constraints and COLS[\"duration\"] in df.columns:\n",
        "        mask &= df[COLS[\"duration\"]].fillna(np.inf) <= constraints[\"duration_max\"]\n",
        "    if \"protein_min\" in constraints and COLS[\"protein\"] in df.columns:\n",
        "        mask &= df[COLS[\"protein\"]].fillna(-np.inf) >= constraints[\"protein_min\"]\n",
        "    if \"sodium_max\" in constraints and COLS[\"sodium\"] in df.columns:\n",
        "        mask &= df[COLS[\"sodium\"]].fillna(np.inf) <= constraints[\"sodium_max\"]\n",
        "    if \"fiber_min\" in constraints and COLS[\"fiber\"] in df.columns:\n",
        "        mask &= df[COLS[\"fiber\"]].fillna(-np.inf) >= constraints[\"fiber_min\"]\n",
        "    if \"ingredients_include\" in constraints and COLS[\"ingredients\"] in df.columns:\n",
        "        for ing in constraints[\"ingredients_include\"]:\n",
        "            mask &= df[COLS[\"ingredients\"]].str.contains(ing.lower(), na=False)\n",
        "    if constraints.get(\"balanced\"):\n",
        "        mask &= df[COLS[\"calories\"]].fillna(np.inf) <= 700\n",
        "        mask &= df[COLS[\"protein\"]].fillna(-np.inf) >= 8\n",
        "        mask &= df[COLS[\"total_fat\"]].fillna(-np.inf) > 0\n",
        "    filtered = df[mask]\n",
        "    if len(filtered) == 0:\n",
        "        return None\n",
        "    # return the top candidate (you may prefer a smarter ranking)\n",
        "    return filtered.iloc[0]\n",
        "\n",
        "# -------------------------\n",
        "# Post-processing helpers\n",
        "# -------------------------\n",
        "def claims_close_enough(claims: Dict[str, float], recipe_row: pd.Series, tolerances: Dict[str, float]) -> bool:\n",
        "    try:\n",
        "        for k, v in claims.items():\n",
        "            if k not in COLS:\n",
        "                continue\n",
        "            col = COLS.get(k)\n",
        "            # dataset missing -> treat as not close\n",
        "            truth = recipe_row.get(col, None)\n",
        "            if truth is None or pd.isna(truth):\n",
        "                return False\n",
        "            truth = float(truth)\n",
        "            # numeric claim value\n",
        "            try:\n",
        "                claim_val = float(v)\n",
        "            except Exception:\n",
        "                # if claim couldn't be parsed to float, not close\n",
        "                return False\n",
        "            if k in {\"calories\", \"protein\", \"sodium\", \"carbs\", \"total_fat\", \"fiber\"}:\n",
        "                rel_tol = tolerances.get(k, DEFAULT_TOLERANCES.get(k, 0.2))\n",
        "                if truth == 0:\n",
        "                    if abs(claim_val - truth) > 1e-6:\n",
        "                        return False\n",
        "                else:\n",
        "                    if abs(claim_val - truth) / (abs(truth) if truth != 0 else 1.0) > rel_tol:\n",
        "                        return False\n",
        "            elif k in {\"duration\", \"serves\"}:\n",
        "                abs_tol = tolerances.get(k, DEFAULT_TOLERANCES.get(k, 1))\n",
        "                if abs(claim_val - truth) > abs_tol:\n",
        "                    return False\n",
        "            else:\n",
        "                # conservative fallback\n",
        "                if abs(claim_val - truth) > 1e-6:\n",
        "                    return False\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def format_recipe_facts(recipe_row: pd.Series) -> Dict[str, Any]:\n",
        "    out = {}\n",
        "    for key in [\"calories\", \"protein\", \"sodium\", \"duration\", \"serves\", \"fiber\", \"total_fat\", \"carbs\"]:\n",
        "        col = COLS.get(key)\n",
        "        if col in recipe_row and not pd.isna(recipe_row[col]):\n",
        "            val = recipe_row[col]\n",
        "            num = to_number(val)\n",
        "            if num is not None:\n",
        "                out[key] = num\n",
        "            else:\n",
        "                out[key] = str(val).strip()\n",
        "    if COLS[\"ingredients\"] in recipe_row and isinstance(recipe_row[COLS[\"ingredients\"]], str):\n",
        "        out[\"ingredients\"] = recipe_row[COLS[\"ingredients\"]].strip()\n",
        "    if COLS[\"title\"] in recipe_row and isinstance(recipe_row[COLS[\"title\"]], str):\n",
        "        out[\"title\"] = recipe_row[COLS[\"title\"]].strip()\n",
        "    return out\n",
        "\n",
        "def build_corrected_output(original_output: str, corrected_title: str, facts: Dict[str, Any]) -> str:\n",
        "    title = corrected_title or facts.get(\"title\")\n",
        "    parts = []\n",
        "    if title:\n",
        "        parts.append(str(title))\n",
        "    factuals = []\n",
        "    if \"calories\" in facts:\n",
        "        try:\n",
        "            factuals.append(f\"{int(round(float(facts['calories'])))} calories\")\n",
        "        except Exception:\n",
        "            factuals.append(f\"calories: {facts['calories']}\")\n",
        "    if \"protein\" in facts:\n",
        "        try:\n",
        "            factuals.append(f\"{round(float(facts['protein']), 1)}g protein\")\n",
        "        except Exception:\n",
        "            factuals.append(f\"protein: {facts['protein']}\")\n",
        "    if \"sodium\" in facts:\n",
        "        try:\n",
        "            factuals.append(f\"{int(round(float(facts['sodium'])))}mg sodium\")\n",
        "        except Exception:\n",
        "            factuals.append(f\"sodium: {facts['sodium']}\")\n",
        "    if \"duration\" in facts:\n",
        "        try:\n",
        "            factuals.append(f\"ready in {int(round(float(facts['duration'])))} minutes\")\n",
        "        except Exception:\n",
        "            factuals.append(f\"duration: {facts['duration']}\")\n",
        "    if \"serves\" in facts:\n",
        "        try:\n",
        "            factuals.append(f\"serves {int(round(float(facts['serves'])))}\")\n",
        "        except Exception:\n",
        "            factuals.append(f\"serves: {facts['serves']}\")\n",
        "    if factuals:\n",
        "        if parts:\n",
        "            parts = [f\"{parts[0]} - {', '.join(factuals)}\"]\n",
        "        else:\n",
        "            parts = [\", \".join(factuals)]\n",
        "    if \"ingredients\" in facts and facts[\"ingredients\"]:\n",
        "        parts.append(f\"Ingredients: {facts['ingredients']}\")\n",
        "    return \". \".join(parts) if parts else original_output\n",
        "\n",
        "# -------------------------\n",
        "# Title matching helper (robust)\n",
        "# -------------------------\n",
        "def find_title_in_df(df: pd.DataFrame, title: str) -> Tuple[Optional[pd.Series], Optional[str]]:\n",
        "    \"\"\"\n",
        "    Try to find the title in df. Return (row, match_type)\n",
        "    match_type in {\"exact\", \"substring\", \"fuzzy\", None}\n",
        "    \"\"\"\n",
        "    if not title or COLS[\"title\"] not in df.columns:\n",
        "        return None, None\n",
        "    title_norm = title.strip().lower()\n",
        "    # exact match\n",
        "    exact = df[df[COLS[\"title\"]].astype(str).str.lower() == title_norm]\n",
        "    if len(exact) > 0:\n",
        "        return exact.iloc[0], \"exact\"\n",
        "    # substring\n",
        "    substr = df[df[COLS[\"title\"]].astype(str).str.lower().str.contains(re.escape(title_norm), na=False)]\n",
        "    if len(substr) > 0:\n",
        "        return substr.iloc[0], \"substring\"\n",
        "    # fuzzy: use difflib on the list of titles\n",
        "    titles = df[COLS[\"title\"]].astype(str).tolist()\n",
        "    # compute close matches using sequence matcher ratio\n",
        "    best = None\n",
        "    best_score = 0.0\n",
        "    for t in titles:\n",
        "        score = difflib.SequenceMatcher(None, title_norm, t.lower()).ratio()\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best = t\n",
        "    if best_score >= FUZZY_TITLE_THRESH:\n",
        "        row = df[df[COLS[\"title\"]].astype(str).str.lower() == best.lower()]\n",
        "        if len(row) > 0:\n",
        "            return row.iloc[0], \"fuzzy\"\n",
        "        else:\n",
        "            # fallback: return first row that contains best as substring\n",
        "            row2 = df[df[COLS[\"title\"]].astype(str).str.lower().str.contains(re.escape(best.lower()), na=False)]\n",
        "            if len(row2) > 0:\n",
        "                return row2.iloc[0], \"fuzzy\"\n",
        "    return None, None\n",
        "\n",
        "# -------------------------\n",
        "# Main evaluation with post-processing\n",
        "# -------------------------\n",
        "def evaluate(inferenced_data: Dict[str, Any], df: pd.DataFrame, split_key: str = \"test\"):\n",
        "    preds, refs, insts = inferenced_data[split_key]\n",
        "\n",
        "    # Normalize predictions/instructions into list of {instruction, output}\n",
        "    normalized = []\n",
        "    if isinstance(preds, list) and len(preds) > 0 and isinstance(preds[0], dict) and 'output' in preds[0]:\n",
        "        normalized = preds\n",
        "    else:\n",
        "        if isinstance(preds, list) and isinstance(insts, list) and len(preds) == len(insts):\n",
        "            for p, i in zip(preds, insts):\n",
        "                if isinstance(i, list):\n",
        "                    # i is list of variants; p might be list of outputs or single string\n",
        "                    if isinstance(p, list) and len(p) == len(i):\n",
        "                        for out, var in zip(p, i):\n",
        "                            normalized.append({\"instruction\": var.get(\"instruction\") if isinstance(var, dict) else str(var),\n",
        "                                               \"output\": out})\n",
        "                    else:\n",
        "                        for var in i:\n",
        "                            normalized.append({\"instruction\": var.get(\"instruction\") if isinstance(var, dict) else str(var),\n",
        "                                               \"output\": p if isinstance(p, str) else str(p)})\n",
        "                else:\n",
        "                    normalized.append({\"instruction\": i, \"output\": p})\n",
        "        else:\n",
        "            # fallback: try to interpret insts as list of dicts\n",
        "            if isinstance(insts, list):\n",
        "                for entry in insts:\n",
        "                    if isinstance(entry, dict) and 'instruction' in entry and 'output' in entry:\n",
        "                        normalized.append({\"instruction\": entry['instruction'], \"output\": entry['output']})\n",
        "                    elif isinstance(entry, dict) and 'instruction' in entry:\n",
        "                        normalized.append({\"instruction\": entry['instruction'], \"output\": \"\"})\n",
        "                    else:\n",
        "                        normalized.append({\"instruction\": str(entry), \"output\": \"\"})\n",
        "            else:\n",
        "                raise ValueError(\"Unable to normalize predictions/instructions structure. Inspect your inferenced_data format.\")\n",
        "\n",
        "    records = []\n",
        "    for item in normalized:\n",
        "        instruction = item.get(\"instruction\", \"\")\n",
        "        output = item.get(\"output\", \"\")\n",
        "\n",
        "        title, claims, mentioned_ings = extract_title_and_claims(output)\n",
        "        constraints = parse_instruction_to_constraints(instruction)\n",
        "\n",
        "        # Try to find title in dataset using robust matching\n",
        "        title_present = False\n",
        "        recipe_row = None\n",
        "        matched_by = None\n",
        "        if title:\n",
        "            recipe_row, matched_by = find_title_in_df(df, title)\n",
        "            if recipe_row is not None:\n",
        "                title_present = True\n",
        "\n",
        "        # Check satisfied_by_returned (only meaningful if title_present)\n",
        "        satisfied_by_returned = False\n",
        "        if title_present and recipe_row is not None and constraints:\n",
        "            satisfied_by_returned = recipe_satisfies_constraints(recipe_row, constraints)\n",
        "        elif title_present and not constraints:\n",
        "            satisfied_by_returned = True\n",
        "\n",
        "        # Does dataset contain any recipe satisfying constraints?\n",
        "        any_matching = True if not constraints else (find_any_matching_recipe(df, constraints) is not None)\n",
        "\n",
        "        # Start post-processing decision\n",
        "        corrected_output = output\n",
        "        correction_type = None\n",
        "        correction_reason = None\n",
        "\n",
        "        # If model referenced an existing dataset title:\n",
        "        if title_present and recipe_row is not None:\n",
        "            # Are the numeric claims close enough?\n",
        "            if claims:\n",
        "                if not claims_close_enough(claims, recipe_row, DEFAULT_TOLERANCES):\n",
        "                    facts = format_recipe_facts(recipe_row)\n",
        "                    corrected_output = build_corrected_output(output, recipe_row[COLS[\"title\"]], facts)\n",
        "                    correction_type = \"fix_claims\"\n",
        "                    correction_reason = f\"numeric claims diverged (matched_by={matched_by})\"\n",
        "            else:\n",
        "                # No numeric claims â€” we optionally can enrich with dataset facts. We'll not auto-enrich by default.\n",
        "                pass\n",
        "            hallucinated = False  # referenced existing or fuzzy match -> not hallucinated\n",
        "\n",
        "        else:\n",
        "            # title not present in dataset (strict)\n",
        "            # if constraints exist, see if we can find a dataset recipe matching constraints\n",
        "            hallucinated = True\n",
        "            if constraints:\n",
        "                candidate = find_any_matching_recipe(df, constraints)\n",
        "                if candidate is not None:\n",
        "                    # Replace hallucinated output with this dataset recipe\n",
        "                    facts = format_recipe_facts(candidate)\n",
        "                    corrected_output = build_corrected_output(output, candidate[COLS[\"title\"]], facts)\n",
        "                    correction_type = \"replace_with_dataset\"\n",
        "                    correction_reason = \"hallucinated title but dataset had a recipe satisfying constraints\"\n",
        "                    hallucinated = False  # we replaced with dataset -> treat as corrected to non-hallucinated\n",
        "\n",
        "        # if there were no constraints and no title, we still treat as hallucinated unless we can fuzzy match => above took care\n",
        "        records.append({\n",
        "            \"instruction\": instruction,\n",
        "            \"model_output\": output,\n",
        "            \"parsed_title\": title,\n",
        "            \"title_in_dataset\": title_present,\n",
        "            \"matched_by\": matched_by,\n",
        "            \"satisfied_by_returned\": satisfied_by_returned,\n",
        "            \"dataset_has_any_matching\": any_matching,\n",
        "            \"hallucinated\": hallucinated,\n",
        "            \"constraints\": constraints,\n",
        "            \"claims\": claims,\n",
        "            \"mentioned_ingredients\": mentioned_ings,\n",
        "            \"corrected_output\": corrected_output,\n",
        "            \"correction_type\": correction_type,\n",
        "            \"correction_reason\": correction_reason\n",
        "        })\n",
        "\n",
        "    # build dataframe and metrics\n",
        "    summary_df = pd.DataFrame(records)\n",
        "    # Save summary CSVs\n",
        "    summary_df.to_csv(OUTPUT_SUMMARY_CSV, index=False)\n",
        "    summary_df.to_csv(OUTPUT_CORRECTED_CSV, index=False)\n",
        "\n",
        "    # Metrics\n",
        "    total = len(summary_df)\n",
        "    halluc_count = int(summary_df['hallucinated'].sum()) if total > 0 else 0\n",
        "    corrected_count = int(summary_df['correction_type'].notna().sum()) if total > 0 else 0\n",
        "    satisfied_count = int(summary_df['satisfied_by_returned'].sum()) if 'satisfied_by_returned' in summary_df else 0\n",
        "    title_in_dataset_count = int(summary_df['title_in_dataset'].sum()) if 'title_in_dataset' in summary_df else 0\n",
        "\n",
        "    metrics = {\n",
        "        \"total_examples\": total,\n",
        "        \"hallucination_count\": halluc_count,\n",
        "        \"hallucination_rate\": halluc_count / total if total > 0 else 0.0,\n",
        "        \"corrected_count\": corrected_count,\n",
        "        \"satisfied_by_returned_count\": satisfied_count,\n",
        "        \"title_in_dataset_count\": title_in_dataset_count,\n",
        "        \"summary_csv\": OUTPUT_SUMMARY_CSV,\n",
        "        \"corrected_csv\": OUTPUT_CORRECTED_CSV\n",
        "    }\n",
        "\n",
        "    return summary_df, metrics\n",
        "\n",
        "# -------------------------\n",
        "# If run as script (example)\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Loading JSON:\", JSON_PATH)\n",
        "    inferenced = load_inputs(JSON_PATH)\n",
        "    print(\"Loading CSV:\", CSV_PATH)\n",
        "    df = load_df(CSV_PATH)\n",
        "\n",
        "    # pick split\n",
        "    split_to_eval = \"test\" if \"test\" in inferenced else (\"val\" if \"val\" in inferenced else list(inferenced.keys())[0])\n",
        "    print(\"Evaluating split:\", split_to_eval)\n",
        "    summary_df, metrics = evaluate(inferenced, df, split_key=split_to_eval)\n",
        "\n",
        "    print(\"\\n=== Metrics ===\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "    print(f\"\\nDetailed summary saved to {metrics['summary_csv']}\")\n",
        "    print(f\"Corrected summary saved to {metrics['corrected_csv']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rag Evaluation and hallucination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading JSON: ../results/fine-tuned-rag-inference.json\n",
            "Loading hummus CSV: ../data/pp_recipes.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/1g/st98989x26136dtmmybf9mdc0000gn/T/ipykernel_22720/2709231389.py:38: DtypeWarning: Columns (35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(csv_path, index_col=0, low_memory=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating split: test\n",
            "\n",
            "=== Metrics ===\n",
            "total_examples: 50\n",
            "TP: 20\n",
            "FP: 0\n",
            "FN: 30\n",
            "precision: 1.0\n",
            "recall: 0.4\n",
            "f1: 0.5714285714285715\n",
            "hallucination_count: 10\n",
            "hallucination_rate: 0.2\n",
            "summary_csv: constraint_evaluation_summary_rag.csv\n",
            "\n",
            "Detailed summary saved to constraint_evaluation_summary_rag.csv\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# CONFIG - change file names / keys if needed\n",
        "JSON_PATH = \"../results/fine-tuned-rag-inference.json\"   # <- path to your jsondump\n",
        "CSV_PATH = \"../data/pp_recipes.csv\"          # <- hummus recipes CSV\n",
        "OUTPUT_SUMMARY_CSV = \"constraint_evaluation_summary_rag.csv\"\n",
        "\n",
        "# Columns mapping from your description (adjust if different)\n",
        "COLS = {\n",
        "    \"title\": \"title\",\n",
        "    \"calories\": \"calories [cal]\",\n",
        "    \"protein\": \"protein [g]\",\n",
        "    \"sodium\": \"sodium [mg]\",\n",
        "    \"duration\": \"duration\",           # may be string/object - ensure numeric if possible\n",
        "    \"serves\": \"serves\",\n",
        "    \"total_fat\": \"totalFat [g]\",\n",
        "    \"carbs\": \"totalCarbohydrate [g]\",\n",
        "    \"fiber\": \"dietaryFiber [g]\",\n",
        "    \"ingredients\": \"ingredients\"\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# Helper functions\n",
        "# -------------------------\n",
        "def load_inputs(json_path: str) -> Dict[str, Any]:\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "\n",
        "def load_df(csv_path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_path, index_col=0, low_memory=True)\n",
        "    # Normalise title for matching\n",
        "    df[COLS[\"title\"]] = df[COLS[\"title\"]].astype(str).str.strip()\n",
        "    # Try converting numeric columns\n",
        "    for c in [\"calories\", \"protein\", \"sodium\", \"duration\", \"total_fat\", \"carbs\", \"fiber\"]:\n",
        "        colname = COLS.get(c)\n",
        "        if colname in df.columns:\n",
        "            # remove non-numeric and coerce\n",
        "            df[colname] = pd.to_numeric(df[colname].astype(str).str.replace(r\"[^\\d\\.\\-]\", \"\", regex=True), errors=\"coerce\")\n",
        "    # Normalize ingredients column to lowercase string for containment checks\n",
        "    if COLS[\"ingredients\"] in df.columns:\n",
        "        df[COLS[\"ingredients\"]] = df[COLS[\"ingredients\"]].astype(str).str.lower()\n",
        "    return df\n",
        "\n",
        "\n",
        "def extract_title_and_claims(model_output: str) -> Tuple[Optional[str], Dict[str, float], List[str]]:\n",
        "    \"\"\"\n",
        "    Extract a claimed title and numeric claims from model output.\n",
        "    Returns (title, numeric_claims, list_of_mentioned_ingredients)\n",
        "    Numeric claims keys: calories, protein, sodium, duration, serves, fiber, total_fat, carbs\n",
        "    This function uses heuristic regex matching on outputs like:\n",
        "      \"Hummus Delight - 350 calories, 15g protein, ready in 20 minutes.\"\n",
        "      \"Title - Takes 12 minutes, 300.0 calories\"\n",
        "    \"\"\"\n",
        "    claims = {}\n",
        "    ing_list = []\n",
        "\n",
        "    if not isinstance(model_output, str):\n",
        "        return None, claims, ing_list\n",
        "\n",
        "    # Attempt to parse \"Title - ...\" or \"Title: ...\" or \"Title â€” ...\"\n",
        "    m = re.match(r'^\\s*([^\\-\\â€“\\â€”\\:]+?)\\s*(?:[-\\â€“\\â€”\\:])\\s*(.*)$', model_output.strip())\n",
        "    if m:\n",
        "        title = m.group(1).strip()\n",
        "        rest = m.group(2)\n",
        "    else:\n",
        "        # fallback: first token phrase before comma\n",
        "        parts = model_output.split(\",\")\n",
        "        title = parts[0].strip()\n",
        "        rest = \", \".join(parts[1:]) if len(parts) > 1 else \"\"\n",
        "\n",
        "    # numeric captures\n",
        "    # calories: \"350 calories\" or \"350.0 calories\"\n",
        "    mcal = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*(?:calories|cal|kcal)\\b', model_output, flags=re.I)\n",
        "    if mcal:\n",
        "        claims[\"calories\"] = float(mcal.group(1))\n",
        "    # protein: \"15g protein\"\n",
        "    mprot = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*g\\s*(?:protein)\\b', model_output, flags=re.I)\n",
        "    if mprot:\n",
        "        claims[\"protein\"] = float(mprot.group(1))\n",
        "    # sodium: \"180mg sodium\"\n",
        "    msod = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*mg\\s*(?:sodium)\\b', model_output, flags=re.I)\n",
        "    if msod:\n",
        "        claims[\"sodium\"] = float(msod.group(1))\n",
        "    # duration: \"ready in 20 minutes\", \"Takes 12 minutes\"\n",
        "    mtime = re.search(r'(\\d+)\\s*(?:minutes|min|mins)\\b', model_output, flags=re.I)\n",
        "    if mtime:\n",
        "        claims[\"duration\"] = float(mtime.group(1))\n",
        "    # serves: \"serves 4\"\n",
        "    mserves = re.search(r'serves\\s*(\\d+)', model_output, flags=re.I)\n",
        "    if mserves:\n",
        "        claims[\"serves\"] = int(mserves.group(1))\n",
        "    # fiber: \"5g fiber\"\n",
        "    mfib = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*g\\s*(?:dietary fiber|fiber)\\b', model_output, flags=re.I)\n",
        "    if mfib:\n",
        "        claims[\"fiber\"] = float(mfib.group(1))\n",
        "    # total_fat: \"9g fat\"\n",
        "    mfat = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*g\\s*(?:fat)\\b', model_output, flags=re.I)\n",
        "    if mfat:\n",
        "        claims[\"total_fat\"] = float(mfat.group(1))\n",
        "    # carbs: \"30g carbs\"\n",
        "    mcarb = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*g\\s*(?:carb|carbs|carbohydrate|carbohydrates)\\b', model_output, flags=re.I)\n",
        "    if mcarb:\n",
        "        claims[\"carbs\"] = float(mcarb.group(1))\n",
        "\n",
        "    # Extract simple ingredients mentioned like \"Features chickpeas and tahini\"\n",
        "    # Look for \"Features X and Y\" or \"using X and Y\" patterns\n",
        "    ming = re.search(r'(?:features|using|uses|with)\\s+([a-zA-Z0-9\\s\\-\\']+?)\\s*(?:,|\\band\\b|\\.)', model_output, flags=re.I)\n",
        "    if ming:\n",
        "        # split on 'and' or commas\n",
        "        text = ming.group(1)\n",
        "        candidates = re.split(r'\\band\\b|,', text, flags=re.I)\n",
        "        ing_list = [c.strip().lower() for c in candidates if c.strip()]\n",
        "\n",
        "    # fallback: look for \"using X and Y.\" explicit pattern\n",
        "    m2 = re.search(r'using\\s+([^\\.,]+?)\\.', model_output, flags=re.I)\n",
        "    if m2:\n",
        "        parts = re.split(r'\\band\\b|,', m2.group(1))\n",
        "        ing_list = [p.strip().lower() for p in parts if p.strip()]\n",
        "\n",
        "    return title if title else None, claims, ing_list\n",
        "\n",
        "\n",
        "def parse_instruction_to_constraints(instruction: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Given an instruction string (as generated in variants), return a constraints dict.\n",
        "    Supports the variant instruction formats you provided.\n",
        "    \"\"\"\n",
        "    instr = instruction.lower()\n",
        "    constraints = {}\n",
        "\n",
        "    # calories: \"under 400 calories\" or \"around 400 calories\" or \"under 400\"\n",
        "    m = re.search(r'under\\s+(\\d+)', instr)\n",
        "    if m:\n",
        "        constraints[\"calories_max\"] = float(m.group(1))\n",
        "    m2 = re.search(r'around\\s+(\\d+)', instr)\n",
        "    if m2:\n",
        "        val = float(m2.group(1))\n",
        "        # allow +/- 50 calories tolerance for \"around\"\n",
        "        constraints[\"calories_min\"] = max(0.0, val - 50)\n",
        "        constraints[\"calories_max\"] = val + 50\n",
        "\n",
        "    # time-based: \"less than X minutes\"\n",
        "    mtime = re.search(r'less than\\s+(\\d+)\\s*minutes', instr)\n",
        "    if mtime:\n",
        "        constraints[\"duration_max\"] = float(mtime.group(1))\n",
        "\n",
        "    # protein: \"at least Xg protein\" or \"high-protein at least X\"\n",
        "    mprot = re.search(r'at least\\s+(\\d+)\\s*g\\s*protein', instr)\n",
        "    if mprot:\n",
        "        constraints[\"protein_min\"] = float(mprot.group(1))\n",
        "    else:\n",
        "        # \"high-protein recipe with at least 12g protein.\" or \"high-protein with at least 10\"\n",
        "        mprot2 = re.search(r'(\\d+)\\s*g\\s*protein', instr)\n",
        "        if mprot2 and 'high-protein' in instr:\n",
        "            constraints[\"protein_min\"] = float(mprot2.group(1))\n",
        "\n",
        "    # sodium: \"under Xmg sodium\"\n",
        "    msod = re.search(r'under\\s+(\\d+)\\s*mg\\s*sodium', instr)\n",
        "    if msod:\n",
        "        constraints[\"sodium_max\"] = float(msod.group(1))\n",
        "\n",
        "    # ingredient-based: \"using X and Y\"\n",
        "    ming = re.search(r'suggest a recipe using\\s+([a-z0-9\\s\\-\\']+?)\\s+and\\s+([a-z0-9\\s\\-\\']+)', instr)\n",
        "    if ming:\n",
        "        constraints[\"ingredients_include\"] = [ming.group(1).strip(), ming.group(2).strip()]\n",
        "\n",
        "    # fiber: \"at least Xg fiber\" or \"high-fiber at least\"\n",
        "    mf = re.search(r'at least\\s+(\\d+)\\s*g\\s*fiber', instr)\n",
        "    if mf:\n",
        "        constraints[\"fiber_min\"] = float(mf.group(1))\n",
        "    mff = re.search(r'high-fiber.*?(\\d+)', instr)\n",
        "    if mff and \"fiber\" in instr:\n",
        "        constraints[\"fiber_min\"] = float(mff.group(1))\n",
        "\n",
        "    # balanced meal: this is generic -> require calories, protein, total_fat present and between some moderate bounds\n",
        "    if \"balanced meal\" in instr:\n",
        "        constraints[\"balanced\"] = True\n",
        "\n",
        "    # time variant in your code: instruction uses \"less than {duration + 10} minutes\"\n",
        "    mquick = re.search(r'less than\\s+(\\d+)\\s*minutes', instr)\n",
        "    if mquick:\n",
        "        constraints[\"duration_max\"] = float(mquick.group(1))\n",
        "\n",
        "    return constraints\n",
        "\n",
        "\n",
        "def recipe_satisfies_constraints(recipe_row: pd.Series, constraints: Dict[str, Any]) -> bool:\n",
        "    \"\"\"\n",
        "    Returns True if the pandas series (one recipe) satisfies all constraints.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # calories\n",
        "        if \"calories_max\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"calories\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"calories\"]] > constraints[\"calories_max\"]:\n",
        "                return False\n",
        "        if \"calories_min\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"calories\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"calories\"]] < constraints[\"calories_min\"]:\n",
        "                return False\n",
        "        # duration\n",
        "        if \"duration_max\" in constraints:\n",
        "            if COLS[\"duration\"] not in recipe_row or pd.isna(recipe_row[COLS[\"duration\"]]):\n",
        "                return False\n",
        "            if float(recipe_row[COLS[\"duration\"]]) > constraints[\"duration_max\"]:\n",
        "                return False\n",
        "        # protein\n",
        "        if \"protein_min\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"protein\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"protein\"]] < constraints[\"protein_min\"]:\n",
        "                return False\n",
        "        # sodium\n",
        "        if \"sodium_max\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"sodium\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"sodium\"]] > constraints[\"sodium_max\"]:\n",
        "                return False\n",
        "        # ingredients include\n",
        "        if \"ingredients_include\" in constraints:\n",
        "            ing_field = recipe_row.get(COLS[\"ingredients\"], \"\")\n",
        "            if not isinstance(ing_field, str):\n",
        "                return False\n",
        "            ing_field_low = ing_field.lower()\n",
        "            for ing in constraints[\"ingredients_include\"]:\n",
        "                if ing.lower() not in ing_field_low:\n",
        "                    return False\n",
        "        # fiber\n",
        "        if \"fiber_min\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"fiber\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"fiber\"]] < constraints[\"fiber_min\"]:\n",
        "                return False\n",
        "        # balanced: require numeric calories/protein/total_fat exists; simple heuristics\n",
        "        if constraints.get(\"balanced\"):\n",
        "            if any(pd.isna(recipe_row.get(COLS.get(k), None)) for k in [\"calories\", \"protein\", \"total_fat\"]):\n",
        "                return False\n",
        "            # require moderate calories <= 700 and protein >= 10\n",
        "            if recipe_row[COLS[\"calories\"]] > 700:\n",
        "                return False\n",
        "            if recipe_row[COLS[\"protein\"]] < 8:\n",
        "                return False\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        # if any unexpected error, return False\n",
        "        return False\n",
        "\n",
        "\n",
        "def find_any_matching_recipe(df: pd.DataFrame, constraints: Dict[str, Any]) -> Optional[pd.Series]:\n",
        "    \"\"\"\n",
        "    Returns first matching recipe row (as Series) that satisfies constraints, or None.\n",
        "    \"\"\"\n",
        "    # quick vectorized filter approach\n",
        "    mask = pd.Series(True, index=df.index)\n",
        "\n",
        "    if \"calories_max\" in constraints and COLS[\"calories\"] in df.columns:\n",
        "        mask &= df[COLS[\"calories\"]].fillna(np.inf) <= constraints[\"calories_max\"]\n",
        "    if \"calories_min\" in constraints and COLS[\"calories\"] in df.columns:\n",
        "        mask &= df[COLS[\"calories\"]].fillna(-np.inf) >= constraints[\"calories_min\"]\n",
        "    if \"duration_max\" in constraints and COLS[\"duration\"] in df.columns:\n",
        "        mask &= df[COLS[\"duration\"]].fillna(np.inf) <= constraints[\"duration_max\"]\n",
        "    if \"protein_min\" in constraints and COLS[\"protein\"] in df.columns:\n",
        "        mask &= df[COLS[\"protein\"]].fillna(-np.inf) >= constraints[\"protein_min\"]\n",
        "    if \"sodium_max\" in constraints and COLS[\"sodium\"] in df.columns:\n",
        "        mask &= df[COLS[\"sodium\"]].fillna(np.inf) <= constraints[\"sodium_max\"]\n",
        "    if \"fiber_min\" in constraints and COLS[\"fiber\"] in df.columns:\n",
        "        mask &= df[COLS[\"fiber\"]].fillna(-np.inf) >= constraints[\"fiber_min\"]\n",
        "    if \"ingredients_include\" in constraints and COLS[\"ingredients\"] in df.columns:\n",
        "        for ing in constraints[\"ingredients_include\"]:\n",
        "            mask &= df[COLS[\"ingredients\"]].str.contains(ing.lower(), na=False)\n",
        "\n",
        "    # balanced: apply heuristic\n",
        "    if constraints.get(\"balanced\"):\n",
        "        mask &= df[COLS[\"calories\"]].fillna(np.inf) <= 700\n",
        "        mask &= df[COLS[\"protein\"]].fillna(-np.inf) >= 8\n",
        "        mask &= df[COLS[\"total_fat\"]].fillna(-np.inf) > 0\n",
        "\n",
        "    filtered = df[mask]\n",
        "    if len(filtered) == 0:\n",
        "        return None\n",
        "    return filtered.iloc[0]\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Main evaluation\n",
        "# -------------------------\n",
        "def evaluate(inferenced_data: Dict[str, Any], df: pd.DataFrame, split_key: str = \"test\"):\n",
        "    \"\"\"\n",
        "    Expects inferenced_data[split_key] to be [predictions_list, references_list, instructions_list]\n",
        "    Each element in predictions_list corresponds to a model output. In your variant setup, you might\n",
        "    have predictions as lists of variants per recipe; we attempt to handle either flat lists or nested.\n",
        "    \"\"\"\n",
        "    preds, refs, insts = inferenced_data[split_key]\n",
        "\n",
        "    # Normalize lists: if preds is a dict or nested list-of-lists, flatten into per-variant instruction objects.\n",
        "    # We'll assume 'insts' is parallel: each entry may contain 'variants' list (per your earlier generation),\n",
        "    # or insts may already be the list of generated 'instruction' strings.\n",
        "    # We'll construct a list of dicts: { \"instruction\": ..., \"output\": ... }\n",
        "    records = []\n",
        "\n",
        "    # Case A: you saved a structure of variants per example (list of dicts with \"instruction\" and \"output\")\n",
        "    # We'll detect types and normalize.\n",
        "    if isinstance(preds, list) and len(preds) > 0 and isinstance(preds[0], dict) and 'output' in preds[0]:\n",
        "        # already normalized predictions as dicts\n",
        "        normalized = preds\n",
        "    else:\n",
        "        # Attempt to pair insts and preds element-wise\n",
        "        normalized = []\n",
        "        # If preds entries are lists of outputs per example and insts are lists of variants (list-of-dicts)\n",
        "        if isinstance(preds, list) and len(preds) == len(insts):\n",
        "            for p, i in zip(preds, insts):\n",
        "                # If i is list of variant dicts\n",
        "                if isinstance(i, list):\n",
        "                    # each variant has instruction + output but model output might be in p list in same order\n",
        "                    # Best effort: if p is list with same length, pair them; otherwise assume p is single str\n",
        "                    if isinstance(p, list) and len(p) == len(i):\n",
        "                        for out, var in zip(p, i):\n",
        "                            normalized.append({\"instruction\": var.get(\"instruction\") if isinstance(var, dict) else str(var),\n",
        "                                               \"output\": out})\n",
        "                    else:\n",
        "                        # pair each variant instruction with same p (string)\n",
        "                        for var in i:\n",
        "                            normalized.append({\"instruction\": var.get(\"instruction\") if isinstance(var, dict) else str(var),\n",
        "                                               \"output\": p if isinstance(p, str) else str(p)})\n",
        "                else:\n",
        "                    # i is a single instruction string\n",
        "                    normalized.append({\"instruction\": i, \"output\": p})\n",
        "        else:\n",
        "            # fallback: if insts is list of variant dicts\n",
        "            if isinstance(insts, list):\n",
        "                for entry in insts:\n",
        "                    if isinstance(entry, dict) and 'instruction' in entry and 'output' in entry:\n",
        "                        normalized.append({\"instruction\": entry['instruction'], \"output\": entry['output']})\n",
        "                    elif isinstance(entry, dict) and 'instruction' in entry:\n",
        "                        normalized.append({\"instruction\": entry['instruction'], \"output\": \"\"})\n",
        "                    else:\n",
        "                        # can't interpret; make best-effort\n",
        "                        normalized.append({\"instruction\": str(entry), \"output\": \"\"})\n",
        "            else:\n",
        "                raise ValueError(\"Unable to normalize predictions/instructions structure. Inspect your inferenced_data format.\")\n",
        "\n",
        "    # Now evaluate each normalized pair\n",
        "    for item in normalized:\n",
        "        instruction = item.get(\"instruction\", \"\")\n",
        "        output = item.get(\"output\", \"\")\n",
        "        title, claims, mentioned_ings = extract_title_and_claims(output)\n",
        "        constraints = parse_instruction_to_constraints(instruction)\n",
        "\n",
        "        title_present = False\n",
        "        recipe_row = None\n",
        "        if title:\n",
        "            # try exact or case-insensitive match in df titles\n",
        "            matches = df[df[COLS[\"title\"]].str.lower() == title.lower()]\n",
        "            if len(matches) == 0:\n",
        "                # try substring match\n",
        "                matches = df[df[COLS[\"title\"]].str.lower().str.contains(re.escape(title.lower()), na=False)]\n",
        "            if len(matches) > 0:\n",
        "                title_present = True\n",
        "                recipe_row = matches.iloc[0]\n",
        "\n",
        "        # Check if the title's referenced recipe (if present) satisfies constraints\n",
        "        satisfied_by_returned = False\n",
        "        if title_present and recipe_row is not None and constraints:\n",
        "            satisfied_by_returned = recipe_satisfies_constraints(recipe_row, constraints)\n",
        "        elif title_present and (not constraints):\n",
        "            # if no constraints parsed, consider it satisfied_by_returned = True (no constraint)\n",
        "            satisfied_by_returned = True\n",
        "\n",
        "        # Check whether any recipe in dataset satisfies constraints (for recall/TP/FN)\n",
        "        any_matching = True if not constraints else (find_any_matching_recipe(df, constraints) is not None)\n",
        "\n",
        "        # Hallucination: title not found in dataset\n",
        "        hallucinated = not title_present\n",
        "\n",
        "        records.append({\n",
        "            \"instruction\": instruction,\n",
        "            \"model_output\": output,\n",
        "            \"parsed_title\": title,\n",
        "            \"title_in_dataset\": title_present,\n",
        "            \"satisfied_by_returned\": satisfied_by_returned,\n",
        "            \"dataset_has_any_matching\": any_matching,\n",
        "            \"hallucinated\": hallucinated,\n",
        "            \"constraints\": constraints,\n",
        "            \"claims\": claims,\n",
        "            \"mentioned_ingredients\": mentioned_ings\n",
        "        })\n",
        "\n",
        "    # Compute metrics:\n",
        "    TP = 0  # dataset has a matching recipe AND model returned an example that satisfied constraints\n",
        "    FP = 0  # model returned a recipe that DOES NOT satisfy constraints OR hallucination where dataset had none\n",
        "    FN = 0  # dataset has a matching recipe but model either returned non-matching recipe or hallucinated/no answer\n",
        "\n",
        "    for r in records:\n",
        "        if r[\"dataset_has_any_matching\"]:\n",
        "            # ground truth: there exists an example satisfying constraints\n",
        "            if r[\"title_in_dataset\"] and r[\"satisfied_by_returned\"]:\n",
        "                TP += 1\n",
        "            else:\n",
        "                FN += 1\n",
        "        else:\n",
        "            # dataset has no matching recipe\n",
        "            if r[\"title_in_dataset\"]:\n",
        "                # model returned a recipe (but dataset actually doesn't have matching recipe!) -> FP\n",
        "                FP += 1\n",
        "            else:\n",
        "                # model did not return any recipe (and none exists): true negative (not used in precision/recall)\n",
        "                pass\n",
        "\n",
        "    # Another kind of FP: returned a recipe but it didn't satisfy constraints (even though dataset has matching recipe).\n",
        "    # The above counts that as FN (because dataset_has_any_matching true and model didn't return matching) â€” acceptable.\n",
        "    # Also count hallucinated returns (title not present) as FP when dataset_has_any_matching is False or True\n",
        "    # For clarity compute hallucination rate:\n",
        "    total_outputs = len(records)\n",
        "    halluc_count = sum(1 for r in records if r[\"hallucinated\"])\n",
        "    halluc_rate = halluc_count / total_outputs if total_outputs > 0 else 0.0\n",
        "\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    summary_df = pd.DataFrame(records)\n",
        "    summary_df.to_csv(OUTPUT_SUMMARY_CSV, index=False)\n",
        "\n",
        "    metrics = {\n",
        "        \"total_examples\": total_outputs,\n",
        "        \"TP\": TP,\n",
        "        \"FP\": FP,\n",
        "        \"FN\": FN,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"hallucination_count\": halluc_count,\n",
        "        \"hallucination_rate\": halluc_rate,\n",
        "        \"summary_csv\": OUTPUT_SUMMARY_CSV\n",
        "    }\n",
        "\n",
        "    return summary_df, metrics\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Entry point\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Load files\n",
        "    print(\"Loading JSON:\", JSON_PATH)\n",
        "    inferenced = load_inputs(JSON_PATH)\n",
        "    print(\"Loading hummus CSV:\", CSV_PATH)\n",
        "    df = load_df(CSV_PATH)\n",
        "\n",
        "    # Choose split to evaluate - 'test' or 'val' - modify if needed\n",
        "    split_to_eval = \"test\"\n",
        "    if split_to_eval not in inferenced:\n",
        "        # fallback to 'val' or first key\n",
        "        if \"val\" in inferenced:\n",
        "            split_to_eval = \"val\"\n",
        "        else:\n",
        "            split_to_eval = list(inferenced.keys())[0]\n",
        "\n",
        "    print(f\"Evaluating split: {split_to_eval}\")\n",
        "    summary_df, metrics = evaluate(inferenced, df, split_key=split_to_eval)\n",
        "\n",
        "    print(\"\\n=== Metrics ===\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "    print(f\"\\nDetailed summary saved to {metrics['summary_csv']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3150629f50354957befc67ff88cacef7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2f6fc8d87914de3ac880f7dcc11c8ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91850fdfdbb947c09c44bf6b0da69afb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading extra modules: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating split: test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:02<00:00, 19.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Evaluation Summary ===\n",
            "Total samples: 50\n",
            "Average BLEU:   0.1393\n",
            "Average ROUGE-L:0.3912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from evaluate import load\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# ---- CONFIG ----\n",
        "JSON_PATH = \"../results/fine-tuned-rag-inference.json\"   # Path to your file\n",
        "SPLIT_KEY = \"test\"                                       # or \"val\", depending on your JSON\n",
        "\n",
        "# ---- Load metrics ----\n",
        "bleu_metric = load(\"bleu\")\n",
        "rouge_metric = load(\"rouge\")\n",
        "\n",
        "# ---- Helper ----\n",
        "def load_inferenced_data(json_path: str):\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "# ---- Main evaluation ----\n",
        "def evaluate_rouge_bleu(inferenced_data, split_key=\"test\"):\n",
        "    preds, refs, _ = inferenced_data[split_key]\n",
        "\n",
        "    # Flatten if nested\n",
        "    if isinstance(preds[0], list):  # handle list of lists\n",
        "        preds = [p for sublist in preds for p in sublist]\n",
        "    if isinstance(refs[0], list):\n",
        "        refs = [r for sublist in refs for r in sublist]\n",
        "\n",
        "    assert len(preds) == len(refs), f\"Predictions ({len(preds)}) and references ({len(refs)}) length mismatch.\"\n",
        "\n",
        "    bleu_scores = []\n",
        "    rougeL_scores = []\n",
        "\n",
        "    for pred, ref in tqdm(zip(preds, refs), total=len(preds), desc=\"Evaluating\"):\n",
        "        # BLEU\n",
        "        bleu = bleu_metric.compute(predictions=[pred], references=[ref])[\"bleu\"]\n",
        "        bleu_scores.append(bleu)\n",
        "\n",
        "        # ROUGE-L\n",
        "        rougeL = rouge_metric.compute(predictions=[pred], references=[ref])[\"rougeL\"]\n",
        "        rougeL_scores.append(rougeL)\n",
        "\n",
        "    avg_bleu = np.mean(bleu_scores)\n",
        "    avg_rougeL = np.mean(rougeL_scores)\n",
        "\n",
        "    print(\"\\n=== Evaluation Summary ===\")\n",
        "    print(f\"Total samples: {len(preds)}\")\n",
        "    print(f\"Average BLEU:   {avg_bleu:.4f}\")\n",
        "    print(f\"Average ROUGE-L:{avg_rougeL:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"bleu_scores\": bleu_scores,\n",
        "        \"rougeL_scores\": rougeL_scores,\n",
        "        \"avg_bleu\": avg_bleu,\n",
        "        \"avg_rougeL\": avg_rougeL\n",
        "    }\n",
        "\n",
        "# ---- Run ----\n",
        "if __name__ == \"__main__\":\n",
        "    data = load_inferenced_data(JSON_PATH)\n",
        "\n",
        "    # Auto-select split\n",
        "    if SPLIT_KEY not in data:\n",
        "        if \"val\" in data:\n",
        "            SPLIT_KEY = \"val\"\n",
        "        else:\n",
        "            SPLIT_KEY = list(data.keys())[0]\n",
        "\n",
        "    print(f\"Evaluating split: {SPLIT_KEY}\")\n",
        "    results = evaluate_rouge_bleu(data, SPLIT_KEY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5649d914cbf429392d975b17f0f9002",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "750d08426e4743c8b3cd0c44477219ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading extra modules: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating split: test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:03<00:00, 16.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Evaluation Summary ===\n",
            "Total samples: 50\n",
            "Average BLEU:   0.1234\n",
            "Average ROUGE-L:0.3795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from evaluate import load\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# ---- CONFIG ----\n",
        "JSON_PATH = \"../results/fine-tuned-rag-inference-prompt.json\"   # Path to your file\n",
        "SPLIT_KEY = \"test\"                                       # or \"val\", depending on your JSON\n",
        "\n",
        "# ---- Load metrics ----\n",
        "bleu_metric = load(\"bleu\")\n",
        "rouge_metric = load(\"rouge\")\n",
        "\n",
        "# ---- Helper ----\n",
        "def load_inferenced_data(json_path: str):\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "# ---- Main evaluation ----\n",
        "def evaluate_rouge_bleu(inferenced_data, split_key=\"test\"):\n",
        "    preds, refs, _ = inferenced_data[split_key]\n",
        "\n",
        "    # Flatten if nested\n",
        "    if isinstance(preds[0], list):  # handle list of lists\n",
        "        preds = [p for sublist in preds for p in sublist]\n",
        "    if isinstance(refs[0], list):\n",
        "        refs = [r for sublist in refs for r in sublist]\n",
        "\n",
        "    assert len(preds) == len(refs), f\"Predictions ({len(preds)}) and references ({len(refs)}) length mismatch.\"\n",
        "\n",
        "    bleu_scores = []\n",
        "    rougeL_scores = []\n",
        "\n",
        "    for pred, ref in tqdm(zip(preds, refs), total=len(preds), desc=\"Evaluating\"):\n",
        "        # BLEU\n",
        "        bleu = bleu_metric.compute(predictions=[pred], references=[ref])[\"bleu\"]\n",
        "        bleu_scores.append(bleu)\n",
        "\n",
        "        # ROUGE-L\n",
        "        rougeL = rouge_metric.compute(predictions=[pred], references=[ref])[\"rougeL\"]\n",
        "        rougeL_scores.append(rougeL)\n",
        "\n",
        "    avg_bleu = np.mean(bleu_scores)\n",
        "    avg_rougeL = np.mean(rougeL_scores)\n",
        "\n",
        "    print(\"\\n=== Evaluation Summary ===\")\n",
        "    print(f\"Total samples: {len(preds)}\")\n",
        "    print(f\"Average BLEU:   {avg_bleu:.4f}\")\n",
        "    print(f\"Average ROUGE-L:{avg_rougeL:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"bleu_scores\": bleu_scores,\n",
        "        \"rougeL_scores\": rougeL_scores,\n",
        "        \"avg_bleu\": avg_bleu,\n",
        "        \"avg_rougeL\": avg_rougeL\n",
        "    }\n",
        "\n",
        "# ---- Run ----\n",
        "if __name__ == \"__main__\":\n",
        "    data = load_inferenced_data(JSON_PATH)\n",
        "\n",
        "    # Auto-select split\n",
        "    if SPLIT_KEY not in data:\n",
        "        if \"val\" in data:\n",
        "            SPLIT_KEY = \"val\"\n",
        "        else:\n",
        "            SPLIT_KEY = list(data.keys())[0]\n",
        "\n",
        "    print(f\"Evaluating split: {SPLIT_KEY}\")\n",
        "    results = evaluate_rouge_bleu(data, SPLIT_KEY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading JSON: ../results/fine-tuned-rag-inference-prompt.json\n",
            "Loading hummus CSV: ../data/pp_recipes.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/1g/st98989x26136dtmmybf9mdc0000gn/T/ipykernel_22720/79174957.py:38: DtypeWarning: Columns (35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(csv_path, index_col=0, low_memory=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating split: test\n",
            "\n",
            "=== Metrics ===\n",
            "total_examples: 50\n",
            "TP: 17\n",
            "FP: 0\n",
            "FN: 33\n",
            "precision: 1.0\n",
            "recall: 0.34\n",
            "f1: 0.5074626865671642\n",
            "hallucination_count: 10\n",
            "hallucination_rate: 0.2\n",
            "summary_csv: constraint_evaluation_summary_rag.csv\n",
            "\n",
            "Detailed summary saved to constraint_evaluation_summary_rag.csv\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# CONFIG - change file names / keys if needed\n",
        "JSON_PATH = \"../results/fine-tuned-rag-inference-prompt.json\"   # <- path to your jsondump\n",
        "CSV_PATH = \"../data/pp_recipes.csv\"          # <- hummus recipes CSV\n",
        "OUTPUT_SUMMARY_CSV = \"constraint_evaluation_summary_rag.csv\"\n",
        "\n",
        "# Columns mapping from your description (adjust if different)\n",
        "COLS = {\n",
        "    \"title\": \"title\",\n",
        "    \"calories\": \"calories [cal]\",\n",
        "    \"protein\": \"protein [g]\",\n",
        "    \"sodium\": \"sodium [mg]\",\n",
        "    \"duration\": \"duration\",           # may be string/object - ensure numeric if possible\n",
        "    \"serves\": \"serves\",\n",
        "    \"total_fat\": \"totalFat [g]\",\n",
        "    \"carbs\": \"totalCarbohydrate [g]\",\n",
        "    \"fiber\": \"dietaryFiber [g]\",\n",
        "    \"ingredients\": \"ingredients\"\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# Helper functions\n",
        "# -------------------------\n",
        "def load_inputs(json_path: str) -> Dict[str, Any]:\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "\n",
        "def load_df(csv_path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_path, index_col=0, low_memory=True)\n",
        "    # Normalise title for matching\n",
        "    df[COLS[\"title\"]] = df[COLS[\"title\"]].astype(str).str.strip()\n",
        "    # Try converting numeric columns\n",
        "    for c in [\"calories\", \"protein\", \"sodium\", \"duration\", \"total_fat\", \"carbs\", \"fiber\"]:\n",
        "        colname = COLS.get(c)\n",
        "        if colname in df.columns:\n",
        "            # remove non-numeric and coerce\n",
        "            df[colname] = pd.to_numeric(df[colname].astype(str).str.replace(r\"[^\\d\\.\\-]\", \"\", regex=True), errors=\"coerce\")\n",
        "    # Normalize ingredients column to lowercase string for containment checks\n",
        "    if COLS[\"ingredients\"] in df.columns:\n",
        "        df[COLS[\"ingredients\"]] = df[COLS[\"ingredients\"]].astype(str).str.lower()\n",
        "    return df\n",
        "\n",
        "\n",
        "def extract_title_and_claims(model_output: str) -> Tuple[Optional[str], Dict[str, float], List[str]]:\n",
        "    \"\"\"\n",
        "    Extract a claimed title and numeric claims from model output.\n",
        "    Returns (title, numeric_claims, list_of_mentioned_ingredients)\n",
        "    Numeric claims keys: calories, protein, sodium, duration, serves, fiber, total_fat, carbs\n",
        "    This function uses heuristic regex matching on outputs like:\n",
        "      \"Hummus Delight - 350 calories, 15g protein, ready in 20 minutes.\"\n",
        "      \"Title - Takes 12 minutes, 300.0 calories\"\n",
        "    \"\"\"\n",
        "    claims = {}\n",
        "    ing_list = []\n",
        "\n",
        "    if not isinstance(model_output, str):\n",
        "        return None, claims, ing_list\n",
        "\n",
        "    # Attempt to parse \"Title - ...\" or \"Title: ...\" or \"Title â€” ...\"\n",
        "    m = re.match(r'^\\s*([^\\-\\â€“\\â€”\\:]+?)\\s*(?:[-\\â€“\\â€”\\:])\\s*(.*)$', model_output.strip())\n",
        "    if m:\n",
        "        title = m.group(1).strip()\n",
        "        rest = m.group(2)\n",
        "    else:\n",
        "        # fallback: first token phrase before comma\n",
        "        parts = model_output.split(\",\")\n",
        "        title = parts[0].strip()\n",
        "        rest = \", \".join(parts[1:]) if len(parts) > 1 else \"\"\n",
        "\n",
        "    # numeric captures\n",
        "    # calories: \"350 calories\" or \"350.0 calories\"\n",
        "    mcal = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*(?:calories|cal|kcal)\\b', model_output, flags=re.I)\n",
        "    if mcal:\n",
        "        claims[\"calories\"] = float(mcal.group(1))\n",
        "    # protein: \"15g protein\"\n",
        "    mprot = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*g\\s*(?:protein)\\b', model_output, flags=re.I)\n",
        "    if mprot:\n",
        "        claims[\"protein\"] = float(mprot.group(1))\n",
        "    # sodium: \"180mg sodium\"\n",
        "    msod = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*mg\\s*(?:sodium)\\b', model_output, flags=re.I)\n",
        "    if msod:\n",
        "        claims[\"sodium\"] = float(msod.group(1))\n",
        "    # duration: \"ready in 20 minutes\", \"Takes 12 minutes\"\n",
        "    mtime = re.search(r'(\\d+)\\s*(?:minutes|min|mins)\\b', model_output, flags=re.I)\n",
        "    if mtime:\n",
        "        claims[\"duration\"] = float(mtime.group(1))\n",
        "    # serves: \"serves 4\"\n",
        "    mserves = re.search(r'serves\\s*(\\d+)', model_output, flags=re.I)\n",
        "    if mserves:\n",
        "        claims[\"serves\"] = int(mserves.group(1))\n",
        "    # fiber: \"5g fiber\"\n",
        "    mfib = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*g\\s*(?:dietary fiber|fiber)\\b', model_output, flags=re.I)\n",
        "    if mfib:\n",
        "        claims[\"fiber\"] = float(mfib.group(1))\n",
        "    # total_fat: \"9g fat\"\n",
        "    mfat = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*g\\s*(?:fat)\\b', model_output, flags=re.I)\n",
        "    if mfat:\n",
        "        claims[\"total_fat\"] = float(mfat.group(1))\n",
        "    # carbs: \"30g carbs\"\n",
        "    mcarb = re.search(r'([0-9]+(?:\\.[0-9]+)?)\\s*g\\s*(?:carb|carbs|carbohydrate|carbohydrates)\\b', model_output, flags=re.I)\n",
        "    if mcarb:\n",
        "        claims[\"carbs\"] = float(mcarb.group(1))\n",
        "\n",
        "    # Extract simple ingredients mentioned like \"Features chickpeas and tahini\"\n",
        "    # Look for \"Features X and Y\" or \"using X and Y\" patterns\n",
        "    ming = re.search(r'(?:features|using|uses|with)\\s+([a-zA-Z0-9\\s\\-\\']+?)\\s*(?:,|\\band\\b|\\.)', model_output, flags=re.I)\n",
        "    if ming:\n",
        "        # split on 'and' or commas\n",
        "        text = ming.group(1)\n",
        "        candidates = re.split(r'\\band\\b|,', text, flags=re.I)\n",
        "        ing_list = [c.strip().lower() for c in candidates if c.strip()]\n",
        "\n",
        "    # fallback: look for \"using X and Y.\" explicit pattern\n",
        "    m2 = re.search(r'using\\s+([^\\.,]+?)\\.', model_output, flags=re.I)\n",
        "    if m2:\n",
        "        parts = re.split(r'\\band\\b|,', m2.group(1))\n",
        "        ing_list = [p.strip().lower() for p in parts if p.strip()]\n",
        "\n",
        "    return title if title else None, claims, ing_list\n",
        "\n",
        "\n",
        "def parse_instruction_to_constraints(instruction: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Given an instruction string (as generated in variants), return a constraints dict.\n",
        "    Supports the variant instruction formats you provided.\n",
        "    \"\"\"\n",
        "    instr = instruction.lower()\n",
        "    constraints = {}\n",
        "\n",
        "    # calories: \"under 400 calories\" or \"around 400 calories\" or \"under 400\"\n",
        "    m = re.search(r'under\\s+(\\d+)', instr)\n",
        "    if m:\n",
        "        constraints[\"calories_max\"] = float(m.group(1))\n",
        "    m2 = re.search(r'around\\s+(\\d+)', instr)\n",
        "    if m2:\n",
        "        val = float(m2.group(1))\n",
        "        # allow +/- 50 calories tolerance for \"around\"\n",
        "        constraints[\"calories_min\"] = max(0.0, val - 50)\n",
        "        constraints[\"calories_max\"] = val + 50\n",
        "\n",
        "    # time-based: \"less than X minutes\"\n",
        "    mtime = re.search(r'less than\\s+(\\d+)\\s*minutes', instr)\n",
        "    if mtime:\n",
        "        constraints[\"duration_max\"] = float(mtime.group(1))\n",
        "\n",
        "    # protein: \"at least Xg protein\" or \"high-protein at least X\"\n",
        "    mprot = re.search(r'at least\\s+(\\d+)\\s*g\\s*protein', instr)\n",
        "    if mprot:\n",
        "        constraints[\"protein_min\"] = float(mprot.group(1))\n",
        "    else:\n",
        "        # \"high-protein recipe with at least 12g protein.\" or \"high-protein with at least 10\"\n",
        "        mprot2 = re.search(r'(\\d+)\\s*g\\s*protein', instr)\n",
        "        if mprot2 and 'high-protein' in instr:\n",
        "            constraints[\"protein_min\"] = float(mprot2.group(1))\n",
        "\n",
        "    # sodium: \"under Xmg sodium\"\n",
        "    msod = re.search(r'under\\s+(\\d+)\\s*mg\\s*sodium', instr)\n",
        "    if msod:\n",
        "        constraints[\"sodium_max\"] = float(msod.group(1))\n",
        "\n",
        "    # ingredient-based: \"using X and Y\"\n",
        "    ming = re.search(r'suggest a recipe using\\s+([a-z0-9\\s\\-\\']+?)\\s+and\\s+([a-z0-9\\s\\-\\']+)', instr)\n",
        "    if ming:\n",
        "        constraints[\"ingredients_include\"] = [ming.group(1).strip(), ming.group(2).strip()]\n",
        "\n",
        "    # fiber: \"at least Xg fiber\" or \"high-fiber at least\"\n",
        "    mf = re.search(r'at least\\s+(\\d+)\\s*g\\s*fiber', instr)\n",
        "    if mf:\n",
        "        constraints[\"fiber_min\"] = float(mf.group(1))\n",
        "    mff = re.search(r'high-fiber.*?(\\d+)', instr)\n",
        "    if mff and \"fiber\" in instr:\n",
        "        constraints[\"fiber_min\"] = float(mff.group(1))\n",
        "\n",
        "    # balanced meal: this is generic -> require calories, protein, total_fat present and between some moderate bounds\n",
        "    if \"balanced meal\" in instr:\n",
        "        constraints[\"balanced\"] = True\n",
        "\n",
        "    # time variant in your code: instruction uses \"less than {duration + 10} minutes\"\n",
        "    mquick = re.search(r'less than\\s+(\\d+)\\s*minutes', instr)\n",
        "    if mquick:\n",
        "        constraints[\"duration_max\"] = float(mquick.group(1))\n",
        "\n",
        "    return constraints\n",
        "\n",
        "\n",
        "def recipe_satisfies_constraints(recipe_row: pd.Series, constraints: Dict[str, Any]) -> bool:\n",
        "    \"\"\"\n",
        "    Returns True if the pandas series (one recipe) satisfies all constraints.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # calories\n",
        "        if \"calories_max\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"calories\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"calories\"]] > constraints[\"calories_max\"]:\n",
        "                return False\n",
        "        if \"calories_min\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"calories\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"calories\"]] < constraints[\"calories_min\"]:\n",
        "                return False\n",
        "        # duration\n",
        "        if \"duration_max\" in constraints:\n",
        "            if COLS[\"duration\"] not in recipe_row or pd.isna(recipe_row[COLS[\"duration\"]]):\n",
        "                return False\n",
        "            if float(recipe_row[COLS[\"duration\"]]) > constraints[\"duration_max\"]:\n",
        "                return False\n",
        "        # protein\n",
        "        if \"protein_min\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"protein\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"protein\"]] < constraints[\"protein_min\"]:\n",
        "                return False\n",
        "        # sodium\n",
        "        if \"sodium_max\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"sodium\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"sodium\"]] > constraints[\"sodium_max\"]:\n",
        "                return False\n",
        "        # ingredients include\n",
        "        if \"ingredients_include\" in constraints:\n",
        "            ing_field = recipe_row.get(COLS[\"ingredients\"], \"\")\n",
        "            if not isinstance(ing_field, str):\n",
        "                return False\n",
        "            ing_field_low = ing_field.lower()\n",
        "            for ing in constraints[\"ingredients_include\"]:\n",
        "                if ing.lower() not in ing_field_low:\n",
        "                    return False\n",
        "        # fiber\n",
        "        if \"fiber_min\" in constraints:\n",
        "            if pd.isna(recipe_row[COLS[\"fiber\"]]):\n",
        "                return False\n",
        "            if recipe_row[COLS[\"fiber\"]] < constraints[\"fiber_min\"]:\n",
        "                return False\n",
        "        # balanced: require numeric calories/protein/total_fat exists; simple heuristics\n",
        "        if constraints.get(\"balanced\"):\n",
        "            if any(pd.isna(recipe_row.get(COLS.get(k), None)) for k in [\"calories\", \"protein\", \"total_fat\"]):\n",
        "                return False\n",
        "            # require moderate calories <= 700 and protein >= 10\n",
        "            if recipe_row[COLS[\"calories\"]] > 700:\n",
        "                return False\n",
        "            if recipe_row[COLS[\"protein\"]] < 8:\n",
        "                return False\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        # if any unexpected error, return False\n",
        "        return False\n",
        "\n",
        "\n",
        "def find_any_matching_recipe(df: pd.DataFrame, constraints: Dict[str, Any]) -> Optional[pd.Series]:\n",
        "    \"\"\"\n",
        "    Returns first matching recipe row (as Series) that satisfies constraints, or None.\n",
        "    \"\"\"\n",
        "    # quick vectorized filter approach\n",
        "    mask = pd.Series(True, index=df.index)\n",
        "\n",
        "    if \"calories_max\" in constraints and COLS[\"calories\"] in df.columns:\n",
        "        mask &= df[COLS[\"calories\"]].fillna(np.inf) <= constraints[\"calories_max\"]\n",
        "    if \"calories_min\" in constraints and COLS[\"calories\"] in df.columns:\n",
        "        mask &= df[COLS[\"calories\"]].fillna(-np.inf) >= constraints[\"calories_min\"]\n",
        "    if \"duration_max\" in constraints and COLS[\"duration\"] in df.columns:\n",
        "        mask &= df[COLS[\"duration\"]].fillna(np.inf) <= constraints[\"duration_max\"]\n",
        "    if \"protein_min\" in constraints and COLS[\"protein\"] in df.columns:\n",
        "        mask &= df[COLS[\"protein\"]].fillna(-np.inf) >= constraints[\"protein_min\"]\n",
        "    if \"sodium_max\" in constraints and COLS[\"sodium\"] in df.columns:\n",
        "        mask &= df[COLS[\"sodium\"]].fillna(np.inf) <= constraints[\"sodium_max\"]\n",
        "    if \"fiber_min\" in constraints and COLS[\"fiber\"] in df.columns:\n",
        "        mask &= df[COLS[\"fiber\"]].fillna(-np.inf) >= constraints[\"fiber_min\"]\n",
        "    if \"ingredients_include\" in constraints and COLS[\"ingredients\"] in df.columns:\n",
        "        for ing in constraints[\"ingredients_include\"]:\n",
        "            mask &= df[COLS[\"ingredients\"]].str.contains(ing.lower(), na=False)\n",
        "\n",
        "    # balanced: apply heuristic\n",
        "    if constraints.get(\"balanced\"):\n",
        "        mask &= df[COLS[\"calories\"]].fillna(np.inf) <= 700\n",
        "        mask &= df[COLS[\"protein\"]].fillna(-np.inf) >= 8\n",
        "        mask &= df[COLS[\"total_fat\"]].fillna(-np.inf) > 0\n",
        "\n",
        "    filtered = df[mask]\n",
        "    if len(filtered) == 0:\n",
        "        return None\n",
        "    return filtered.iloc[0]\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Main evaluation\n",
        "# -------------------------\n",
        "def evaluate(inferenced_data: Dict[str, Any], df: pd.DataFrame, split_key: str = \"test\"):\n",
        "    \"\"\"\n",
        "    Expects inferenced_data[split_key] to be [predictions_list, references_list, instructions_list]\n",
        "    Each element in predictions_list corresponds to a model output. In your variant setup, you might\n",
        "    have predictions as lists of variants per recipe; we attempt to handle either flat lists or nested.\n",
        "    \"\"\"\n",
        "    preds, refs, insts = inferenced_data[split_key]\n",
        "\n",
        "    # Normalize lists: if preds is a dict or nested list-of-lists, flatten into per-variant instruction objects.\n",
        "    # We'll assume 'insts' is parallel: each entry may contain 'variants' list (per your earlier generation),\n",
        "    # or insts may already be the list of generated 'instruction' strings.\n",
        "    # We'll construct a list of dicts: { \"instruction\": ..., \"output\": ... }\n",
        "    records = []\n",
        "\n",
        "    # Case A: you saved a structure of variants per example (list of dicts with \"instruction\" and \"output\")\n",
        "    # We'll detect types and normalize.\n",
        "    if isinstance(preds, list) and len(preds) > 0 and isinstance(preds[0], dict) and 'output' in preds[0]:\n",
        "        # already normalized predictions as dicts\n",
        "        normalized = preds\n",
        "    else:\n",
        "        # Attempt to pair insts and preds element-wise\n",
        "        normalized = []\n",
        "        # If preds entries are lists of outputs per example and insts are lists of variants (list-of-dicts)\n",
        "        if isinstance(preds, list) and len(preds) == len(insts):\n",
        "            for p, i in zip(preds, insts):\n",
        "                # If i is list of variant dicts\n",
        "                if isinstance(i, list):\n",
        "                    # each variant has instruction + output but model output might be in p list in same order\n",
        "                    # Best effort: if p is list with same length, pair them; otherwise assume p is single str\n",
        "                    if isinstance(p, list) and len(p) == len(i):\n",
        "                        for out, var in zip(p, i):\n",
        "                            normalized.append({\"instruction\": var.get(\"instruction\") if isinstance(var, dict) else str(var),\n",
        "                                               \"output\": out})\n",
        "                    else:\n",
        "                        # pair each variant instruction with same p (string)\n",
        "                        for var in i:\n",
        "                            normalized.append({\"instruction\": var.get(\"instruction\") if isinstance(var, dict) else str(var),\n",
        "                                               \"output\": p if isinstance(p, str) else str(p)})\n",
        "                else:\n",
        "                    # i is a single instruction string\n",
        "                    normalized.append({\"instruction\": i, \"output\": p})\n",
        "        else:\n",
        "            # fallback: if insts is list of variant dicts\n",
        "            if isinstance(insts, list):\n",
        "                for entry in insts:\n",
        "                    if isinstance(entry, dict) and 'instruction' in entry and 'output' in entry:\n",
        "                        normalized.append({\"instruction\": entry['instruction'], \"output\": entry['output']})\n",
        "                    elif isinstance(entry, dict) and 'instruction' in entry:\n",
        "                        normalized.append({\"instruction\": entry['instruction'], \"output\": \"\"})\n",
        "                    else:\n",
        "                        # can't interpret; make best-effort\n",
        "                        normalized.append({\"instruction\": str(entry), \"output\": \"\"})\n",
        "            else:\n",
        "                raise ValueError(\"Unable to normalize predictions/instructions structure. Inspect your inferenced_data format.\")\n",
        "\n",
        "    # Now evaluate each normalized pair\n",
        "    for item in normalized:\n",
        "        instruction = item.get(\"instruction\", \"\")\n",
        "        output = item.get(\"output\", \"\")\n",
        "        title, claims, mentioned_ings = extract_title_and_claims(output)\n",
        "        constraints = parse_instruction_to_constraints(instruction)\n",
        "\n",
        "        title_present = False\n",
        "        recipe_row = None\n",
        "        if title:\n",
        "            # try exact or case-insensitive match in df titles\n",
        "            matches = df[df[COLS[\"title\"]].str.lower() == title.lower()]\n",
        "            if len(matches) == 0:\n",
        "                # try substring match\n",
        "                matches = df[df[COLS[\"title\"]].str.lower().str.contains(re.escape(title.lower()), na=False)]\n",
        "            if len(matches) > 0:\n",
        "                title_present = True\n",
        "                recipe_row = matches.iloc[0]\n",
        "\n",
        "        # Check if the title's referenced recipe (if present) satisfies constraints\n",
        "        satisfied_by_returned = False\n",
        "        if title_present and recipe_row is not None and constraints:\n",
        "            satisfied_by_returned = recipe_satisfies_constraints(recipe_row, constraints)\n",
        "        elif title_present and (not constraints):\n",
        "            # if no constraints parsed, consider it satisfied_by_returned = True (no constraint)\n",
        "            satisfied_by_returned = True\n",
        "\n",
        "        # Check whether any recipe in dataset satisfies constraints (for recall/TP/FN)\n",
        "        any_matching = True if not constraints else (find_any_matching_recipe(df, constraints) is not None)\n",
        "\n",
        "        # Hallucination: title not found in dataset\n",
        "        hallucinated = not title_present\n",
        "\n",
        "        records.append({\n",
        "            \"instruction\": instruction,\n",
        "            \"model_output\": output,\n",
        "            \"parsed_title\": title,\n",
        "            \"title_in_dataset\": title_present,\n",
        "            \"satisfied_by_returned\": satisfied_by_returned,\n",
        "            \"dataset_has_any_matching\": any_matching,\n",
        "            \"hallucinated\": hallucinated,\n",
        "            \"constraints\": constraints,\n",
        "            \"claims\": claims,\n",
        "            \"mentioned_ingredients\": mentioned_ings\n",
        "        })\n",
        "\n",
        "    # Compute metrics:\n",
        "    TP = 0  # dataset has a matching recipe AND model returned an example that satisfied constraints\n",
        "    FP = 0  # model returned a recipe that DOES NOT satisfy constraints OR hallucination where dataset had none\n",
        "    FN = 0  # dataset has a matching recipe but model either returned non-matching recipe or hallucinated/no answer\n",
        "\n",
        "    for r in records:\n",
        "        if r[\"dataset_has_any_matching\"]:\n",
        "            # ground truth: there exists an example satisfying constraints\n",
        "            if r[\"title_in_dataset\"] and r[\"satisfied_by_returned\"]:\n",
        "                TP += 1\n",
        "            else:\n",
        "                FN += 1\n",
        "        else:\n",
        "            # dataset has no matching recipe\n",
        "            if r[\"title_in_dataset\"]:\n",
        "                # model returned a recipe (but dataset actually doesn't have matching recipe!) -> FP\n",
        "                FP += 1\n",
        "            else:\n",
        "                # model did not return any recipe (and none exists): true negative (not used in precision/recall)\n",
        "                pass\n",
        "\n",
        "    # Another kind of FP: returned a recipe but it didn't satisfy constraints (even though dataset has matching recipe).\n",
        "    # The above counts that as FN (because dataset_has_any_matching true and model didn't return matching) â€” acceptable.\n",
        "    # Also count hallucinated returns (title not present) as FP when dataset_has_any_matching is False or True\n",
        "    # For clarity compute hallucination rate:\n",
        "    total_outputs = len(records)\n",
        "    halluc_count = sum(1 for r in records if r[\"hallucinated\"])\n",
        "    halluc_rate = halluc_count / total_outputs if total_outputs > 0 else 0.0\n",
        "\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    summary_df = pd.DataFrame(records)\n",
        "    summary_df.to_csv(OUTPUT_SUMMARY_CSV, index=False)\n",
        "\n",
        "    metrics = {\n",
        "        \"total_examples\": total_outputs,\n",
        "        \"TP\": TP,\n",
        "        \"FP\": FP,\n",
        "        \"FN\": FN,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"hallucination_count\": halluc_count,\n",
        "        \"hallucination_rate\": halluc_rate,\n",
        "        \"summary_csv\": OUTPUT_SUMMARY_CSV\n",
        "    }\n",
        "\n",
        "    return summary_df, metrics\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Entry point\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Load files\n",
        "    print(\"Loading JSON:\", JSON_PATH)\n",
        "    inferenced = load_inputs(JSON_PATH)\n",
        "    print(\"Loading hummus CSV:\", CSV_PATH)\n",
        "    df = load_df(CSV_PATH)\n",
        "\n",
        "    # Choose split to evaluate - 'test' or 'val' - modify if needed\n",
        "    split_to_eval = \"test\"\n",
        "    if split_to_eval not in inferenced:\n",
        "        # fallback to 'val' or first key\n",
        "        if \"val\" in inferenced:\n",
        "            split_to_eval = \"val\"\n",
        "        else:\n",
        "            split_to_eval = list(inferenced.keys())[0]\n",
        "\n",
        "    print(f\"Evaluating split: {split_to_eval}\")\n",
        "    summary_df, metrics = evaluate(inferenced, df, split_key=split_to_eval)\n",
        "\n",
        "    print(\"\\n=== Metrics ===\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "    print(f\"\\nDetailed summary saved to {metrics['summary_csv']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABHoAAACuCAYAAABJL2pfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAT/FJREFUeJzt3Qd4FGX3NvAHQyf0Hkqo0nsTEAKCdAhFQC6QZkOiVOn1hRcCUhWQLiABQaqICNKlSQkdAgKG3pWOtGT+132+b/ad3WySDdlsdnfu33WtsruT3dnkzOwzZ85zJommaZoiIiIiIiIiIiKP90ZirwARERERERERETkHEz1ERERERERERF6CiR4iIiIiIiIiIi/BRA8RERERERERkZdgooeIiIiIiIiIyEsw0UNERERERERE5CWY6CEiIiIiIiIi8hJM9BAREREREREReQkmeoiIiIiIiIiIvAQTPUREREREREREXoKJHiIiIiIiIiIiL8FEDxERERERERGRl2Cih4iIiIiIiIjISzDRQ0RERERERETkJZjoISIiIiIiIiLyEkz0EBERERERERF5CSZ6iIiIiIiIiIi8BBM9RERERERERERegokeIiIiIiIiIiIvwUQPEREREREREZGXYKKHiIiIiIiIiMhLMNFDREREREREROQlmOghIiIiIiIiIvISTPQQEREREREREXkJJnqIiIiIiIiIiLxE0oR40cuXL6u7d+8mxEsTuY3nz5+rFClSJPZqECUoxjmZAeOczIBxTmbAOCczyJIli8qbN69rEz1I8hQrVkw9ffrU2S9N5FZ8fHxUREREYq8GUYJinJMZMM7JDBjnZAaMczKD1KlTq7CwsBiTPU5P9KCSB0mekJAQSfgQeaMNGzaoYcOGMc7JqzHOyQwY52QGjHMyA8Y5mUFYWJjq0KGD5F1cmujRYeMqX758Qr08UaJvYMA4J2/GOCczYJyTGTDOyQwY50T/w2bMXmrkyJGqbNmyib0aRERERG4zHurcubNq3rx5oq4TkTPG7xzre69atWqpXr16We7ny5dPTZ061Wmv78r9oLPXnRzHRI8L3blzR3322WdSYoUmYTly5FD169dXe/bsidcOPUmSJGrt2rVWj3355Zdq69atTlt3Ike+NBCLuCVLlkzlz59f9e/fXz179ky5G3vbDJGztwPcMmfOrBo0aKCOHz/uUPzt2LHD6ueNt5s3b8Y4QNN/9v79+wn4CcmbIKa++OILVaBAARmX5MmTRzVt2tQyfjh27Jhq1qyZypYtm0qZMqUM2Nu2batu374d62tfvHjRKn4zZcqkAgIC1K5du1zwycgMXBm/2JfXq1dPHTlyJEE/U1zG7xzruxdP+m7++uuv1cKFC536mni9DBkyRHn84MGD6pNPPlEJyXbslDVrVtWoUSN14sQJp3wGT8VEjwu1atVKviAWLVqk/vzzT7Vu3TrJ2P79999Ofy9fX1/5UiJyJRzQ3rhxQ/31119qypQpavbs2WrEiBGJvVpEibId4IZBeNKkSVWTJk3i9Bpnz561vIZ+w8EKkbPgQLZChQpq27ZtasKECTIg3rhxo6pdu7YKCgqSk1N16tSRBM2mTZtkSsSCBQuUn5+fevLkicPvs2XLFonf33//XX4W28KtW7cS9LOR93N1/OI1Hj9+rBo2bBjtAfvLly9dOn7nWJ9eV/r06V2W0EDSBY2DXUEfO2F7ff78uWrcuLF68eKFMismelwEXwo4izV+/Hj5EvL391eVK1dWgwYNkrMN+jIfffSRbBDp0qVT77zzjpyN0DOM//nPf+S+nq3EYzg7AS1atJDH9PvRlSpPnDhR5cyZU74Y8EVo/FLChoENIlWqVFKNsXTpUpbbUZzolWo4q4Z4q1u3rtq8ebM8hx1ujx49LGfW3n77bcnyx5RFR9UD4trov//9r7xG2rRpZXsZOHBglEq3efPmyfxsvE/RokXVt99+m6Cfm8jedoAbYhMxeuXKFTnwcBRiXH8N/fbGG/zKJufp3r277F8PHDggJ6LefPNNVaJECdWnTx/1xx9/SLXxgwcPZH9arlw5GRdg/IIkPv7tKIw3EL8lS5ZUgwcPVg8fPlT79++3PH/y5Ek5eMZBa/bs2dUHH3wgDSZ1kZGR6quvvlKFChWSbQtV0WPGjLE8P2DAAFl3HEigsgONWJ1xwE3uzdXxW7FiRRlDI0mJ+NUrfpYvXy6VahhvLFmyxKExyNWrV1W7du0kCZUmTRp5bX2bsB2/o1IBxwtYDmOk6tWrq0uXLtldFtvKqFGjVO7cuWVbwXNIfun0dV69erX8LrDNlClTRu3bty8efwmKK5zgx98/V65c8jcoVaqU+uGHHxz+ef3vePToUctjOIbEY4gX3alTpySxjmNKjJlr1KihLly4YLf6CIUHGKOjEh9xiZhHfBlNnjxZ1hWxiHE+tkEkPwHv26VLF9nm9ONU/edtjyVxhe7AwEDZ52Pd2rRpY5X81+N68eLF8rNISr3//vvq0aNHDo+d0J+pV69eMvY6c+ZMvD8DjmFQQYe/GX62SpUqVr9rd8VRo4sgmHHDgSuCxZ7WrVtLOemvv/6qQkNDJUhxNuKff/6RUtO+ffvKl5h+dheP6QfKOEuBx4wHzra2b98uGzj+j6oiHFgby/Y6duyorl+/LoG7atUqNWfOHIfKW4nsweB97969Knny5HIfXx6IK8Te4cOHZdCOqYuIb0dhEIUBPhKm2EYw4J85c2aUZYYPHy7L4Qze2LFjZeCP9yVyNQwgcPUPxDvPvJK7wH4XB4A44YNBqy0cUGKw/OrVK7VmzRqlaVq83/Pff/9V33//vfxb/17AwQlOauFA/NChQ7JOGPBj4K/DCbFx48bJfvz06dNyEgoJIR0OYDCWwXOYjjB37lw5mCfvlRjxCzgRCsYKASTye/bsKeMNjGliG4PgOwGJoWvXrkllP07gYnyEJI0trD8OxrE8pv8iIYMpMLYnwHSI/0mTJklCCstjfXAy+dy5c1bLDRkyRA5akShAggxJB7wXuQZaGqAa7ZdffpGxMv6mSHAjaeksiK+aNWtKwg9Vbxgzd+3aNca/M2IU2xOSjkiuI2mon6wFnGz65ptvJIGEZfG6iF2oVq2aJHOQuNGPUxFjthDnSPJgG965c6e8PmYB4JjWCMerOGZev3693LAsvgcchWTNsmXLrL5v4vMZPv/8c9n+8JrYtnDMjupt223L7WhOFhoair2p/J+srVy5UsuYMaOWMmVKrVq1atqgQYO0Y8eOyXO7du3S0qVLpz179szqZwoWLKjNnj1b/j1ixAitTJkyUV4Xv+81a9ZYPWa7bKdOnTR/f3/t1atXlsdat26ttW3bVv4dFhYmr3Pw4EHL8+fOnZPHpkyZ4rTfgbcICQlhnNtAjPn4+Ghp0qTRUqRIIb+fN954Q+L+8ePHWrJkybQlS5ZYln/x4oXm5+enffXVV3J/wYIFWvr06a1eE3Ft3E1VqVJFCwoKslqmevXqVrGObWbp0qVWy4wePVqrWrVqjNsMRcU4j992gBt+fzlz5rT6HcYUf9u3b5fn9Z/Xb8WLF7d6j8DAwGh/9t69ewn06byTGeN8//798plXr14d43KDBw/WkiZNqmXKlElr0KCB7K9v3rzp0HuEh4fLe6RKlUpiOEmSJHK/QoUKsv/X98316tWz+rkrV67IcmfPntUePnwo3ydz5851+LNNmDBB3iOm8ZC97cfbeVOcuzJ+jxw5IvexX23RooXm6+srr6E/P3XqVKufi20MgjF92rRptb///tvu+xrjFcvgPXbs2BHrsoAx1ZgxY6yWqVSpkta9e3erzzRv3jzL86dOnZLHcBzgDRIzzm2///Ubjvti+25u3Lix1rdvX8v9gIAArWfPnpb7OIbTj8dsYxPw2ngM4wDAMWb+/Pkt+1p762rcD+L93n777SixM2DAgGjXecWKFVrmzJkt9+2N423X/bfffpPf0eXLl6PE4IEDByxxnTp1atn/6/r16yfHANGxHTvh30oprVmzZtH+jKOf4dKlS7LO165ds3q8Tp068ntODI7mWxLs8uoUFUpLMTUKU7hQVorKHWRMUeKJ+cLI8tue8cUZML3MLr5QDeTj42O5jylcepMqzGlEHwnjpQhxBjpjxoxOeW8yB5QCo8IG8YwzqogpxD2y3yilR8mxDg2bUY6sXwrTEYhTlFka4TWQkQe8L7aXDz/8UH388ceWZXAGA6WfRK7cDuDevXtSto+pKThbh2m7jsD3BCoVjNsLkbM4WuGAqgRMhcE+Fmd5Z82aJRUK6LeD8ndHYGoLpq/gzDXOnKL6Ro9nVDOgyhgVz7awL0fFD6qgUd0c0+vjDC2WxzgK+3uckSXv5cr4xVl+VAFgfIGpgYg3VJRh+gxg2pXOkTEIqmhQwYbpMbHBMphig8qcd999V6bDo9oN43dbmBKJqnzjOAtwX28DoStdurTl3/proYIf2yk57/tfh9jr0KGD5X5ERITE4Y8//iiVN6gQw37OmX1sEGeYqhWXsYMxLvTYMM7sQL+q4OBgmQqFeENcozrp6dOnDq87xvyYMoWbrnjx4lKFh+cqVaokj2HKlnEMZLsuMY2dsC44zh47dqxs80av8xlwrIy/GarfjPA3c/dKbSZ6XAzzdbGzxg2lnOgxgma1OHhFENub7+esZlm2GztKP+2VihK9LpR8IkEI3333ncz9nj9/vmXHHRMMpGwHb3Hts6DPs0XpPubPGhmTnESu2g4AyXwM8hGX6DHlCPSQiG7fj4NYvUeDEQ6KEef2pjIQGRUuXFjGAMbeBdHBQBZl6rhh4IyDVEwNcXQ6LAb0eD/cMKhGT0EkfTClAPtsXCUJ03FtYUyEkv6YoJS+ffv20sMQB8PYzlBaj+kr5L1cGb9I7OBAFK9jb59s3N86MgbRp385Cq0Z0DsFU9WwLkOHDpXpLm+99ZZyxvGAPg2MxwMJ8/2v92QyQvNwTLPDNCG9Xwz6yTjaNFjv12ccM9uOl+MaZ7EdJyKxiX4/uHo0EqhIQu7evVuSmlhvZzdbft1jVn3sVKRIEUkMYUoYErvx+QzYrrH9Yvqb7bGEvZMU7oQ9ehIZvjxwBgCVNLhMJCogsIMw3rJkyWKZY4iMor2Nwd7jcYENAgMw42Ujz58/L2ejiV4HvojQeBODkoIFC0r8ojmi8UsJPaWwDQCakKPRmvFqGMZGc3qc2vahMt7HWTZcUQMHB7bbUVyaLxI5EwYo2B5QoekM2A4wv9y23xt6XyHOWf1DscEAF4mRGTNm2L0CUXRXFcJ+HPvzuFy1yOi9996TcY7enBZjH8Qyzt7a7rNx8IMDehywRHcJafSBQ5Uceo6gsgLL20uCkndxZfwiUYmfceSkqyNjEFRNYGwTl/6ESE6hVxXiHU3N0afK3gkAvLdxnAW4r4+zyD3gb4I+NajywQlRVIrhasyOwngZ0EMmuvEy4gzVLc5qTI8kBxItSKIjyYjqFlSQGUV3nGqEJuVokIybDv3VsM06O06DgoLkpAL6dMXnM2D7w2NIHNlu1+gF5s6Y6HFhh3U0HERTTkxjCQ8PVytWrJCpW9jYUY5ZtWpVabr222+/SdYRO3QMXtCgEDAQws9hY8YVKfRBPh7HIAiJotdNzKBcE+uAhmCYXoCED/6NAVZ0Td+IYoMzaMh+o4wVGfR+/frJWSns1FHWjFJJZNIBZ7+QTUdyCKXPGMgYm4XDF198IRVCOBOHBmiojsD2ZIxRnNlFWSZK+fHFiZJLnBFDp30jfVsy3l734IXICPtm7I9xQyky4lavXHA0/jCg0F9Dv+kDNlQwIObRQB8DFyTlUUGHs4No2k/kCBwkY/CK6a9olI99KuIV+06MR9AAEwci+D/2pZg6i0qIDRs2yLjldSBuUZ2ApprY/2MgjgNeNINF0h77flwWF1c+wbqhChpX1cKULzRyxvMoycf3ACCxgyu4oIoHz2Hd9UE9ebfEiF9HxDYGQazj4BDjfRzwIymE9bd35St8TyDBg+eQwMTxAT4nDpbtwRgL1XGo/MHnRaNofLegWTS5D+y3UJWF4zzE7Keffmp11anY4NgMiQrsR/HzaFSMk6pGaB6MqUm4WhWOIxE3uIoV4uJ1IKmBMci0adMkZvFattOicDyKsQ6OSXGcin28LRxroooJ4xicnMIxJ8YyaDhunAbpDKlTp5ZjDcycQfXT634GJISwvlhPXLEO2yXWG9s5Gmq7tcRqDmQ2aLI8cOBArXz58tLkCU2mihQpog0dOlR7+vSpLIOmU1988YU0U0Pj2jx58mjt27e3NKzCa7Rq1UrLkCGD/I7RMArWrVunFSpUSBrOoeGVo80H0eQLzbd0169f1xo2bCiND/E6aCaXLVs2bdasWS75HXkSb2pq6CzRNbgMDg7WsmbNKg2ZEd9ZsmSRGEMTZb3xmg4NahHLaN7ZpEkTbc6cOVbNmGHUqFHyGmiI2LVrV61Hjx7aW2+9ZbUMmj6XLVtWS548uTRAr1mzplXTRr1Jm+0NTdHpfxjnr7cdGGMKTTfR0BBNyR2JP72hoL3bvn37LK+BRrVoDIrvCzQexP4eDWsjIyMT6ZN7LjPHOb730eAe3/nYX+bKlUuaVyIOL1y4oH388cfam2++KftkjD0Qy/rYIzb2GobCkydPZL88fvx4uf/nn39KLOP18T5FixbVevXqZYnliIgI7b///a+sI8ZGefPm1caOHWvVpBPNNPGdgAtMoOmnsZkmmzF7b5wnRvw68nxsY5CLFy/KeB4XYcHxQMWKFaXBtG28oulz8+bNpaE/Xgufc/jw4bJN2C4LeHzkyJHye8C2gud+/fXXGNfZtomvp0vsZsyOXCgBTbaxHPZZOM7CsWDHjh2jNEeOrhkznD59Whp8I7YRa2hybPt3xAV/0OweMYaxSI0aNWS7sLeutu8HeB7L6SZPniyxiPesX7++9v3330dpMt2tWzfZH+NxxKe9dUdzY2ynGLtgvXBxIGOTdHsXH8LP68e49kR3MYrLly/L8fHy5cvj9RnQ1BrbXr58+WTbwmvge+v48eNaYnA035IE/3Fm4gjZOVwyTr88OHkuzClFySoaV8XUCNGMcPlMnClinCc+9LvC2TFk5sm5GOdkBoxzMgPGOZkB45zM4LCD+RY2YyYLXJUA5WooqcO8T5RKo4StZs2aib1qRAIllCizxNx8TAn74YcfJBGJElgiIiIiIiJijx4ywLxF9EfBZdhxVQw0+8JVwNjYk9wF+jtgfj2Sj8hk//zzzzK3HXN+iYjIdbp16yZXHLF3w3NE7ozxS0TejhU9ZIEqCdyI3BUa0KGCh4iIEteoUaPUl19+afc5XAGIyJ0xfonI2zHRQ0RERERxki1bNrkReSLGLxF5O4cTPbh8JS4zFhtc5g0wvUL/N5G3wSUxgXFO3oxxTmbAOCczYJyTGTDOyQzCw8MdWs6hq24hyVOsWDFphOqIN954Q0VGRjq0LJGnYpyTGTDOyQwY52QGjHMyA8Y5mYGPj4/atWuXqlq1avwqelDJgyRPSEiIJHxiggzqsGHDHFqWyFMxzskMGOdkBoxzMgPGOZkB45zMICwsTHXo0EGlSJHCeT16sMHEdK12/Y0dXZbIUzHOyQwY52QGjHMyA8Y5mQHjnOh/eHl1L5YvXz41depUq0tTr127NlHXiYiIiIiIiIjcMNEzY8YMSSSkTJlSValSRR04cMC5a+bhOnfuLIkV/ZY5c2bVoEEDdfz48URbpxs3bqiGDRsm2vsTxWcfsmLFClW0aFFZvlSpUlKeG51u3brJdmdMdBKZIfaJPC2GX758qQYMGCCPp0mTRvn5+amOHTuq69evW5bZsWOH1ZjKeDt48GCCflai14n7U6dOqVatWsny0Y1HHj16pHr16qX8/f1VqlSpVLVq1RjP5FFxjv33qFGjVMGCBWX5MmXKqI0bN0a7/Lhx42R7QNyTmyZ6li9frvr06aNGjBihDh8+LH/U+vXrq9u3bzt/DT0YEjtIruC2detWlTRpUtWkSZNEW58cOXLEOpePyBXiug/Zu3evateunfrwww/VkSNHVPPmzeV28uTJKMuuWbNG/fHHH3KwQGSm2CfyxBhGD0i8Dvpq4P+rV69WZ8+eVc2aNbO8Bg6A9fGUfvvoo49U/vz5VcWKFV322cm84hr3iOsCBQrIgS3G3/Yghjdv3qwWL16sTpw4oerVq6fq1q2rrl27lsCfhsg5cT506FA1e/ZsNW3aNHX69Gk50dqiRQvZ19tCEhPLli5d2gWfhITmgNDQUFyZS/4PlStX1oKCgizPR0REaH5+flpwcLAWEhJitaxZderUSQsMDLR6bNeuXfK7uX37ttzv37+/VrhwYS1VqlRa/vz5taFDh2ovXrywLH/06FGtVq1amq+vr5Y2bVqtfPny2sGDB61e7+2339ZSpkyp5c6dW/viiy+0x48fW5739/fXpkyZYrmP916zZo38Ozw8XO6vWrVK3gPrULp0aW3v3r1R1jmm9zArxnn8xLQPsadNmzZa48aNrR6rUqWK9umnn1o9dvXqVS1XrlzayZMno8Q/xR3j3HNin14f49z9YvjAgQPyN7l06ZLd5zFWypo1qzZq1KjX/hxmwzh3bdwb2RuPPH36VPPx8dHWr19v9TjG+kOGDHHimpsL49y1cZ4zZ05t+vTpVo+1bNlSa9++vdVjjx49kmPezZs3awEBAVrPnj0T6BOYQ6hNbiY6ca7oefHihQoNDZWMs/Eydri/b98+ps+i8fjxY+kAX6hQIZnGBWnTplULFy6UDOjXX3+t5s6dq6ZMmWL5mfbt26vcuXNLBhS/84EDB6pkyZLJcxcuXJCKIZSFYjoYMrC7d+9Wn3/+eZzWa8iQIerLL79UR48eVW+++aacdXv16pVT34MovvsQPG5cHnCGwbg8LqX5wQcfqH79+qkSJUok4Ccgcq/YJ/K2GH7w4IGU92fIkMHu8+vWrVN///236tKly2t/FqLEPPbBWDsiIkKmuxhhChfG2kSeEOfPnz93KIaDgoJU48aNo3wXUMKK01W39EutY8eUPXt2q8dx/8yZM85cN4+3fv165evrK/9+8uSJypkzpzyGjUYvd9NhLiQSLsuWLVP9+/eXxy5fviwHrZjXDoULF7YsHxwcLIkgfY4jnvvmm29UQECAmjlzZpSNLjp4T2x48J///EcOkM+fPy/v6az3IIrvPuTmzZt2l8fjuvHjx8v0yB49eiTQmhO5Z+wTeVMMP3v2THr24MRTunTp7C4zf/58SRbhZBhRQkuIYx+c7K1ataoaPXq0XCEKr/XDDz/IATVOChN5QpxjPzx58mRVs2ZN6dODViWYfovX0eHYFtPA2H/K9XjVrQRUu3ZtqZTBDY2ssDGgGfKlS5fkeVTIVK9eXebuIiGExA+SOzrMkcT8XWQ/MccXFTa6Y8eOSTUQfk6/4fVR1RAeHu7wOhrnSSIRBfo8TGe9B1FCwxkIVMUhXnEWmIiIPA8ae7Zp0wZtBeSEkj1Xr15VmzZtkp4/RJ4MvXkQ67ly5ZIemjiZigSnfkKYyN1h7I1CABQIJE+eXGZ9oNJSj+ErV66onj17qiVLlrBAIBHEeU+SJUsW5ePjo27dumX1OO5H12zMrHD1CGTlcatUqZKaN2+eVPZgihYy9qiWadSokVT5oGkVplGhbE43cuRI6dqPiptt27ap4sWLS6NZfSrYp59+akkk4YbEzLlz5ySj6ih9KhjoB8hI5DjzPYjiuw/B4zEtv2vXLklQ5s2bV6p6cENCtW/fvlItR+StsU/kLTGsJ3mw70aD2uiqeRYsWCBT4I3NmokSUkId+2AsvXPnThlv44AYJ4WxHaCJM5EnxHnWrFnV2rVr5fgW+25U/qAwQI9hnIjF+Lx8+fKW8TliHklN/NtY+UNukOhBtq5ChQpSmqVDYgD3UYJI0UMiBRnOf//9V65CgcspIrmDK0YgG6pX+hihb07v3r3Vb7/9plq2bCkDHMAGg94+eiLJeMPfyBlc8R5kPq+zD8HjxuUBBwL68ujNgz5SxqQkrrqFqY8480vkrbFP5A0xrCd5cCJpy5Ytll6GtlD9gHEQLr9uPFFFlJAS+tgHJ4ZRVX/v3j0ZswQGBsb7NYlcGeeo1kFlGnpPrVq1yhLDderUkSvKGcfnOO5FsQP+jcQSuVGPHn1KUadOneQPVblyZTV16lTJ5KFUC1/Q9L8GVfocdOy8p0+fLln7pk2bqocPH8o0LcxbRLXPL7/8YqnWASSDcJD63nvvyeVDUaqMuY1ojAyYv/7WW29JiRymd+FLAkkZDJ7wPs7givcgc4ppHwIYxOMLA32iAGWf6A01adIkqXDDdnPo0CE1Z84ceR4HBbYHBjgIwBmIIkWKJMInJHJN7BN5egwjyYOxDno4oMIZZ3j1sVOmTJmsTiyhuhlTxzEmIXLnuEeFPsbM+r9xyXQc2KLaQe/Bg6QOkpcYp6A/pt6Xk03GyVPifP/+/RLbZcuWlf9jNgqSQ3q/WfSiKlmypNV74HgSY3bbx8lNEj1t27ZVd+7cUcOHD5cvY/xxN27cGKV5k9nhd6L3vUGgY+e9YsUKVatWLXkMlTpIoiAhhMHPsGHDZAMBZDhxRQlsUCiZQzkdKnrQMFnvrYPSN1QE1ahRQ74oUAKKv42zuOI9yJxi24cgCWqco16tWjW1dOlS6WM1ePBgqYBDqSi/JMjTMPbJ0zk7hnFwgKtoAV7LaPv27ZYxk96EGa+nX6SCyF3j/vr166pcuXKW+xMnTpQbkp47duywXF1u0KBBcjIXSU2czB0zZgyr1chj4hzN87Fv/+uvvySJiZYk6D0V3RUTybWS4BrrsS2Esywo5cI8O0zniQmaLXXo0MGhZYk8FeOczIBxTmbAOCczYJyTGTDOyQwOO5ibYVt3IiIiIiIiIiIvwUQPEREREREREZGXYKKHiIiIiIiIiMhLMNFDRERERERERGTGq25t2LBBhYWFxbjMnj17HF6WyFMxzskMGOdkBoxzMgPGOZkB45zMIDw83HlX3dq3b59cXjsiIsKhF8Vl1yIjIx1alshTMc7JDBjnZAaMczIDxjmZAeOczMDHx0ft2rVLVa1aNX4VPSlSpJAkT0hIiCpWrFiMyyKDOmzYMIeWJfJUjHMyA8Y5mQHjnMyAcU5mwDgnMwgLC1MdOnSQHI3Tpm5hg4npWu36Gzu6LJGnYpyTGTDOyQwY52QGjHMyA8Y50f+wGXMCqFWrlurVq5cym86dO6vmzZsn9moQERERERERmdZrJXp+//131bRpU+Xn56eSJEmi1q5dq8wIiQ18ftvbV199pUaPHp0g77ljxw6772m8YRkidzdjxgyVL18+lTJlSlWlShV14MCBaJddvXq1qlixosqQIYNKkyaNKlu2rFq8eLHVMo8fP1aff/65yp07t0qVKpUqXry4mjVrlgs+CVH04hLnp06dUq1atZLlsS+fOnVqlGUwjRpl6fnz55c4L1iwoHzfONBuj8hj9ucjR45URYsWleczZsyo6tatq/bv3++CT0LknDiH+/fvq6CgIJUzZ06ZYvHmm2/K1CJ7xo0bJ/t9M54oJs+N87lz50ofX+yn9X217fLcn3tYoufJkyeqTJkyEghm16BBA3Xjxg2rW4UKFVTatGkT5P2qVatm9V5t2rSJsg5YhsidLV++XPXp00eNGDFCHT58WPYn9evXV7dv37a7fKZMmdSQIUOkMfzx48dVly5d5LZp0ybLMni9jRs3yrxslO5isITEz7p161z4yYheP86fPn2qChQoIAP+HDly2F1m/PjxaubMmWr69OkS57iPkwvTpk1L4E9D5Lr9OQ6IEeMnTpxQu3fvloOOevXqqTt37rjwkxG9fpy/ePFCvfvuu+rixYtq5cqV6uzZs3JQnCtXrijLHjx4UM2ePVuVLl3aBZ+EyHlxjuKCdu3aqe3bt8s+PU+ePLKvvnbtmmUZ7s8TkeaA0NBQnCqU/9vC42vWrLHcDwkJiXZZb9OpUyctMDAwyuMBAQFaz549Lff9/f21MWPGaF26dNF8fX21PHnyaLNnz7b6mcuXL2utW7fW0qdPr2XMmFFr1qyZFh4eHud1sH1vwPNYzpnr8+rVK613797yfKZMmbR+/fppHTt2tPv78EZmivOEULlyZS0oKMhyPyIiQvPz89OCg4Mdfo1y5cppQ4cOtdwvUaKENmrUKKtlypcvrw0ZMsRJa20+jPPEi3Psp6dMmRLl8caNG2tdu3a1eqxly5Za+/btnbTW5sM4d7/9ua0HDx7I32jLli3xXl+zYpy7Ns5nzpypFShQQHvx4kWMr/vo0SOtcOHC2ubNm+2O4SluGOeJuz/H8WHatGm1RYsWRbsM9+fxF1Nuxog9elxk0qRJUqp85MgR1b17d/XZZ59Jdh9evnwp2VJUAeEyaXv27FG+vr5SqYMzAu64Pvj5hQsXqu+++06ys//8849as2ZNgqwreRfEUGhoqJRuGi+Fifs4GxAb5Je3bt0q8VqzZk3L46hkQ/UOziJgGZxd+PPPP+WsAZGnxXl0EOeIf8Q2HDt2TPbBDRs2dMp6E7nD/tz2PebMmaPSp08vZ5eJPCHOMR7BZY8xdSt79uyqZMmSauzYsTL91gjPN27c2Oq1iTx13ILKZBxHonIzuvfg/tx14nTVLYpq/fr1kgTRRTfYbtSokSRUYMCAAWrKlClyIFqkSBEpk4uMjFTz5s2T+bmwYMECmb+OkriEOFCN7/qgd8SgQYNUy5Yt5Xn0QjGWXRNF5+7duzLQwcDHCPfPnDkT7c89ePBASp6fP3+ufHx81Lfffitl0TpMXfnkk0+kR0/SpEnlywll0tEdPBC5Y5zHZuDAgerhw4cy3x3bAd5jzJgxqn379k5YayL32J/r46v3339fDhzQ42Tz5s0qS5YsCfZZiJwZ53/99Zfatm2b7JvRl+f8+fMy7sZBMKbFwLJly2R6DKZuEXnDuAXHlOjha5u45P48cTDRE0+1a9eWfgk6NJrCXEVbxnm3SJ6g/4I+3xFnZPEFYNvX59mzZ+rChQtSVWNMIGEeb3wH9fFZHwzQ0AsIDbp0OLBGhRAbglJCQTwePXpUmi7jDDDmEKOfCa5ypyd6/vjjDzmL5u/vL03jcabM3hcOkaf68ccf1ZIlS9TSpUtViRIlZJtAPyrEeadOnRJ79Yicsj/Xx1dYBgcfSNqjJyEaeGbLli1R153IEThhilhF9QKSmejfiYrjCRMmSKLnypUrqmfPnnLAi6a3RJ4O/QWRvERRgG1Mc3+eOJjoiSckdgoVKhTrcsmSJbO6j+QKvgQAAx18AWDwbitr1qwqefLksnHobDOtRqhisE224OyBM9eHKD6Qwceg59atW1aP4350DWj12Na3NVylBY1og4OD5cDg33//VYMHD5bpgyiB1pOZ2G4mTpzIRA95TJzHpl+/flLVgzNjUKpUKXXp0iXZFpjoIW/Yn9uOr3B76623VOHChdX8+fOlmpjI3eMcVQsYa+PndMWKFVM3b960TJHBCdby5ctbnkc1BU5SoXGtXu1G5AnjFoy1kejZsmWL3abi3J8nDvbocQPYyZ87d06ymvpGoN8whxGX0DU+FtMVvZCIQbWN8Uvj5MmTTl0f3PAFZrw03qtXr+RLiyg2SFwikYizuDokGXEf89kdhZ/BQEhPZuKGgwcjfGHpCUwiT4xzWyh7ZpyTu0iI/Xl8liFylzivXr26VMcb983orYbxM16vTp06chUinJDSb6iMR8U+/s0kD3nK/hxX/hw9erRc+RYx7Ajuz9040YOKD32nBOHh4fLvy5cvO3v9TAE7dWRRAwMDZZoWfp8oe+vRo4e6evVqnF7rnXfeUb/88ovcMJ8STZbv37/v9PVBuSkyt2vXrpX3wbzjuL4PmRfK9FG6uWjRIjmTizh98uSJXGIXOnbsaJXlx5lelDdjzjuWRzPwxYsXqw4dOsjz6dKlUwEBAVLtgFhFzKJZ+Pfff69atGiRaJ+TzC2ucY6zvPp3K/6NMn/8GwcLuqZNm0pPHuzjcdleVLFNnjyZcU5esz/Hz6JCE1NxUa2Gk0hdu3aV7aF169aJ9jnJ3OIa53geFyrBeBkJHuyz0YwZU8oBJ23RoNl4Q9VD5syZ5d9EnhDn48ePV8OGDZOL8+Cy6ahYww25AuD+3AOnbh06dEjm2hmDAlA2bttMj2KXOnVqKdVEAys0N3706JE0KUS2HwewcYGNBz12sCGib07v3r2t/lbOWp++fftK5RD+5ji7jPfFgQb69xDFpm3bturOnTtq+PDh8oWA0n2cCdCnJSJpbKxawBcFkolINKLCDY1oQ0JC5HV0mBeMLx8kKjG4Qp8eHBB369YtUT4jUVzj/Pr166pcuXJWpdC4IYmJBKbeiwqDKmwPKPtHb55PP/1U3oPIG/bnqGTACSQcaKCfAw58K1WqJCee0JeKyBPiPE+ePHKREozDMZUF42gkfTC2JvKWOEefWpyYeu+996xeB32oRo4cyf15IkuCa6zHthA6wqOUC1k441xSe9DXBWdlHFmWyFMxzskMGOdkBoxzMgPGOZkB45zM4LCDuRn26CEiIiIiIiIi8hJM9BAREREREREReQkmeoiIiIiIiIiIvAQTPUREREREREREZrzq1oYNG+RSazHZs2ePw8sSeSrGOZkB45zMgHFOZsA4JzNgnJMZhIeHO++qW/v27VM1atRQERERDr0oLrsWGRnp0LJEnopxTmbAOCczYJyTGTDOyQwY52QGPj4+cpn6qlWrxq+iJ0WKFJLkCQkJUcWKFYtxWWRQhw0b5tCyRJ6KcU5mwDgnM2CckxkwzskMGOdkBmFhYapDhw6So3Ha1C1sMDFdq11/Y0eXJfJUjHMyA8Y5mQHjnMyAcU5mwDgnMnEz5lq1aqlevXops+ncubNq3rx5Yq8GEREREREREblToic4OFhVqlRJpU2bVmXLlk2SB2fPnlXultRIkiRJlNv58+fV6tWr1ejRoxPkfXfs2GH3fY03LOONbD971qxZVaNGjdSJEyfsLl+/fn2ZW3jw4EG7zx85ckS1bdtW5cyZU8rS/P39VZMmTdTPP/+sHGgrRR5gxowZKl++fCplypSqSpUq6sCBA9Eui+22YsWKKkOGDCpNmjSqbNmyavHixVbL3Lp1S7Z9Pz8/lTp1atWgQQN17tw5F3wSIufE+alTp1SrVq1keexHp06dGuNrjxs3TpYz48kL8q7YN1q2bJnENU9OkSfHNE4s2zsOaNy4sTz/8uVLNWDAAFWqVCkZ12Ds0rFjR3X9+nUXfiIi58f+3LlzpbdvxowZ5Va3bl2H9/+UyImenTt3qqCgIPXHH3+ozZs3y46qXr166smTJ8qd4CDvxo0bVrf8+fOrTJkySZIqIVSrVs3q/dq0aRNlPbCMJ1i4cKF8ScUVkn74nJs2bVLPnz+XL7QXL15YLXP58mW1d+9e9fnnn6vvvvsuymv89NNP6q233lKPHz9WixYtkjLMjRs3qhYtWqihQ4eqBw8exOuzUeJbvny56tOnjxoxYoQ6fPiwKlOmjCT/bt++bXd5bLdDhgyRxvDHjx9XXbp0kRviDJD8w0HBX3/9JfGDRCGSg/hycbd9E5lHXOP86dOnqkCBApLAyZEjR4yvjST57NmzVenSpRNo7YlcF/u6ixcvqi+//FIOEog8OaZxgso4/j958qSc4GzdurVlf4/XQT8Z/B/LYwzdrFkzF38yIufGPk7+t2vXTm3fvl3G7Xny5JFcwbVr11y+7qanOSA0NBQlFPJ/W7dv35bndu7cKfdDQkKiXdZVOnXqpAUGBtp9LiAgQOvZs6flvr+/vzZmzBitS5cumq+vr5YnTx5t9uzZVj9z+fJlrXXr1lr69Om1jBkzas2aNdPCw8PjvB627w14Hss5c31evXql9e7dW57PlCmT1q9fP61jx47R/k7sWbBggayvo7Zv3y5/93v37lkeW7dunTx27Ngxq2VHjhypvf/++1pYWJis49OnTy3PPX78WMucObPWokWLaN8rMjJSS2zuEOeerHLlylpQUJDlfkREhObn56cFBwc7/BrlypXThg4dKv8+e/as/D1Onjxp9ZpZs2bV5s6d6+S1Nw/GeeLFOb4LpkyZYve5R48eaYULF9Y2b95s93uF4oZx7h6xj7FLtWrVtHnz5sU4jqPXwzhP3HEL9udp06aVcW50Dhw4IH+jS5cuOWWdzYhx7n6xj307Yn/RokUJuJbmEhpDbsYo3j169OoKnHH3VJMmTZJpIagC6N69u/rss88s09FQsYSsJaqAcAmzPXv2KF9fX6nUsa1UcZf1wc+jIgfVMrt371b//POPWrNmjXIlxAXKryF58uSWx1F5sWDBAukUXrRoUVWoUCG1cuVKy/O//fab+vvvv1X//v2jfW2UvpLnQpyGhoZKtY3xUpi4j8x/bBBDW7dulW2iZs2a8hiqxwAlpcbXxLQ/bANEnhbnMUFVLaolja9N5OmxP2rUKGkJ8OGHH7poTYlctz+fP3++ev/992WaVkxjZ4xxMU2dyFtiH9VrOH715FyBp4pXoicyMlJ6A1SvXl2VLFlSuZP169dLAkS/6aWS9qCXDBIqSDpgvmyWLFmk3EwvV8PnnDdvnsyjRRd3JCow/Sih+u3Ed33Q12HQoEGqZcuW8vysWbNU+vTplSvkzp1bft/4klq6dKmUoCKho9uyZYts8EhWARI++PLT/fnnn/L/IkWKWE1RMP4t8bclz3X37l0VERGhsmfPbvU47t+8eTPGARD+/kgc4iB32rRp6t1335XnEGN58+aVuL937558MY0fP15dvXpVSqaJPCXOY4MEOkqn0S+PyFtiHwl5jAXQ24HI2/bn6E+CqVsfffRRtMs8e/ZMxvyY8pIuXTqnrDeRO4xlENfoQcWTU64Xp8ur2zuriB2XO54xr127tpo5c6blfkwZdGOPA2TS0RtBn3d47NgxaeJs29cHO+QLFy5IVU3Dhg0tj6NnQvv27eO17vFZHxwM48AWjbJ0SZMmlQqhmJoYI1FUvHhxy/1Xr15J9hUH1rrBgwfLLSb4faARLno4jR07VpJMRqgyQpNlrBPgC61fv36y7gULFoz293H06FH5d+HChWXdyHwQ84gD9G5CRQ/mC6OfCXpJJUuWTOa340wwzhhgHjy+ULBtsnk3eYsrV66onj17Sn88Y/UakSd79OiR+uCDDyTJgxNbRN4GSUycnK1cubLd5zHeRl9PjFeMxy5Eng49B3GCCsUIHLd4UKIHjXRRWfH7779LFYe7QWIHFTGOwEGiEZIrqJoBHFRWqFBBLVmyJMrP4cpSqC7QkxBgm/E0Qqmb7UEndu7OXJ/XhUyr8XPgoHnVqlVW7+NIyR0aXqOaBxU5SE4hqYMYAX0KGT6z8YsMmWIkgMaMGSOJHMC0HDRkBky/cfRvSe4PA3kkYnCVLCPcj6kBLbYfPQ5w1S006UZVg940HNsFYhjJTlT0YHtAwhNJTiJPifOYoHwa+9Xy5ctb7T+xj50+fbpMYcR7EnlS7ONED5owN23a1PKYPubBSSGMB6I7EUTk7vtzXBACB7qYmhhTkufSpUtq27ZtrOYhr4n9iRMnSqIHszl44QgPmbqFRAWSPDhgxw4JB/beDANqXKIZ88ZxkGm8YTpUqlSprB6L6YpeOPA0TiPBAB0VUc5cH9xwSfL9+/dbfgYVMDhAiAkGU8bXwuvbfra4zq3UK770/kBIGiEpiKokHJDrN72nEH4f6MqO98G0G/JOSI4iKYOqHOOgHverVq3q8OvgZ/TePEbYBrCtYTs5dOiQCgwMdNq6E7k6zo3q1KmjTpw4YbX/RCITVaT4N5M85Imxj6m3tnGNad+ozMa/ccUWIk/dn69YsULGKmhVEF2SB+MVHAxnzpw5QdafyNWx/9VXX6nRo0fLVZN5wtWDKnpw8I7eK7iEMZIa+vw8PenhbTCAnjBhghwsIhuPRAWy7qh4QcPguFQzvfPOOzLd5JdffpGzU5MnT1b37993+vqgtB8ZVFTHYAD1Ou/jDJjC9fHHH8vl+HDpa5Suvvfee1H6OWEQh94q2Bmg9wr6D6ESCP/u0aOHfA5UMuF54MGM58N20KlTJ9n5o5QZfaVw1guXTIeOHTuqXLlyWfqQ4P9YFtsNBkwbNmxQixcvtqoMw2AKCR706sFBA7YDxB2Sh0SeEOeoRDt9+rTl37gUKQ50MYVWP5Fgu/9E9SoODtytTx6ZW1xiH+X8tvGrN6NlXJOn7s91GPtiLGKbxEGSB2Ni9FzDDAmc7NSPqXDC03ghEyJPin2crB8+fLjkC/Lly2eJa73XKrlOnBM9+oGVPl1Ch4bAnTt3Vt4GyQqUxaORFJobYy45ghlnVuNaXtm1a1epZsEGgQqa3r17yxkrZ69P3759pXIIGyWmu+B9W7RoYblCmiuh+guJJmR28dntNVpEkhDrjy9DJHewrnv37pUdBX5XmPKFZbCDQflrkyZNXP45yLmQyLtz5458EeALAFOxkMjTpz6iZxRiV4cvFDQoR3NlJJSRwAwJCZHX0SHm8WWEclJUtSF2hg0bliifj+h14vz69euqXLlyVmXPuAUEBCRY838id4h9Im+MaUw7RB9TXFHWFhL569atk3/jtYxwARbb4ywiT4l95ApwsgqJTCOc+B85cqTL19/MkuAa67EthGwzyrYw/cfYG8AeTM9BeaIjyxJ5KsY5mQHjnMyAcU5mwDgnM2CckxkcdjA3w9MpRERERERERERegokeIiIiIiIiIiIvwUQPEREREREREZGXYKKHiIiIiIiIiMiMV93CJY3DwsJiXGbPnj0OL0vkqRjnZAaMczIDxjmZAeOczIBxTmYQHh7uvKtu7du3T9WoUUNFREQ49KK4xFpkZKRDyxJ5KsY5mQHjnMyAcU5mwDgnM2Cckxn4+PioXbt2qapVq8avoidFihSS5AkJCVHFihWLcVlkUIcNG+bQskSeinFOZsA4JzNgnJMZMM7JDBjnZAZhYWGqQ4cOkqNx2tQtbDAxXatdf2NHlyXyVIxzMgPGOZkB45zMgHFOZsA4J/ofNmM2qFWrlurVq5cym86dO6vmzZsn9moQERERERERkasTPTNnzlSlS5dW6dKlkxvmhf3666/Kk5IaSZIkiXI7f/68Wr16tRo9enSCvO+OHTvsvq/xhmW8ke1nz549u2rVqpX666+/LMvky5fP8nyaNGkkC79ixYpEXW9KWDNmzJC/e8qUKVWVKlXUgQMHol0W22bFihVVhgwZJD7Kli2rFi9ebLXMrVu3ZPv28/NTqVOnVg0aNFDnzp1zwSchck6cnzp1SvaN+v5w6tSpMb72uHHjZDkznqAg74p9o2XLlklc8wQUubPff/9dNW3aVMYciNe1a9c6NB7G+BbTLQoVKqQWLlzoknUlSsh9N47XihYtKsuXKlVKps8ZcXzuQYme3Llzy+AyNDRUHTp0SL3zzjsqMDBQBqieAgF248YNq1v+/PlVpkyZVNq0aRPkPatVq2b1fm3atImyHljGE+CLCdVPcXX27Fl1/fp12SEgXvAFaWzwPWrUKPk9HDlyRFWqVEm1bdtW7d2718lrT+5g+fLlqk+fPmrEiBHq8OHDqkyZMqp+/frq9u3bdpfHtjlkyBBpDH/8+HHVpUsXuW3atEmeR095HBQgefjTTz9JDPn7+6u6deuqJ0+euPjTEb1enD99+lQVKFBAvmNz5MgR42sfPHhQzZ49W068EHl67OsuXryovvzyS7kACJE7w9gCcY2DYkevktO4cWNVu3ZtdfToUUnQf/TRR5ZxDJEn7rtxnNauXTv14YcfytgbY3HcTp48Kc9zfJ7INAeEhobiylzyf3syZsyozZs3T/4dEhIS47KJrVOnTlpgYKDd5wICArSePXta7vv7+2tjxozRunTpovn6+mp58uTRZs+ebfUzly9f1lq3bq2lT59efg/NmjXTwsPD47wetu8NeB7LOXN9Xr16pfXu3Vuez5Qpk9avXz+tY8eO0f5O7FmwYIGsr6O2b98uMXHv3j3LY0uWLJHHzpw5Y/lsU6ZMsTz/8uVLLXXq1NrAgQM1d+Tuce7uKleurAUFBVnuR0REaH5+flpwcLDDr1GuXDlt6NCh8u+zZ8/K3+PkyZNWr5k1a1Zt7ty5Tl5782CcJ16c2+4TjR49eqQVLlxY27x5s93vDoobxrl7xD7GJ9WqVZPxZExjNXo9jPOEg9/rmjVrYlymf//+WokSJawea9u2rVa/fv0EXjtzYZy7dt/dpk0brXHjxlaPValSRfv000/l3xyfJ4zYcjO6ePXoQTUGSmyRkYvp0l6ebNKkSTJlBBnI7t27q88++0wqU+Dly5eS5UQVEC5vtmfPHuXr6yuVOi9evHDL9cHPoyLnu+++U7t371b//POPWrNmjXK1VKlSyf+j+z0lTZpUJUuWLMF+j5R48DdFRSCy+cZLYeI+KnZigzHV1q1bJe5r1qwpjz1//lz+j7JR42uiPBpxTuRpcR6ToKAgOTNsfG0iT499VPVmy5ZNzgwTeRvEvu0+G2P2+H4fECXmvju2uOb4PHG9VqLnxIkTkkDAH6lbt26SKChevLjyFOvXr5f112+tW7eOdtlGjRpJQgVzaQcMGKCyZMmitm/fbilvi4yMVPPmzZM5iejwvmDBAnX58uUE67cT3/VBz4dBgwapli1byvOzZs1S6dOnV66E6VkTJ05UuXLlUkWKFLG7owkODlYPHjyQqYHkXe7evStJYvRqMsL9mzdvRvtziAdsr8mTJ5eD3GnTpql3331XnsPc4Lx580ps37t3T2Jo/Pjx6urVqxJvRJ4S57HByRWUU2MfSeQtsY8B//z589XcuXNdtJZEroXYt7dNPHz4UP3777+Jtl5E8dl3RxfX+vIcnyeuOF1eXYeDc8wvxYHXypUrVadOndTOnTs9JtmD+bFoKq1Dc9foGPsfoNka+ibo8xSPHTsmTZxt+/o8e/ZMXbhwQapqGjZsaHkc/RTat28fr3WPz/rg74WNCo21jJUzqBD6f5Wn9iFRZPzbvnr1SqqHcNCtGzx4sNxi6++E90EfCsz5XLVqlRy065C4Gjp0qKwvXht9KnBATwSIa+x3Hj9+LBU9mEOMfiboF4XqLzRsxplg9PPx8fGRMwzY/mKKbSJPcuXKFdWzZ0+1efNmq7NjRJ7s0aNH6oMPPpAkD05eERGRd+D43AMTPTg4R0UJVKhQQZpCfv3115LI8ARI7Ojr70iAGiG5gqoZwAEnPv+SJUui/FzWrFnl94QDU51txtMIZWy2AY9kijPX53WhS7rxc2CDRZLG+D7YeGODxBeu1IbSbHtNr/v16ydd2ZHkwe8Kn428Dwby2NGjC78R7sfUgBbbiL7d4qpbYWFhUtWgNwZH7OsJaJwxQMwjqYlEJpGnxHlMUFKNxD6u2qLD2Tdc/WX69OlSIo33JPKk2MeJKDRhxgUadPq4BiejME23YMGCLlhzooSD2Le3TWBcrLczIPK0cUt0cW1cnuPzxBOvHj3GL2R9Dp6ZYLCNy8MhcYEDUOMN06Gw4zY+FtMVvRD0xhI2DN71juXOWh/ccubMqfbv329VnYODh5hgoGV8Lby+7WdzJNGDK5thsBbd7wE7GLwWdg5M8ngvJECx00dVjnEfgvtx6fUV3X4HcY7tCdsCrgyIqwISeWqcG9WpU0emTmPApN8wUEKlKP7NJA95YuyjtN82rps1a2a5OlGePHlc/AmInA+xb9wmANWZ3trjlMwxbolLXHN87gEVPZhjh3IrzLdDue3SpUul/4sZLw+IwfWECRMkUNFEEFOTLl26JBUv/fv3l/uOQi8aTEX55ZdfJBkyefJkdf/+faevD8r+MSWqcOHCMrh6nfchii/EOqZ84iC1cuXK0jsKTd1xyXTo2LGj9HDS+5Dg/1gW2waSOxs2bFCLFy+2moK5YsUK+QLBvgkHDYh1XNKxXr16ifY5ydziGuc403X69GnLv69duyYHuqhy1E8WlCxZMkqFaubMmaM8TuQpsY9piLbxmyFDBvk/45rcFaro0S7BePl07K9x4lPvSYJ9+Pfffy/Po6cpKi8xHu/atavatm2b+vHHH2XcT+Sp4xaMtQMCAuRiP2i3gT6CSOLMmTPH8pocn3tQogdl4/gjo/oEmTn0jEGSR2+KaiapU6eWknn0lkFzYyS+EPw464pSzLjATh89dvC7RQVN79695WyWs9enb9++8rfDRoypMHjfFi1aSDkdkau0bdtW3blzRw0fPlwatmEq1saNGy3TG9EXCvGpw5cMmpCjeRuqyZCkDAkJkdfRIa7xBYWSUVSuYVsaNmxYonw+oteJ8+vXr6ty5cpZ7qNpPW4YRCVUg38id4h9Ik+Dg1njOB3jD8D4Gle3xZgEcW6sakdSB+N7tLvAyVdcPAVXKCLy1H13tWrVpOgDPVbRqxWFBGvXrrVK0nN8nniS4BrrsS2EK3yglAtTfIy9AexB35YOHTo4tCyRp2KckxkwzskMGOdkBoxzMgPGOZnBYQdzMzydQkRERERERETkJZjoISIiIiIiIiLyEkz0EBERERERERF5CSZ6iIiIiIiIiIjMeNUtXNI4LCwsxmX27Nnj8LJEnopxTmbAOCczYJyTGTDOyQwY52QG4eHhzrvq1r59+1SNGjVURESEQy+Ky65FRkY6tCyRp2KckxkwzskMGOdkBoxzMgPGOZmBj4+P2rVrl6patWr8KnpSpEghSZ6QkBBVrFixGJdFBnXYsGEOLUvkqRjnZAaMczIDxjmZAeOczIBxTmYQFhamOnToIDkap03dwgYT07Xa9Td2dFkiT8U4JzNgnJMZMM7JDBjnZAaMc6L/YTNmcpqLFy+qJEmSqKNHjyb2qhARERERERGZUrwTPePGjZOD+169eil31blzZ1lH29u8efPsPm687dixI8HWa/v27apRo0Yqc+bMKnXq1Kp48eKqb9++6tq1a8pV8BnXrl3rlNfKkyePunHjhipZsqTDPzNy5EhVtmxZp7w/eZYZM2aofPnyqZQpU6oqVaqoAwcORLvs6tWrVcWKFVWGDBlUmjRpJGYWL15stczjx4/V559/rnLnzq1SpUol29OsWbNc8EmInBPnp06dUq1atZLlsW+eOnVqlGWCg4NVpUqVVNq0aVW2bNlU8+bN1dmzZxP4UxC5dn9u1K1bt2i3ByJ3jfNatWrZPa5o3Lix3eUZ5+QtsT937lzp7ZsxY0a51a1bN8blyU0TPQcPHlSzZ89WpUuXVu6uQYMGkoQw3j744AOr+23atImyXLVq1RyuZIkL/N4Q+Dly5FCrVq1Sp0+floPSBw8eqEmTJil38uLFC4ebQuHzJE0apxmBZELLly9Xffr0USNGjFCHDx9WZcqUUfXr11e3b9+2u3ymTJnUkCFDpDH88ePHVZcuXeS2adMmyzJ4vY0bN8q8bJTuIvmMxM+6detc+MmIXj/Onz59qgoUKCAnULAvtWfnzp0qKChI/fHHH2rz5s3q5cuXql69eurJkycJ/GmIXLc/161Zs0Zi3c/PzwWfhMh5cY6EpvF44uTJkzJObt26dZRlGefkTbGPIol27dpJQQP28ygEwDjFlYUM9P9pDggNDcWVueT/ukePHmmFCxfWNm/erAUEBGg9e/aUx0NCQqIsm9g6deqkBQYGOm05W+Hh4fKZHXXlyhUtefLkWq9evew+f+/ePcu/V65cqRUvXlyW9/f31yZOnGi1LB4bM2aM1qVLF83X11fLkyePNnv2bMvzz58/14KCgrQcOXJoKVKk0PLmzauNHTvW8rNYb/2G+zBixAitTJky2ty5c7V8+fJpSZLIxdm0X3/9VatevbqWPn16LVOmTFrjxo218+fPR/k9HDlyRO5v375d7m/ZskWrUKGClipVKq1q1aramTNn5PkFCxZYvT9ueCwyMlLWAZ8FnztnzpzaF198obkTd4xzT1K5cmWJS11ERITm5+enBQcHO/wa5cqV04YOHWq5X6JECW3UqFFWy5QvX14bMmSIk9bafBjniRfn2B9PmTIl1uVu374tf6OdO3fGe33NinHufvtzuHr1qpYrVy7t5MmTDm8PFD3GeeLGOeI3bdq02uPHj60eZ5w7F+Pc/WL/1atXEvuLFi1KwLU0l1A7uRl7XruiB2cUUX6IqhSKmxUrVkiVTP/+/e0+j3JmCA0NlSqj999/X504cUKmOaGT/MKFC62WRwUQyqCPHDmiunfvrj777DNLKf8333wjFQ0//vijPLZkyRIpvdMrsmDBggVytkG/D+fPn5dKI5yR0Hvu4IwxMrqHDh1SW7dulcsXtmjRItZLGOLMHdYRP4dqn65du8rjbdu2lalqJUqUsJzxwGN43ylTpkjV07lz52RqWalSpeLxGyd3gthHbBv3HYgl3EfmPzaapkn8IZ5r1qxpeRzVd4h1nDHAMjiT8Oeff8pZBCJPi3NHoQpUr5Ig8pb9OcYVqLru16+fjBGIPH1/Pn/+fBnPY7qijnFOZoh9VCuj+pjjFNd7rTk2y5Ytk9ItY2LA3a1fv175+vpa7jds2FASLokByYt06dKpnDlzxrjc5MmTVZ06dSS5A2+++aZM8ZowYYL0HdKhzw8SPDBgwABJkuAgt0iRIury5cuqcOHC6u2335bpZf7+/pafy5o1qyWxZDtNABv2999/b1kG0DvC6LvvvpPnsU4x9eUZM2aMCggIkH8PHDhQEoTPnj2TPir4myD5Y3x/rDPuYyeSLFkylTdvXlW5cuVYfqvkKe7evasiIiJU9uzZrR7H/TNnzsR4QJsrVy71/PlzKX/+9ttv1bvvvmt5ftq0aeqTTz6RHj2IKXwRYZ6w8eCByN3jPC5wkIApitWrV49TbzQid9+fjx8/XvbjPXr0SND1J3JEfPfn6E+CqVtI9hgxzskMYxkcm2JaIotDPCDRc+XKFdWzZ0/pDYCGTJ6idu3aaubMmZb7xoz660Dm/dKlS5YzUmBMJKEJ1a+//mr3Z7G8Iz190GckMDDQ6jEM6NGoDRsdBkdg7JGE10WSRJ83iYQQBk9I+qD/UJMmTRyqcEBCyJjk0RNUw4cPV/v375cNX6/kQWImpoMM4/rpyS2sHxI49mD+Mj4jelVgnZHIatq0KXv/mByaz6K6DE2XcQYY1WWIETQ81BM9mOOOqh7E7++//y6Vh/xyIW+F+MbBw+7duxN7VYictj/H2eOvv/5aTijGtf8hkTtCggeV6caTloxzMgP0HESBCPr2eFLewFvE+cgZOyYcpJcvX97yGJIOOKiaPn26TANyR0jsFCpUyGmvt2HDBilDA0wVweDEeFlxVKtEB5U5OJuFqUqxVfU4AlUvRvjC0JMw+DuFh4dL0mnLli0yFQwHvStXrozxNe0lwpBswQE0qiRw8Iz3QIIntmbNxvXTv8ximu6Fpl0o48b6IqGIaiVUMaEJqe1nJc+TJUsWSVLeunXL6nHcj64BLaBCR9+GcZUWJEJxBSJse//++68aPHiwNDTUr2iBBCO2yYkTJzLRQx4T545Co3FUquK7F1VsRN6yP9+1a1eUk0EYZ2KqN04C4QIYRJ6yP0fbAxzojho1yupxxjl5e+xj/I1ED47nPOHCTd4ozj16MJUI/WJwAKXf0B+mffv28m98eZsBEh4YpOCmT4fS7+OGkuTovPfeeyp58uTqq6++svv8/fv35f/FihVTe/bssXoO95Eo0qt5HIFpYuh9gwQNOqejB84///wjzyFxgi+W2Pz999+SfBk6dKjEANbt3r17Kr7we7D3/kiUIbGEHkPIAmMeKOKOPB/+5hUqVJCzuDok/nC/atWqDr8OfgZl/4CkK262+x9sJ7H1kCJy5zi3VxGKJA+Smtu2bVP58+d30hoTucf+HD1LcDUu4zgTJ5fQx8TelbmI3DnO0SYCsd2hQwerxxnn5M2xj2Pc0aNHy9VwkScgD6noQbmt7TQdVH9kzpxZHj927Jgz188roWIFfXQwWH/48KHq2LGjNEi+evWq9MXBFDA0L0ZWv1KlSrKhIFGDZAeqpjCX3VHo84OqoXLlyslBML5wkIHVGz7jfbGxYkpYihQpVMaMGe2+Dh7H33jOnDnyepiuhX478YX3R8URvuBwVhrx9cMPP0jyp0qVKip16tRyuWwkfoz9hcizoUy/U6dOsvNHKTPOXuGsFy6xC9gmkCzFGV7A/7FswYIFZcCEirrFixdbpmMimYk+UBgg6bGCCjBsT9gGiDwhzlEdiZ5n+r9RLYp9I74T9OoHTNdaunSp+umnn2R/efPmTXk8ffr0MVaSEnnK/hxjDdyMcFIKYxdMQyfyhDg3Tttq3rx5lJhmnJO3xj56T6HVB8YqOM7TxykYyxjbnFDCY9OTRILpSKjMQVkbrlyFqSfYGNBDBxuUPu0KV8vCxoJkDxIsKP00NmKODQ4EkFVFfx1UNyBxhEGVXvmAhBLeD9U+2EijKxXF8ig9RcM4JPTwJYRqG70/yutCg2dc2Qs9lFDJhKl/SEKh1A/rhYQP5jX//PPPUb4QyXMhcXnnzh2JbXwBoHQfWX+92RsSicbqHHyhYJtBMhQHs0WLFpUEIF5Hh/gcNGiQVBeiYg3JHjQC79atW6J8RqK4xvn169clKa/D9wNuSGKishH0g2HbfS/2nXH5biBy5/05kafHOaASHj3Ufvvtt0RaayLXxz7GKThZhRksRiNGjJArSJPrJME11mNbCI3CULaF/jzG3jz24PLdKE90ZFkiT8U4JzNgnJMZMM7JDBjnZAaMczKDww7mZszRUIeIiIiIiIiIyASY6CEiIiIiIiIi8hJM9BAREREREREReQkmeoiIiIiIiIiIzHjVrbCwsFiXwaWyHV2WyFMxzskMGOdkBoxzMgPGOZkB45zMIMzB+Hboqlu4bFqxYsXU06dPHXpRXMYbl8Um8maMczIDxjmZAeOczIBxTmbAOCczSJ06tSR88ubNG79Ej57suXv3rkNv/Pz5c5UiRQrH15TIAzHOyQwY52QGjHMyA8Y5mQHjnMwgS5YsMSZ54pToISIiIiIiIiIi98ZmzEREREREREREXoKJHiIiIiIiIiIiL8FEDxERERERERGRl2Cih4iIiIiIiIjISzDRQ0RERERERETkJZjoISIiIiIiIiLyEkz0EBERERERERF5CSZ6iIiIiIiIiIi8BBM9RERERERERERegokeIiIiIiIiIiIvwUQPEREREREREZGXYKKHiIiIiIiIiMhLMNFDREREREREROQlmOghIiIiIiIiIvISTPQQEREREREREXkJJnqIiIiIiIiIiLwEEz1ERERERERERF6CiR4iIiIiIiIiIi/BRA8RERERERERkZdgooeIiIiIiIiIyEsw0UNERERERERE5CWY6CEiIiIiIiIi8hJM9BAREREREREReQkmeoiIiIiIiIiIlHf4PynPaIWJqLcUAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1000x200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Data\n",
        "data = {\n",
        "    \"Setting\": [\n",
        "        \"Baseline\",\n",
        "        \"Fine-Tuned\",\n",
        "        \"Fine-Tuned + RAG\",\n",
        "        \"Fine-Tuned + PP\",\n",
        "        \"FT + Constraints\"\n",
        "    ],\n",
        "    \"RougeL\": [0.04, 0.38, 0.39, 0.39, 0.38],\n",
        "    \"BLEU\": [0.0, 0.18, 0.14, 0.14, 0.12],\n",
        "    \"CS_Recall\": [0.027, 0.33, 0.4, 0.4, 0.34],\n",
        "    \"CS_Precision\": [0.19, 0.64, 0.72, 1.0, 0.74],\n",
        "    \"Hallucination Rate\": [0.94, 0.23, 0.2, 0.09, 0.2]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "metrics = [\"RougeL\", \"BLEU\", \"CS_Recall\", \"CS_Precision\", \"Hallucination Rate\"]\n",
        "\n",
        "# Create figure\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "bar_width = 0.15\n",
        "positions = range(len(df[\"Setting\"]))\n",
        "\n",
        "# Plot bars for each metric\n",
        "for i, metric in enumerate(metrics):\n",
        "    ax.bar(\n",
        "        [p + i * bar_width for p in positions],\n",
        "        df[metric],\n",
        "        width=bar_width,\n",
        "        label=metric\n",
        "    )\n",
        "\n",
        "# Format plot\n",
        "ax.set_xticks([p + 2 * bar_width for p in positions])\n",
        "ax.set_xticklabels(df[\"Setting\"], rotation=15, ha=\"right\")\n",
        "ax.set_ylabel(\"Score\")\n",
        "ax.set_title(\"Performance Comparison Across Methods\")\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display the table separately\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import table\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 2))\n",
        "ax.axis(\"off\")\n",
        "tbl = table(ax, df.round(3), loc=\"center\", cellLoc=\"center\", colWidths=[0.2]*len(df.columns))\n",
        "tbl.auto_set_font_size(False)\n",
        "tbl.set_fontsize(10)\n",
        "tbl.scale(1.2, 1.2)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "1TO8dblDDzSr"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01c577ae017440bf8574713a6431a6cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02400ecf2c4d4223a0bae55b932e9f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02c42f9e9bb14a8fb4ce0996816f4e99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0843de010fd340eaa43cce014053248b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "091f2b020c094abf91f9d3172213c053": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd423d0ade294b648d62739fd884e793",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_12b2f78684dc46ff8dba2e692af3aef8",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "09cea5e418924e74a7bf7925d91c4746": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ac8fb5abd104cc88e676f7b8d9a7499": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_723ab26b8e0c463cbe0276173c0e56e4",
            "max": 1554,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8b3965cd6794a0bb76c6314943ba6ef",
            "value": 1554
          }
        },
        "0b0809a6555d4ffeba21c8ef739205df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7df5c1bd952048e4adfb74909785650f",
              "IPY_MODEL_0ac8fb5abd104cc88e676f7b8d9a7499",
              "IPY_MODEL_919dbcad1670489f8d770d35c4018852"
            ],
            "layout": "IPY_MODEL_d9466ea68d2443dfbab04c304fa72319"
          }
        },
        "0b13f584ddd64125944b50c2962647d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcedb31a48244877a5c29a403ee77ef9",
            "max": 5964186429,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e2c5bc56d2447d1a4307d4396383383",
            "value": 5964186429
          }
        },
        "0c91387fe86d408c90f4f05c4725190e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0fcc3f735e9a42b7afe82fca6edf351a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "102263c3891545b0912cfd82a1cd5d1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "12b2f78684dc46ff8dba2e692af3aef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16cbe4c8ab6f42f494c617e14ff826ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "177346c121c1484a961a3e79be3ab8d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1936b74c380e4390a29dab658aaedde0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aa64635846d40799bb46e2a33ef9d63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b27de43b3314c3991b74bb2d58540f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c87e89f399b4e7fb406ac316b081611": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2076f8c76b1b40f195bee2077f48988e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22bff263c6fc4f7ca0076a3c441040b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72b64491bfb943948a2eb7e5c8b99c28",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_274980930ec04ab093c4e079829dce5d",
            "value": "recipe_recom.parquet:â€‡100%"
          }
        },
        "274980930ec04ab093c4e079829dce5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "311a459f497049a1a342ce1b3c66ff81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "357a336b06aa4eed937c6b0a1ace6062": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "360723bbb6ec4817908f269e3b1c7915": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ea22621877845d59125b30262598bf9",
            "max": 83945296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e20e3316865e4a53bf6b97bb8744c50b",
            "value": 83945296
          }
        },
        "3696af4a31b944ca8baacacb89b4404f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3af44163e808405bbcb583417067afc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16cbe4c8ab6f42f494c617e14ff826ed",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d06441c0490b4463b7d3ed9b7b4fc00a",
            "value": "â€‡5.96G/5.96Gâ€‡[01:00&lt;00:00,â€‡217MB/s]"
          }
        },
        "3c093a9ecaa54d59bf99ab36586be587": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dd3b995a047404eb0360d895569ebcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fa42322604a40699b09aa47bb7ce475": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1936b74c380e4390a29dab658aaedde0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0fcc3f735e9a42b7afe82fca6edf351a",
            "value": "â€‡6.27k/?â€‡[00:00&lt;00:00,â€‡150kB/s]"
          }
        },
        "3fdc0edb544243d2bfd9b8a254977188": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4226eb7a134548ca9567e8133b7fc5df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9392bcac2f045f396b27eafe351d540",
              "IPY_MODEL_ee85bb2c200c403fa95d01e8b60fbc04",
              "IPY_MODEL_791d8e210c6b4eff8195796b919a90d2"
            ],
            "layout": "IPY_MODEL_cf1a1ed6df9d43afadf3a78ca13cb89a"
          }
        },
        "43da9e2f26954c4e8bf3fdb867028d8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "444899c1096b48dfac540255ef4ec07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "478adf2cb9234674bb55205c37b7fb20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d270c228256e4eb6beec82721b300ddf",
              "IPY_MODEL_cfdc0ccf31d14718ba4323d53af1617c",
              "IPY_MODEL_6735fe277015436bb03804426da1b7c3"
            ],
            "layout": "IPY_MODEL_4ba8adf9783e4aa6af62b0098c4fdb3c"
          }
        },
        "4ba8adf9783e4aa6af62b0098c4fdb3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d7c4ad2e2114d85999601f0c37e170c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_762e0363a9d8407c876dccb7de38d718",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3fdc0edb544243d2bfd9b8a254977188",
            "value": "â€‡5149/5149â€‡[00:00&lt;00:00,â€‡45974.39â€‡examples/s]"
          }
        },
        "4f4d3998ff5c4043a929ae6f6c3be395": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "50ee208cda4a42c0b449f7e7ee8c099d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c91387fe86d408c90f4f05c4725190e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_753e9770dbd44e4ca11e675cb22e6b07",
            "value": 1
          }
        },
        "52086dcfb63646ed871652855c620f49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5321b58f90f542f884db313ed7e09886": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53670c3fc0264499b40a8d64977ec0a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54e4b48a274a4bcdb95e041ed1fd6769": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2d6520b78a940cebf166b3678600c33",
            "max": 17209920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b27de43b3314c3991b74bb2d58540f9",
            "value": 17209920
          }
        },
        "5527f5f291ea409b89c36adcadedc36f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "597925f7e8f14bd0b2d34e61715d8c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82a2211a50654b5a9c0fee2ce6631a11",
            "max": 459,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db33dfc1c08f4e1d85df5699ee096e74",
            "value": 459
          }
        },
        "5a3c40d3b5bf453baf55783db1d411e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cafc6a6ca4a4af4b2bdf563749c9ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "662e7520c4cf4c769ed79148764732a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66945d36cfa4425ca6cfed923e86dfc6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67305af8395b4009bf4d0daabc633406": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6735fe277015436bb03804426da1b7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ebb5e67e4f947429d78e6d01ceb7c8f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f658eb52077c4c83b1427446b2a36fea",
            "value": "â€‡5149/5149â€‡[00:00&lt;00:00,â€‡32661.35â€‡examples/s]"
          }
        },
        "684595bd0fdb4b0296b605ce0ad9d87b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bda469ff6674e16adea510262a8fc68",
              "IPY_MODEL_e6c3cc681529436c853d73dc1d655902",
              "IPY_MODEL_ce869b663b7d422d9e2cfbc807b352ad"
            ],
            "layout": "IPY_MODEL_3696af4a31b944ca8baacacb89b4404f"
          }
        },
        "6975eb7347354a25a572d384466f2c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a282541f31c740f7b88f51ade8f24447",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_311a459f497049a1a342ce1b3c66ff81",
            "value": "adapter_model.safetensors:â€‡100%"
          }
        },
        "6c7e8897aa6b4c748a039824a934b368": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87430bbc5852435285c6fff793e78a80",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3dd3b995a047404eb0360d895569ebcb",
            "value": "â€‡459/459â€‡[00:00&lt;00:00,â€‡54.9kB/s]"
          }
        },
        "6cefa094069b49acb1d65a97bb019b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_091f2b020c094abf91f9d3172213c053",
              "IPY_MODEL_597925f7e8f14bd0b2d34e61715d8c52",
              "IPY_MODEL_6c7e8897aa6b4c748a039824a934b368"
            ],
            "layout": "IPY_MODEL_357a336b06aa4eed937c6b0a1ace6062"
          }
        },
        "6d64d877880b4c92a690458256bce02f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6db949a98385435a81e2220619022ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "723ab26b8e0c463cbe0276173c0e56e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72425f0744004baba17d6e5d23ffe8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72549f8f32a149d18731c0d87ead602e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaa0e847a5f04b21941ba7aa28354133",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9068008ac7ec4bc9b98d4ef626ce99c8",
            "value": "â€‡83.9M/83.9Mâ€‡[00:01&lt;00:00,â€‡71.1MB/s]"
          }
        },
        "72b64491bfb943948a2eb7e5c8b99c28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72c20854909a45eaaaf61012b4c15aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ecef4efceec475ab2937fe3bab448af",
              "IPY_MODEL_0b13f584ddd64125944b50c2962647d7",
              "IPY_MODEL_3af44163e808405bbcb583417067afc0"
            ],
            "layout": "IPY_MODEL_7dd05ed4c9c84631b5db552eb3e5799e"
          }
        },
        "74fdbb26d293465d9215fe333d55fffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6975eb7347354a25a572d384466f2c88",
              "IPY_MODEL_360723bbb6ec4817908f269e3b1c7915",
              "IPY_MODEL_72549f8f32a149d18731c0d87ead602e"
            ],
            "layout": "IPY_MODEL_6d64d877880b4c92a690458256bce02f"
          }
        },
        "753e9770dbd44e4ca11e675cb22e6b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "762e0363a9d8407c876dccb7de38d718": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7634e83aa8f546548c4b4f4325936f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77ea68cd55a74d02837ef9c62ea1f2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "791d8e210c6b4eff8195796b919a90d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e84036aaca174fca9430c9cb45412580",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_444899c1096b48dfac540255ef4ec07c",
            "value": "â€‡3.34k/?â€‡[00:00&lt;00:00,â€‡38.0kB/s]"
          }
        },
        "7a3ad35f3f194b8ca8ef94aa72ce5202": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db9394a5c7f841188fd6ad81a3e1cc7b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5cafc6a6ca4a4af4b2bdf563749c9ce6",
            "value": "â€‡17.2M/17.2Mâ€‡[00:00&lt;00:00,â€‡28.2MB/s]"
          }
        },
        "7a5295d41e4f42f493387166853219a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe95c79aab1e4cbfac7649e5e182e4bf",
              "IPY_MODEL_f50b934ba3394f3a9c328ed7c0929f17",
              "IPY_MODEL_4d7c4ad2e2114d85999601f0c37e170c"
            ],
            "layout": "IPY_MODEL_9f42be5e0bc64ad88409b1cfa25e16c0"
          }
        },
        "7bda469ff6674e16adea510262a8fc68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee8309b714b445fbb7576b2c44f4be09",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8b917628c48b4a7e94b0c16373b824f9",
            "value": "tokenizer_config.json:â€‡"
          }
        },
        "7dd05ed4c9c84631b5db552eb3e5799e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7df5c1bd952048e4adfb74909785650f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0843de010fd340eaa43cce014053248b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_841aca65851e46649f908f1a1f27c69b",
            "value": "Downloadingâ€‡extraâ€‡modules:â€‡"
          }
        },
        "7ea22621877845d59125b30262598bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ecef4efceec475ab2937fe3bab448af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_957788d4fae84166bfc9fbb0b572343a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6db949a98385435a81e2220619022ff7",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "7f710b5bebbc419da51335777f905c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82678300934f430782b089e4165a0407": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82a2211a50654b5a9c0fee2ce6631a11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "841aca65851e46649f908f1a1f27c69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87430bbc5852435285c6fff793e78a80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b917628c48b4a7e94b0c16373b824f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f46241d6a244eb4a073860b8c7c5ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22bff263c6fc4f7ca0076a3c441040b6",
              "IPY_MODEL_d3b438d3950549beb8612a0994156ec0",
              "IPY_MODEL_d7f735c7119447c888823e408e0592ed"
            ],
            "layout": "IPY_MODEL_82678300934f430782b089e4165a0407"
          }
        },
        "9068008ac7ec4bc9b98d4ef626ce99c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90f46d8a0330400f9d4235b7cef7df57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52086dcfb63646ed871652855c620f49",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f0704ddf65b94bcaa91ed3af301523bf",
            "value": "â€‡235/235â€‡[00:00&lt;00:00,â€‡5.47kB/s]"
          }
        },
        "919dbcad1670489f8d770d35c4018852": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e85894e4f11b466eaedb1575d0986230",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_72425f0744004baba17d6e5d23ffe8e9",
            "value": "â€‡4.07k/?â€‡[00:00&lt;00:00,â€‡113kB/s]"
          }
        },
        "957788d4fae84166bfc9fbb0b572343a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97ef5fa25e30466bbfdb7d753e4c3883": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "983edc8581cc45888379188d7029c250": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d482698162742b699b06ba177155d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc1cc1d0d8a341cf8c7cd2898c285cc5",
              "IPY_MODEL_e6171dce2972419088864207ae5990cd",
              "IPY_MODEL_90f46d8a0330400f9d4235b7cef7df57"
            ],
            "layout": "IPY_MODEL_e6da1088ce214b9ca2a8680270ad0d2e"
          }
        },
        "9e2c5bc56d2447d1a4307d4396383383": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ebb5e67e4f947429d78e6d01ceb7c8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f42be5e0bc64ad88409b1cfa25e16c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f4f233d9237470c97680200575df1a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a282541f31c740f7b88f51ade8f24447": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a52c989381fd4e85bda4c231f05b8210": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6d10faa97bc4b868b0c614df1d41c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a752cc23a9d04a498e914909ba465b5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a79390a06d394ff895c250cfdf49845e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7df437b088e46fa9346729d94960189": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aef4337da0884c82a3285787ca311b90",
              "IPY_MODEL_54e4b48a274a4bcdb95e041ed1fd6769",
              "IPY_MODEL_7a3ad35f3f194b8ca8ef94aa72ce5202"
            ],
            "layout": "IPY_MODEL_5527f5f291ea409b89c36adcadedc36f"
          }
        },
        "aef4337da0884c82a3285787ca311b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aa64635846d40799bb46e2a33ef9d63",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_53670c3fc0264499b40a8d64977ec0a3",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "b2a1a489992643bb8a01a5e48ab8c908": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b439dea07dba4c0a87d1bebb4241e6c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6da0dd4cb7946a49122554acae6d64c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed6377a8eded4a7daba3dd4577dbe038",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b439dea07dba4c0a87d1bebb4241e6c3",
            "value": "â€‡5.94k/?â€‡[00:00&lt;00:00,â€‡135kB/s]"
          }
        },
        "b9392bcac2f045f396b27eafe351d540": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a752cc23a9d04a498e914909ba465b5c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_77ea68cd55a74d02837ef9c62ea1f2bd",
            "value": "Downloadingâ€‡extraâ€‡modules:â€‡"
          }
        },
        "bc1cc1d0d8a341cf8c7cd2898c285cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a52c989381fd4e85bda4c231f05b8210",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_eea3a2ceae2e44cdb7637f9d6122b32a",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "bcedb31a48244877a5c29a403ee77ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c70df4d2f6244eb0ba8e74d28e01a5a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c72e233a48ef440fa74fcf6a11e4c466": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f4f233d9237470c97680200575df1a2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_edc64d52caf3449b85488f497064990e",
            "value": "Downloadingâ€‡builderâ€‡script:â€‡"
          }
        },
        "ce869b663b7d422d9e2cfbc807b352ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c093a9ecaa54d59bf99ab36586be587",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e0f9738353da487a84d1bb3ee52f825e",
            "value": "â€‡50.6k/?â€‡[00:00&lt;00:00,â€‡1.55MB/s]"
          }
        },
        "cf1a1ed6df9d43afadf3a78ca13cb89a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfdc0ccf31d14718ba4323d53af1617c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01c577ae017440bf8574713a6431a6cf",
            "max": 5149,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7634e83aa8f546548c4b4f4325936f60",
            "value": 5149
          }
        },
        "d06441c0490b4463b7d3ed9b7b4fc00a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d270c228256e4eb6beec82721b300ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_177346c121c1484a961a3e79be3ab8d4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_662e7520c4cf4c769ed79148764732a5",
            "value": "Generatingâ€‡trainâ€‡split:â€‡100%"
          }
        },
        "d3b438d3950549beb8612a0994156ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43da9e2f26954c4e8bf3fdb867028d8f",
            "max": 214339,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c70df4d2f6244eb0ba8e74d28e01a5a4",
            "value": 214339
          }
        },
        "d5602a74e41346d48a40da5055b9bedc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_102263c3891545b0912cfd82a1cd5d1f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02400ecf2c4d4223a0bae55b932e9f4a",
            "value": 1
          }
        },
        "d7f735c7119447c888823e408e0592ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a79390a06d394ff895c250cfdf49845e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2076f8c76b1b40f195bee2077f48988e",
            "value": "â€‡214k/214kâ€‡[00:00&lt;00:00,â€‡331kB/s]"
          }
        },
        "d8b3965cd6794a0bb76c6314943ba6ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9432700110842d6a281e8ce53acdb4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb3464710df4429ab17f03bf32b36cfc",
              "IPY_MODEL_50ee208cda4a42c0b449f7e7ee8c099d",
              "IPY_MODEL_b6da0dd4cb7946a49122554acae6d64c"
            ],
            "layout": "IPY_MODEL_983edc8581cc45888379188d7029c250"
          }
        },
        "d9466ea68d2443dfbab04c304fa72319": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db33dfc1c08f4e1d85df5699ee096e74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db9394a5c7f841188fd6ad81a3e1cc7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0f9738353da487a84d1bb3ee52f825e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e20e3316865e4a53bf6b97bb8744c50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2d6520b78a940cebf166b3678600c33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6171dce2972419088864207ae5990cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5321b58f90f542f884db313ed7e09886",
            "max": 235,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6d10faa97bc4b868b0c614df1d41c5e",
            "value": 235
          }
        },
        "e6c3cc681529436c853d73dc1d655902": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f4d3998ff5c4043a929ae6f6c3be395",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97ef5fa25e30466bbfdb7d753e4c3883",
            "value": 1
          }
        },
        "e6da1088ce214b9ca2a8680270ad0d2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e84036aaca174fca9430c9cb45412580": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e85894e4f11b466eaedb1575d0986230": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaa0e847a5f04b21941ba7aa28354133": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb3464710df4429ab17f03bf32b36cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4a8eafdb5584eafa03b4406c7f1dd39",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_67305af8395b4009bf4d0daabc633406",
            "value": "Downloadingâ€‡builderâ€‡script:â€‡"
          }
        },
        "ed6377a8eded4a7daba3dd4577dbe038": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edc64d52caf3449b85488f497064990e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee8309b714b445fbb7576b2c44f4be09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee85bb2c200c403fa95d01e8b60fbc04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c87e89f399b4e7fb406ac316b081611",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09cea5e418924e74a7bf7925d91c4746",
            "value": 1
          }
        },
        "eea3a2ceae2e44cdb7637f9d6122b32a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef2ea3286cd84745a6635cfb433a8810": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c72e233a48ef440fa74fcf6a11e4c466",
              "IPY_MODEL_d5602a74e41346d48a40da5055b9bedc",
              "IPY_MODEL_3fa42322604a40699b09aa47bb7ce475"
            ],
            "layout": "IPY_MODEL_66945d36cfa4425ca6cfed923e86dfc6"
          }
        },
        "f0704ddf65b94bcaa91ed3af301523bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4a8eafdb5584eafa03b4406c7f1dd39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f50b934ba3394f3a9c328ed7c0929f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2a1a489992643bb8a01a5e48ab8c908",
            "max": 5149,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f710b5bebbc419da51335777f905c97",
            "value": 5149
          }
        },
        "f658eb52077c4c83b1427446b2a36fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd423d0ade294b648d62739fd884e793": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe95c79aab1e4cbfac7649e5e182e4bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02c42f9e9bb14a8fb4ce0996816f4e99",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5a3c40d3b5bf453baf55783db1d411e8",
            "value": "Map:â€‡100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
